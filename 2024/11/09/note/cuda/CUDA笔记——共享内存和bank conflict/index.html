<!DOCTYPE html>
<html lang="zh-cn">
  <head>
    <meta charset="utf8" />
    <meta name="viewport" content="initial-scale=1.0, width=device-width" />
    <title>
      
        CUDA笔记——共享内存和bank conflict | Felt's blog
      
    </title>
    <meta name="description" content="" />
    <meta name="keywords" content="" />
    
      <link rel="apple-touch-icon"
            sizes="180x180"
            href="/images/apple-touch-icon.png" />
    
    
      <link rel="icon"
            type="image/png"
            sizes="32x32"
            href="/images/favicon-32x32.png" />
    
    
      <link rel="icon"
            type="image/png"
            sizes="16x16"
            href="/images/favicon-16x16.png" />
    
    
      <link rel="mask-icon"
            href="/images/logo.svg"
            color="" />
    
    
    
      
  <style>
    @font-face {
        font-family:sourceHanSerif;
        src: url(/font/normal.ttf);
        font-weight: normal;
    }
  </style>

  <style>
    @font-face {
        font-family:sourceHanSerif;
        src: url(/font/bold.ttf);
        font-weight: bold;
    }
  </style>


    
    <link rel="stylesheet"
          type="text/css"
          href='/css/layout.css' />
    
    
  <link rel="stylesheet" type="text/css" href="/css/post.css"/>
  

  <meta name="generator" content="Hexo 7.3.0"></head>
  <body>
    
      <div id="search-mask" style="display:none">
  <div class="search-main" id="search-main">
    <div class="search__head">
      <div class="search-form">
        <svg t="1706347533072"
             class="icon"
             viewBox="0 0 1024 1024"
             version="1.1"
             xmlns="http://www.w3.org/2000/svg"
             p-id="7828"
             width="20"
             height="20">
          <path d="M685.6 660.336l155.152 155.168a16 16 0 0 1 0 22.624l-11.312 11.328a16 16 0 0 1-22.624 0l-158.528-158.544a289.792 289.792 0 0 1-165.152 51.36C322.336 742.256 192 611.904 192 451.12 192 290.336 322.336 160 483.136 160c160.784 0 291.12 130.336 291.12 291.136 0 82.112-33.984 156.272-88.672 209.2z m-202.464 33.92c134.272 0 243.12-108.848 243.12-243.12C726.256 316.848 617.408 208 483.136 208 348.848 208 240 316.848 240 451.136c0 134.272 108.848 243.12 243.136 243.12z" fill="#000000" p-id="7829">
          </path>
        </svg>
        <input id="search-input" placeholder="搜索文章">
        <svg t="1706361500528"
             id="search-clear"
             class="icon"
             viewBox="0 0 1024 1024"
             version="1.1"
             xmlns="http://www.w3.org/2000/svg"
             p-id="4351"
             width="20"
             height="20">
          <path d="M512 562.688l-264.2944 264.2944-50.688-50.688L461.312 512 197.0176 247.7056l50.688-50.688L512 461.312l264.2944-264.2944 50.688 50.688L562.688 512l264.2944 264.2944-50.688 50.688L512 562.688z" fill="#00" p-id="4352">
          </path>
        </svg>
      </div>
    </div>
    <div class="search__body" id="search-result"></div>
    <div class="search__foot"></div>
  </div>
</div>

    
    
    <div class=head>
      <div class="nav">
        <a href='/' class="nav-logo">
          <img alt="logo" height="60px" width="60px" src="/images/logo.svg" />
        </a>
        <input id="navBtn" type="checkbox" />
        <div class="nav-right">
          
            <div class="search-outer">
  <div class="search" id="search-btn">
    <svg t="1706347533072"
         class="icon"
         viewBox="0 0 1024 1024"
         version="1.1"
         xmlns="http://www.w3.org/2000/svg"
         p-id="7828"
         width="20"
         height="20">
      <path d="M685.6 660.336l155.152 155.168a16 16 0 0 1 0 22.624l-11.312 11.328a16 16 0 0 1-22.624 0l-158.528-158.544a289.792 289.792 0 0 1-165.152 51.36C322.336 742.256 192 611.904 192 451.12 192 290.336 322.336 160 483.136 160c160.784 0 291.12 130.336 291.12 291.136 0 82.112-33.984 156.272-88.672 209.2z m-202.464 33.92c134.272 0 243.12-108.848 243.12-243.12C726.256 316.848 617.408 208 483.136 208 348.848 208 240 316.848 240 451.136c0 134.272 108.848 243.12 243.136 243.12z" fill="#000000" p-id="7829">
      </path>
    </svg>
    <span>搜索</span>
    <span class="search-shortcut-key">Ctrl K</span>
  </div>
</div>

          
          <div class="nav-menu">
            
              
                <a class="nav-menu-item" href="/note">学习笔记</a>
              
                <a class="nav-menu-item" href="/project">项目</a>
              
            
            
          </div>
        </div>
        <label class="nav-btn" for="navBtn"></label>
      </div>
    </div>
    <div class="body">
      
  <article class="post-content">
    <div class="post-inner--toc">
      <div class="post-content__head">
        <div class="post-title">CUDA笔记——共享内存和bank conflict</div>
        <div class="post-info">
          
  <a href="/tags/cuda/" class="post-tag">#cuda</a>


          <span class="post-date">2024-11-09</span>
        </div>
      </div>
      
        <aside class="toc-outer">
          <div class="toc-title">目录</div>
          <ol class="post-toc"><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#%E4%BD%BF%E7%94%A8%E6%96%B9%E5%BC%8F"><span class="post-toc-text">使用方式</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#bank-conflict"><span class="post-toc-text">bank conflict</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#bank"><span class="post-toc-text">bank</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#bank-conflict-1"><span class="post-toc-text">bank conflict</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#%E5%88%86%E6%9E%90bank-conflict%E7%9A%84%E6%96%B9%E6%B3%95"><span class="post-toc-text">分析bank conflict的方法</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#%E8%A7%A3%E5%86%B3bank-conflict%E7%9A%84%E6%96%B9%E6%B3%95"><span class="post-toc-text">解决bank conflict的方法</span></a></li></ol></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#%E5%AE%9E%E4%BE%8B%EF%BC%9A%E5%85%B1%E4%BA%AB%E5%86%85%E5%AD%98%E4%BC%98%E5%8C%96%E4%B8%80%E7%BB%B4%E5%8D%B7%E7%A7%AF"><span class="post-toc-text">实例：共享内存优化一维卷积</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#%E6%9C%B4%E7%B4%A0%E5%AE%9E%E7%8E%B0"><span class="post-toc-text">朴素实现</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#%E5%85%B1%E4%BA%AB%E5%86%85%E5%AD%98%E4%BC%98%E5%8C%96"><span class="post-toc-text">共享内存优化</span></a></li></ol></li></ol>
          <a href="#" class="toc-top">回到顶部</a>
        </aside>
      
      <div class="post-content__body">
        
          <div class="post-gallery">
            
          </div>
        
        <p>共享内存比全局内存快得多，因此可以使用共享内存优化算法访存，从而提供性能</p>
<ul>
<li>然而并不是使用共享内存越多性能越快，过多的使用共享内存会导致SM上常驻block减少，降低占有率occupancy，降低性能</li>
</ul>
<blockquote>
<p><strong>最佳实践</strong>：当线程需要多次读写全局内存时，或者同一block的线程需要数据同步和通信的情况，可以使用共享内存进行优化</p>
</blockquote>
<h3 id="使用方式"><a href="#使用方式" class="headerlink" title="使用方式"></a>使用方式</h3><h5 id="静态分配"><a href="#静态分配" class="headerlink" title="静态分配"></a>静态分配</h5><ul>
<li>静态分配的共享内存大小必须在<strong>编译时</strong>确定</li>
</ul>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">__shared__ 数据类型 变量名[大小];</span><br></pre></td></tr></table></figure>
<h5 id="动态分配"><a href="#动态分配" class="headerlink" title="动态分配"></a>动态分配</h5><p>在 kernel 内部，使用 <strong>extern</strong> 关键字声明动态共享内存数组，其大小在运行时确定</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">extern</span> __shared__ <span class="type">float</span> shared[];</span><br></pre></td></tr></table></figure>
<ul>
<li>调用 kernel 时，第三个参数用于指定动态共享内存的大小</li>
</ul>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> block_size = <span class="number">256</span>;</span><br><span class="line"><span class="type">int</span> shared_mem_size = block_size * <span class="keyword">sizeof</span>(<span class="type">float</span>); <span class="comment">// 为每个 block 分配 block_size 个 float</span></span><br><span class="line">myKernel&lt;&lt;&lt;numBlocks, block_size, shared_mem_size&gt;&gt;&gt;(...);</span><br></pre></td></tr></table></figure>

<p>在模板kernel中使用动态共享内存时，不能直接使用 <code>extern __shared__ T sharedMem[];</code></p>
<ul>
<li><strong>必须</strong> 先声明 <code>extern __shared__ unsigned char sharedMem[]</code>;</li>
<li><strong>然后</strong> 在 kernel 内部用<code> reinterpret_cast&lt;T*&gt;(sharedMem)</code> 转换类型</li>
</ul>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">template &lt;typename T&gt;</span><br><span class="line">__global__ <span class="type">void</span> <span class="title function_">myKernel</span><span class="params">(T* d_out, T* d_in, <span class="type">int</span> N)</span> &#123;</span><br><span class="line">    <span class="keyword">extern</span> __shared__ <span class="type">unsigned</span> <span class="type">char</span> sharedMem[];  <span class="comment">// 共享内存声明为字节数组</span></span><br><span class="line"></span><br><span class="line">    T* smem = reinterpret_cast&lt;T*&gt;(sharedMem);   <span class="comment">// 强制转换为 T 类型指针</span></span><br><span class="line"></span><br><span class="line">    <span class="type">int</span> tid = threadIdx.x;</span><br><span class="line">    <span class="keyword">if</span> (tid &lt; N) &#123;</span><br><span class="line">        sharedMem[tid] = d_in[tid];</span><br><span class="line">        __syncthreads();</span><br><span class="line">        d_out[tid] = sharedMem[tid];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="bank-conflict"><a href="#bank-conflict" class="headerlink" title="bank conflict"></a>bank conflict</h3><h4 id="bank"><a href="#bank" class="headerlink" title="bank"></a>bank</h4><p><strong>共享内存的存储方式</strong>: <strong>shared memory</strong> 是由32个 <strong>memory bank</strong> 组成的</p>
<ul>
<li><p>bank的优点：可以同时处理跨 <em>b</em> 个不同内存 bank 的任何内存负载或 <em>n</em> 个地址的存储，从而产生比单个 bank 带宽高 <em>b</em> 倍的有效带宽</p>
</li>
<li><p><strong>Bank结构</strong>： </p>
<ul>
<li>每个 bank 的默认大小（访问粒度）是 <strong>4 字节（即 32-bit，一个 int 或 float 的大小）</strong>。</li>
<li>每个bank都有多个内存地址，可以将每个bank看作是一列数据</li>
<li><strong>每一次每个bank只能访问一个内存地址</strong>，多线程不能<strong>同时访问同一个bank内的不同个内存地址</strong>。</li>
</ul>
</li>
<li><p><strong>Shared Memory到Bank的映射方式</strong>: SM的是以wrap 32个线程为单位调度的，因此shared_memory 会<strong>连续映射</strong>到大小（默认是<strong>4字节对齐</strong>）相等的32个Bank上，</p>
<ul>
<li>对shared_memory 访问addr的逻辑地址，实际映射到BankIndex为<blockquote>
<p><em>BankIndex&#x3D;(addr &#x2F; BankSize) % 32</em></p>
</blockquote>
</li>
</ul>
</li>
</ul>
<p>例如，声明共享内存</p>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">二维 __shared__float sData[32][32]，那么 </span><br><span class="line">	sData[0][0]、sData[1][0]...sData[31][0] 位于 Bank[0]，</span><br><span class="line">	.....</span><br><span class="line">	sData[31][0]、sData[31][1]...sData[31][31] 位于 Bank[31]</span><br><span class="line"></span><br><span class="line">一维 __shared__float sData[64]， 那么</span><br><span class="line">	sData[0]、sData[32] 位于 Bank[0], </span><br><span class="line">	....</span><br><span class="line">	sData[31]、sData[63] 位于 Bank[31]</span><br></pre></td></tr></table></figure>

<p><img src="https://pic1.zhimg.com/v2-7cb74504a5c7b81130bc6ad4d562220c_r.jpg" alt="简述CUDA线程及求CUDA中线程索引 - 知乎"></p>
<h4 id="bank-conflict-1"><a href="#bank-conflict-1" class="headerlink" title="bank conflict"></a><strong>bank conflict</strong></h4><p><strong>bank conflict</strong>：如果在<strong>同一个wrap</strong>中，<strong>如果多个线程同时访问同一 bank 的不同地址（不同数据）</strong>，即取同一列共享内存的不同数据，则访问将被序列化，<strong>退化成顺序读写</strong></p>
<blockquote>
<p><strong>broadcast</strong>：如果多个线程请求的是<strong>同一bank的相同地址</strong>（即相同数据），就会触发广播操作，而不会产生bank conflict</p>
</blockquote>
<p>如下图中间warp中存在bank conflict，两个线程的冲突称为为2路冲突<br><img src="https://oneflow-public.oss-cn-beijing.aliyuncs.com/images/OneTeam/2-way_bank_conflict.png" alt="如何实现一个高效的Softmax CUDA kernel？_OneFlow一流科技有限公司"></p>
<p>bank conflict示例代码：</p>
<ul>
<li>一维：</li>
</ul>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">__shared__ <span class="type">float</span> sharedMem[<span class="number">64</span>];</span><br><span class="line"></span><br><span class="line"><span class="comment">//无冲突</span></span><br><span class="line"><span class="type">int</span> tid = threadIdx.x; <span class="comment">// 0 ~ 31</span></span><br><span class="line"><span class="type">float</span> data = sharedMem[tid]; <span class="comment">// 每个线程访问不同的 bank</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//无冲突</span></span><br><span class="line">data = sharedMem[<span class="number">0</span>]; <span class="comment">// 所有线程访问 sharedMem[0]</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//2路冲突，所有线程访问间隔 2 的地址</span></span><br><span class="line">data = sharedMem[tid * <span class="number">2</span>]; <span class="comment">// 访问 0, 2, 4, ..., 62</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<ul>
<li>二维</li>
</ul>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 1. st不冲突, ld冲突</span></span><br><span class="line">__global__ <span class="type">void</span> <span class="title function_">half_conflict_transfer</span><span class="params">(<span class="type">float</span> *in, <span class="type">float</span> *out)</span> &#123;</span><br><span class="line">  __shared__ <span class="type">float</span> tile[<span class="number">32</span>][<span class="number">32</span>];</span><br><span class="line">  <span class="type">unsigned</span> <span class="type">int</span> idx = threadIdx.y * blockDim.x + threadIdx.x;</span><br><span class="line">  tile[threadIdx.y][threadIdx.x] = in[idx];   <span class="comment">//线程按行写入，不同的 threadIdx.x 访问不同的 Bank</span></span><br><span class="line">  __syncthreads();</span><br><span class="line">  out[idx] = tile[threadIdx.x][threadIdx.y];  <span class="comment">//线程按列读取数据，例如第一个warp读取tile[0][0], tile[1][0], tile[2][0]...,发生冲突</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 2. ld/st 全冲突</span></span><br><span class="line">__global__ <span class="type">void</span> <span class="title function_">conflict_column_transfer</span><span class="params">(<span class="type">float</span> *in, <span class="type">float</span> *out)</span> &#123;</span><br><span class="line">  __shared__ <span class="type">float</span> tile[<span class="number">32</span>][<span class="number">32</span>];</span><br><span class="line">  <span class="type">unsigned</span> <span class="type">int</span> idx = threadIdx.y * blockDim.x + threadIdx.x;</span><br><span class="line">  tile[threadIdx.x][threadIdx.y] = in[idx];</span><br><span class="line">  __syncthreads();</span><br><span class="line">  out[idx] = tile[threadIdx.x][threadIdx.y];</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//3. 无冲突访存</span></span><br><span class="line">__global__ <span class="type">void</span> <span class="title function_">simple_transfer</span><span class="params">(<span class="type">float</span> *in, <span class="type">float</span> *out)</span> &#123;</span><br><span class="line">  __shared__ <span class="type">float</span> tile[<span class="number">32</span>][<span class="number">32</span>+<span class="number">1</span>];</span><br><span class="line">  <span class="type">unsigned</span> <span class="type">int</span> idx = threadIdx.y * blockDim.x + threadIdx.x;</span><br><span class="line">  tile[threadIdx.y][threadIdx.x] = in[idx];</span><br><span class="line">  __syncthreads();</span><br><span class="line">  out[idx] = tile[threadIdx.y][threadIdx.x];</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="分析bank-conflict的方法"><a href="#分析bank-conflict的方法" class="headerlink" title="分析bank conflict的方法"></a>分析bank conflict的方法</h4><h5 id="手动模拟检查"><a href="#手动模拟检查" class="headerlink" title="手动模拟检查"></a>手动模拟检查</h5><p>可以通过画图，模拟32个线程的访问情况，看看是否有访问同一个bank的时候</p>
<ul>
<li>线程访问 float类型的共享内存数据A[i][j]的bank序号的公式如下：<br>- $\text{Bank}(A[i][j]) &#x3D; (i \times 32 + j) \mod 32$</li>
<li>可以带入不同线程的 i、j序号来判断是否有冲突</li>
</ul>
<blockquote>
<p><strong>最佳实践</strong> ：在分析bank conflict时，通常只考虑<strong>threadIdx.x</strong>的影响。 因为同一个 Warp 内，threadIdx.x 唯一不同，threadIdx.y 和 threadIdx.z 固定，所以在 Warp 级优化时，通常只考虑<strong>threadIdx.x</strong></p>
</blockquote>
<h5 id="NVIDIA-Nsight-Compute"><a href="#NVIDIA-Nsight-Compute" class="headerlink" title="NVIDIA Nsight Compute"></a>NVIDIA Nsight Compute</h5><p>使用Nsight Compute分析程序，进入 <strong>“Memory Workload Analysis” → “Shared Memory”</strong>。<br>• 找到 <strong>“Shared Memory Bank Conflicts”</strong> 指标：<br>	• <strong>Shared Memory Bank Conflicts</strong> (数量越大越差)。<br>	• <strong>Shared Memory Efficiency</strong> (接近 100% 最佳)。<br><img src="/CUDA%E7%AC%94%E8%AE%B0%E2%80%94%E2%80%94%E5%85%B1%E4%BA%AB%E5%86%85%E5%AD%98%E5%92%8Cbank%20conflict/img-%E5%85%B1%E4%BA%AB%E5%86%85%E5%AD%98-2.png"></p>
<h4 id="解决bank-conflict的方法"><a href="#解决bank-conflict的方法" class="headerlink" title="解决bank conflict的方法"></a>解决bank conflict的方法</h4><p>解决bank conflict的主要有padding和swizzling ：</p>
<h5 id="padding"><a href="#padding" class="headerlink" title="padding"></a>padding</h5><p>通过新增一列，相同列的不同行的元素的bank值不再一样<br><img src="/CUDA%E7%AC%94%E8%AE%B0%E2%80%94%E2%80%94%E5%85%B1%E4%BA%AB%E5%86%85%E5%AD%98%E5%92%8Cbank%20conflict/img-%E5%85%B1%E4%BA%AB%E5%86%85%E5%AD%98-3.png"></p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//一维</span></span><br><span class="line">__shared__ <span class="type">float</span> sharedMem[<span class="number">64</span> + <span class="number">1</span>]; </span><br><span class="line"></span><br><span class="line"><span class="comment">//二维</span></span><br><span class="line">__shared__ <span class="type">int</span> s_data[<span class="number">32</span>][<span class="number">33</span>];</span><br></pre></td></tr></table></figure>

<p><strong>padding的缺点有</strong>：</p>
<ul>
<li><strong>增加共享内存占用</strong>，降低occupancy，导致 <strong>无法同时运行足够多的线程块</strong>，</li>
<li>破坏了原本的连续内存布局，访问数据时 <strong>必须手动计算偏移量</strong></li>
<li><strong>地址访问对齐问题</strong>。需要仔细考虑padding的大小来避免地址不对齐的问题<ul>
<li>比如访问shared memory时可能是向量化的访问，比如int4访问，也就是每次访问4个int，即16字节，那每次访问的地址必须是16字节对齐的，对于int s_data[32][33]这种padding方式，<strong>第二行元素的起始地址就是非16字节对齐</strong>，会导致kernel执行出错。</li>
</ul>
</li>
</ul>
<h5 id="swizzling"><a href="#swizzling" class="headerlink" title="swizzling"></a>swizzling</h5><p>swizzling是在不额外分配内存的情况下，通过将shared memory的<strong>数据进行重排</strong>来避免bank conflict。将本来在相同 Bank 的内存映射到不同的物理地址，但对于用户来说逻辑地址依然为原来的地址。</p>
<ul>
<li>在 Swizzle 中采用<strong>行列坐标进行异或</strong>的方式进行物理内存重映射。之所以采用异或的原因在于异或操作满足<strong>封闭性与双射性</strong></li>
<li>重排后，每一<strong>行内</strong>的<strong>数据集合</strong>保持不变，但行内元素的相对位置进行重排，比如对于y&#x3D;1行  ，原来的索引顺序是[0, 1, 2, 3, ……, 30, 31]，而新的索引顺序是[1, 0, 3, 2, 5, 4, ……, 31, 30]。<br><img src="/CUDA%E7%AC%94%E8%AE%B0%E2%80%94%E2%80%94%E5%85%B1%E4%BA%AB%E5%86%85%E5%AD%98%E5%92%8Cbank%20conflict/img-%E5%85%B1%E4%BA%AB%E5%86%85%E5%AD%98-5.png"></li>
</ul>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//s_mem[threadIdx.y][threadIdx.x] = input[y1 * N + x1];</span></span><br><span class="line">s_mem[threadIdx.y][threadIdx.x ^ threadIdx.y] = input[y1 * N + x1];  <span class="comment">//其映射的物理存储位置位置(row不变,col=x^y)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">//output[y2 * M + x2] = s_mem[threadIdx.x][threadIdx.y]; </span></span><br><span class="line">output[y2 * M + x2] = s_mem[threadIdx.x][threadIdx.x ^ threadIdx.y];  <span class="comment">// swizzling后，此处不存在bank conflict</span></span><br></pre></td></tr></table></figure>

<h3 id="实例：共享内存优化一维卷积"><a href="#实例：共享内存优化一维卷积" class="headerlink" title="实例：共享内存优化一维卷积"></a>实例：共享内存优化一维卷积</h3><p>卷积是一种数组操作，每个输出元素都是<strong>周围输入元素的加权总和</strong>。权重是由一个输入掩码数组也叫卷积核（convolution kernel）确定的。下面卷积计算都默认padding。<br>一维卷积图例：N是输入数组，M是卷积核，P是输出数组<br><img src="/CUDA%E7%AC%94%E8%AE%B0%E2%80%94%E2%80%94%E5%85%B1%E4%BA%AB%E5%86%85%E5%AD%98%E5%92%8Cbank%20conflict/img-CUDA%E7%AC%94%E8%AE%B0%E2%80%94%E2%80%94%E5%85%B1%E4%BA%AB%E5%86%85%E5%AD%98-8.png"><br>超出范围的元素当0计算<br><img src="/CUDA%E7%AC%94%E8%AE%B0%E2%80%94%E2%80%94%E5%85%B1%E4%BA%AB%E5%86%85%E5%AD%98%E5%92%8Cbank%20conflict/img-CUDA%E7%AC%94%E8%AE%B0%E2%80%94%E2%80%94%E5%85%B1%E4%BA%AB%E5%86%85%E5%AD%98-2.png"></p>
<h4 id="朴素实现"><a href="#朴素实现" class="headerlink" title="朴素实现"></a>朴素实现</h4><ul>
<li>N 为输入数组。 </li>
<li>M 为卷积核。 </li>
<li>P 为输出数组。 </li>
<li>Mask_Width 为卷积核尺寸,默认是奇数。 </li>
<li>Width 为输入输出数组长度。</li>
</ul>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">__global__ <span class="type">void</span> <span class="title function_">convolution_1D_basic_kernel</span><span class="params">(<span class="type">float</span> *N, <span class="type">float</span> *M, <span class="type">float</span> *P, <span class="type">int</span> Mask_Width, <span class="type">int</span> Width)</span>;  </span><br><span class="line">&#123;</span><br><span class="line">	<span class="type">int</span> radius=Mask_Width/<span class="number">2</span>;</span><br><span class="line">	<span class="type">int</span> id=blockDim.x*blockIdx.x+threadIdx.x;</span><br><span class="line">	<span class="type">int</span> start_pos=id-radius;</span><br><span class="line">	<span class="type">int</span> sum=<span class="number">0</span>;</span><br><span class="line">	<span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;Mask_Width;i++)&#123;     <span class="comment">//卷积核当前下标</span></span><br><span class="line">		<span class="type">int</span> cur_pos=start_pos+i;       <span class="comment">//输入数组当前下标</span></span><br><span class="line">		<span class="keyword">if</span>(cur_pos&gt;=<span class="number">0</span> &amp;&amp; cur_pos&lt;Width)&#123;</span><br><span class="line">			sum+=N[cur_pos]*M[i];</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	P[id]=sum;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="共享内存优化"><a href="#共享内存优化" class="headerlink" title="共享内存优化"></a>共享内存优化</h4><p>卷积核M数组尺寸小、内容不变、所有线程都以相同顺序访问，天然适合常量数组<br>输入数组每个元素平均重复访问的次数为卷积核大小Mask_Width，适合使用共享数组<br>	- 使用共享数组就要以block为单位思考，发现不论block多大，都需要多用到Mask_Width-1的边缘数据<br>	- <strong>难点</strong>：<strong>如何加载边缘数据</strong>？可以使用线程交叉加载的方式，后radius的线程加载前radius个元素（假设radius&lt;blockDim)，其实就是将block左平移一个块，对应的线程就加载对应的边缘数据， 另一半也是一样的方法</p>
<p><img src="/CUDA%E7%AC%94%E8%AE%B0%E2%80%94%E2%80%94%E5%85%B1%E4%BA%AB%E5%86%85%E5%AD%98%E5%92%8Cbank%20conflict/img-CUDA%E7%AC%94%E8%AE%B0%E2%80%94%E2%80%94%E5%85%B1%E4%BA%AB%E5%86%85%E5%AD%98-2%201.png"></p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">__constant__  <span class="type">float</span> M[MAX_MASK_WIDTH]</span><br><span class="line">cudaMemcpyToSymbol(M,h_M,Mask_Width*<span class="keyword">sizeof</span>(<span class="type">float</span>));</span><br><span class="line"></span><br><span class="line">__global__ <span class="type">void</span> <span class="title function_">convolution_1D_basic_kernel</span><span class="params">(<span class="type">float</span> *N, <span class="type">float</span> *P, <span class="type">int</span> Mask_Width, <span class="type">int</span> Width)</span>;  </span><br><span class="line">&#123;</span><br><span class="line">	<span class="type">int</span> radius=Mask_Width/<span class="number">2</span>;</span><br><span class="line">	__shared__ <span class="type">float</span> Ns[blockDim.x+<span class="number">2</span>*radius];</span><br><span class="line"></span><br><span class="line">	<span class="type">int</span> id=blockDim.x*blockIdx.x+threadIdx.x;</span><br><span class="line"></span><br><span class="line">	<span class="type">int</span> left=(blockDim.x<span class="number">-1</span>)*blockIdx.x+threadIdx.x;   <span class="comment">//平移到左边对应在N的id,如果该块是一个块则left小于0	</span></span><br><span class="line">	<span class="keyword">if</span>(threadId.x&gt;=blockDim.x-radius).     <span class="comment">//思考为什么左边缘数据对应Ns的下标是threadId.x-（blockDim.x-radius）</span></span><br><span class="line">		Ns[threadIdx.x-blockDim.x+radius]=(left&lt;<span class="number">0</span>) <span class="number">0</span> ? N[left];   <span class="comment">//左边载入Ns</span></span><br><span class="line">	Ns[radius+threadIdx.x]=N[id];       <span class="comment">//载入中间元素</span></span><br><span class="line"></span><br><span class="line">	<span class="type">int</span> right=(blockDim.x+<span class="number">1</span>)*blockIdx.x+threadIdx.x;   <span class="comment">//平移到左边对应在N的id,如果该块是最后块则right大于等于Width	</span></span><br><span class="line">	<span class="keyword">if</span>(threadId.x&lt;radius).     <span class="comment">//思考为什么是小于radius</span></span><br><span class="line">		Ns[threadIdx.x+blockDim.x+radius]=(right&gt;=Width) <span class="number">0</span> ? N[right];   <span class="comment">//载入右边Ns	</span></span><br><span class="line">	__syncthreads();</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">	<span class="type">int</span> sum=<span class="number">0</span>;</span><br><span class="line">	<span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;Mask_Width;i++)&#123;     <span class="comment">//卷积核当前下标</span></span><br><span class="line">		sum+=Ns[threadIdx.x+i]*M[i];</span><br><span class="line">	&#125;</span><br><span class="line">	P[id]=sum;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>访存次数对比：</strong></p>
<ul>
<li>所以对于内部线程块，基本算法与分快算法的访存次数比值为：<br>  ( blockDim.x*(2n+1) )&#x2F;(blockDim.x+2n) </li>
<li>对于边缘线程块，比值为：<br>  ( (blockDim.x*(2n+1) - n(n+1)&#x2F;2 )&#x2F;(blockDim.x+n) <br>如果blockDim.x 的值比n大的多，那么就近似为：2n+1&#x3D;Mask_Width</li>
</ul>

      </div>
    </div>
    
      <script src='https://unpkg.com/mermaid@latest/dist/mermaid.min.js'></script>
      <script>
        if (window.mermaid) {
          mermaid.initialize({"startOnload":true});
        }
      </script>
    
  </article>
  <div class="post__foot">
    
      <div class="like-author">
  <input type="checkbox" id="likeCode" />
  <div class="author-face">
    <img height="100px"
         width="100px"
         id="front-face"
         alt="author face"
         src="/assets/author-face.jpg" />
    <img height="100px"
         width="100px"
         id="back-face"
         alt="like code"
         src="/assets/pay-code.jpg" />
  </div>
  <div class="like-text">“给作者倒杯卡布奇诺”</div>
  <label for="likeCode" class="like-btn">
    <svg viewBox="0 0 1024 1024"
         width="20px"
         style="margin-right: 10px"
         height="20px">
      <path d="M466.88 908.96L113.824 563.296a270.08 270.08 0 0 1 0-387.392c108.8-106.56 284.896-106.56 393.696 0 1.504 1.472 2.976 2.944 4.448 4.48 1.472-1.536 2.944-3.008 4.448-4.48 108.8-106.56 284.896-106.56 393.696 0a269.952 269.952 0 0 1 34.016 347.072l-387.392 385.6a64 64 0 0 1-89.92 0.384z" p-id="13650" fill="#ee4242" />
    </svg>
    喜欢作者
  </label>
</div>

    
    <div class="post-nav">
  
    <a class="post-nav-item-left" href="/2024/11/16/note/cuda/CUDA%E7%AC%94%E8%AE%B0%E2%80%94%E2%80%94%E6%B5%81%E4%B8%8E%E5%BC%82%E6%AD%A5%E5%B9%B6%E8%A1%8C%EF%BC%88%E4%B8%80%EF%BC%89/">
      <div class="text-align">
        <svg t="1670570876164"
             class="icon"
             viewBox="0 0 1024 1024"
             width="16"
             height="16">
          <path d="M384 512L731.733333 202.666667c17.066667-14.933333 19.2-42.666667 4.266667-59.733334-14.933333-17.066667-42.666667-19.2-59.733333-4.266666l-384 341.333333c-10.666667 8.533333-14.933333 19.2-14.933334 32s4.266667 23.466667 14.933334 32l384 341.333333c8.533333 6.4 19.2 10.666667 27.733333 10.666667 12.8 0 23.466667-4.266667 32-14.933333 14.933333-17.066667 14.933333-44.8-4.266667-59.733334L384 512z" p-id="14596" />
        </svg>
        <span class="text-small">上一篇</span>
      </div>
      <div>CUDA笔记——流与异步并行（一）</div>
    </a>
  
  <div class="vhr"></div>
  
    <a class="post-nav-item-right" href="/2024/09/10/note/c++%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%A4%9A%E6%80%81%E4%B8%8E%E8%99%9A%E5%87%BD%E6%95%B0/">
      <div class="text-align">
        <span class="text-small">下一篇</span>
        <svg t="1670570876164"
             class="icon"
             viewBox="0 0 1024 1024"
             transform="scale(-1,-1)"
             width="16"
             height="16">
          <path d="M384 512L731.733333 202.666667c17.066667-14.933333 19.2-42.666667 4.266667-59.733334-14.933333-17.066667-42.666667-19.2-59.733333-4.266666l-384 341.333333c-10.666667 8.533333-14.933333 19.2-14.933334 32s4.266667 23.466667 14.933334 32l384 341.333333c8.533333 6.4 19.2 10.666667 27.733333 10.666667 12.8 0 23.466667-4.266667 32-14.933333 14.933333-17.066667 14.933333-44.8-4.266667-59.733334L384 512z" p-id="14596" />
        </svg>
      </div>
      c++学习笔记——多态与虚函数
    </a>
  
</div>

    
    
  </div>

    </div>
    <div class="foot">
  <div class="foot-inner">
    <div class="foot__head">
      
        <div class="foot-line">
          <div class="matts">海</div><div class="matts">内</div><div class="matts">存</div><div class="matts">知</div><div class="matts">己</div>
        </div>
      
        <div class="foot-line">
          <div class="matts">天</div><div class="matts">涯</div><div class="matts">若</div><div class="matts">比</div><div class="matts">邻</div>
        </div>
      
    </div>
    <div class="foot__body">
      
      
        <div class="foot-item">
          <div class="foot-item__head">账号</div>
          <div class="foot-item__body">
            


  
  
    <div class="foot-link-group">
      
        
        
          <div class="text">
            <img alt="link"
                 height="20px"
                 width="20px"
                 src="/images/logo-github.svg" />
            <a class="foot-link" target="_blank" rel="noopener" href="https://github.com/Felt98">Felt's Github</a>
          </div>
        
      
        
        
          <div class="text">
            <img alt="link"
                 height="20px"
                 width="20px"
                 src="/images/logo-zh.svg" />
            <a class="foot-link" target="_blank" rel="noopener" href="https://www.zhihu.com/people/yi-ming-81-1">Felt</a>
          </div>
        
      
        
        
      
        
        
      
    </div>
  


          </div>
        </div>
      
      <div class="foot-item">
        <div class="foot-item__head">联系</div>
        <div class="foot-item__body">
          


  
  
    <div class="foot-link-group">
      
        
        
          <div class="text">
            <img alt="link"
                 height="20px"
                 width="20px"
                 src="/images/icon/icon-email.svg" />
            <a class="foot-link" href="mailto:haoqingqin@gmail.com">haoqingqin@gmail.com</a>
          </div>
        
      
        
        
      
        
        
      
        
        
      
    </div>
  


        </div>
      </div>
    </div>
    <div class="copyright">
      <a href="http://example.com">Felt's blog</a> &nbsp;|&nbsp;由&nbsp;<a target="_blank" rel="noopener" href="https://hexo.io/">Hexo</a>&nbsp;及&nbsp;
      <svg width="20" height="20" viewBox="0 0 725 725">
        <path fill-rule="evenodd" fill="rgb(221, 221, 221)" d="M145.870,236.632 L396.955,103.578 L431.292,419.44 L156.600,522.53 L145.870,236.632 Z" />
        <path fill-rule="evenodd" fill="rgb(159, 159, 159)" d="M396.955,103.578 L564.345,234.486 L611.558,513.469 L431.292,419.44 L396.955,103.578 Z" />
        <path fill-rule="evenodd" fill="rgb(0, 0, 0)" d="M431.292,419.44 L611.558,513.469 L358.327,595.18 L156.600,522.53 L431.292,419.44 Z" />
      </svg>
      <a target="_blank" rel="noopener" href="https://github.com/hooozen/hexo-theme-tranquility">致远</a>&nbsp;驱动
    </div>
  </div>
</div>

    
    
      <script src="/js/search.js"></script>
      <script>searchInitialize("/search.json")</script>
    
    <script src="/js/copy-code.js"></script>
    
  

  </body>
</html>
