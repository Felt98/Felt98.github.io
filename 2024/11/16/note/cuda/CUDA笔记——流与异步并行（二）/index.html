<!DOCTYPE html>
<html lang="zh-cn">
  <head>
    <meta charset="utf8" />
    <meta name="viewport" content="initial-scale=1.0, width=device-width" />
    <title>
      
        CUDA笔记——流与异步并行（二） | Felt's blog
      
    </title>
    <meta name="description" content="" />
    <meta name="keywords" content="" />
    
      <link rel="apple-touch-icon"
            sizes="180x180"
            href="/images/apple-touch-icon.png" />
    
    
      <link rel="icon"
            type="image/png"
            sizes="32x32"
            href="/images/favicon-32x32.png" />
    
    
      <link rel="icon"
            type="image/png"
            sizes="16x16"
            href="/images/favicon-16x16.png" />
    
    
      <link rel="mask-icon"
            href="/images/logo.svg"
            color="" />
    
    
    
      
  <style>
    @font-face {
        font-family:sourceHanSerif;
        src: url(/font/normal.ttf);
        font-weight: normal;
    }
  </style>

  <style>
    @font-face {
        font-family:sourceHanSerif;
        src: url(/font/bold.ttf);
        font-weight: bold;
    }
  </style>


    
    <link rel="stylesheet"
          type="text/css"
          href='/css/layout.css' />
    
    
  <link rel="stylesheet" type="text/css" href="/css/post.css"/>
  

  <meta name="generator" content="Hexo 7.3.0"></head>
  <body>
    
      <div id="search-mask" style="display:none">
  <div class="search-main" id="search-main">
    <div class="search__head">
      <div class="search-form">
        <svg t="1706347533072"
             class="icon"
             viewBox="0 0 1024 1024"
             version="1.1"
             xmlns="http://www.w3.org/2000/svg"
             p-id="7828"
             width="20"
             height="20">
          <path d="M685.6 660.336l155.152 155.168a16 16 0 0 1 0 22.624l-11.312 11.328a16 16 0 0 1-22.624 0l-158.528-158.544a289.792 289.792 0 0 1-165.152 51.36C322.336 742.256 192 611.904 192 451.12 192 290.336 322.336 160 483.136 160c160.784 0 291.12 130.336 291.12 291.136 0 82.112-33.984 156.272-88.672 209.2z m-202.464 33.92c134.272 0 243.12-108.848 243.12-243.12C726.256 316.848 617.408 208 483.136 208 348.848 208 240 316.848 240 451.136c0 134.272 108.848 243.12 243.136 243.12z" fill="#000000" p-id="7829">
          </path>
        </svg>
        <input id="search-input" placeholder="搜索文章">
        <svg t="1706361500528"
             id="search-clear"
             class="icon"
             viewBox="0 0 1024 1024"
             version="1.1"
             xmlns="http://www.w3.org/2000/svg"
             p-id="4351"
             width="20"
             height="20">
          <path d="M512 562.688l-264.2944 264.2944-50.688-50.688L461.312 512 197.0176 247.7056l50.688-50.688L512 461.312l264.2944-264.2944 50.688 50.688L562.688 512l264.2944 264.2944-50.688 50.688L512 562.688z" fill="#00" p-id="4352">
          </path>
        </svg>
      </div>
    </div>
    <div class="search__body" id="search-result"></div>
    <div class="search__foot"></div>
  </div>
</div>

    
    
    <div class=head>
      <div class="nav">
        <a href='/' class="nav-logo">
          <img alt="logo" height="60px" width="60px" src="/images/logo.svg" />
        </a>
        <input id="navBtn" type="checkbox" />
        <div class="nav-right">
          
            <div class="search-outer">
  <div class="search" id="search-btn">
    <svg t="1706347533072"
         class="icon"
         viewBox="0 0 1024 1024"
         version="1.1"
         xmlns="http://www.w3.org/2000/svg"
         p-id="7828"
         width="20"
         height="20">
      <path d="M685.6 660.336l155.152 155.168a16 16 0 0 1 0 22.624l-11.312 11.328a16 16 0 0 1-22.624 0l-158.528-158.544a289.792 289.792 0 0 1-165.152 51.36C322.336 742.256 192 611.904 192 451.12 192 290.336 322.336 160 483.136 160c160.784 0 291.12 130.336 291.12 291.136 0 82.112-33.984 156.272-88.672 209.2z m-202.464 33.92c134.272 0 243.12-108.848 243.12-243.12C726.256 316.848 617.408 208 483.136 208 348.848 208 240 316.848 240 451.136c0 134.272 108.848 243.12 243.136 243.12z" fill="#000000" p-id="7829">
      </path>
    </svg>
    <span>搜索</span>
    <span class="search-shortcut-key">Ctrl K</span>
  </div>
</div>

          
          <div class="nav-menu">
            
              
                <a class="nav-menu-item" href="/note">学习笔记</a>
              
                <a class="nav-menu-item" href="/project">项目</a>
              
            
            
          </div>
        </div>
        <label class="nav-btn" for="navBtn"></label>
      </div>
    </div>
    <div class="body">
      
  <article class="post-content">
    <div class="post-inner--toc">
      <div class="post-content__head">
        <div class="post-title">CUDA笔记——流与异步并行（二）</div>
        <div class="post-info">
          
  <a href="/tags/cuda/" class="post-tag">#cuda</a>


          <span class="post-date">2024-11-16</span>
        </div>
      </div>
      
        <aside class="toc-outer">
          <div class="toc-title">目录</div>
          <ol class="post-toc"><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#CUDA%E5%B9%B6%E8%A1%8C%E8%A1%8C%E4%B8%BA"><span class="post-toc-text">CUDA并行行为</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#%E5%86%85%E6%A0%B8%E5%B9%B6%E8%A1%8C%E6%89%A7%E8%A1%8C"><span class="post-toc-text">内核并行执行</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#%E6%95%B0%E6%8D%AE%E5%B9%B6%E8%A1%8C%E4%BC%A0%E8%BE%93-%E9%9C%80%E8%A6%81%E4%BD%BF%E7%94%A8%E9%94%81%E9%A1%B5%E5%86%85%E5%AD%98"><span class="post-toc-text">数据并行传输(需要使用锁页内存)</span></a></li></ol></li></ol></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#%E6%B5%81"><span class="post-toc-text">流</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#%E6%B5%81%E7%9A%84%E5%88%9B%E5%BB%BA%E5%92%8C%E9%94%80%E6%AF%81"><span class="post-toc-text">流的创建和销毁</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#%E9%BB%98%E8%AE%A4%E6%B5%81-Default-Stream"><span class="post-toc-text">默认流(Default Stream)</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#%E6%B5%81%E7%9A%84%E4%BC%98%E5%85%88%E7%BA%A7-Stream-Priorities"><span class="post-toc-text">流的优先级(Stream Priorities)</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#%E6%B5%81%E5%90%8C%E6%AD%A5"><span class="post-toc-text">流同步</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#%E5%9B%9E%E8%B0%83%E5%87%BD%E6%95%B0-Callbacks"><span class="post-toc-text">回调函数(Callbacks)</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#%E4%BA%8B%E4%BB%B6"><span class="post-toc-text">事件</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#%E5%A4%9A%E8%AE%BE%E5%A4%87%E4%B8%8B-%E6%B5%81%E5%92%8C%E4%BA%8B%E4%BB%B6%E7%9A%84%E6%89%A7%E8%A1%8C%E6%83%85%E5%86%B5"><span class="post-toc-text">(多设备下)流和事件的执行情况</span></a></li></ol></li></ol></li></ol>
          <a href="#" class="toc-top">回到顶部</a>
        </aside>
      
      <div class="post-content__body">
        
          <div class="post-gallery">
            
          </div>
        
        <h2 id="CUDA并行行为"><a href="#CUDA并行行为" class="headerlink" title="CUDA并行行为"></a>CUDA并行行为</h2><p>CUDA允许以下操作异步并行：  </p>
<ul>
<li><em>主机端计算</em> </li>
<li>设备端计算(内核执行) </li>
<li><em>主机端to设备端传数据</em> </li>
<li>设备端to主机端传数据 </li>
<li><em>设备端内部传数据</em> </li>
<li>设备间传数据(可通过PCI-E直接传输，不需要先传到主机端再转发，<em>不过这一操作跟使用的操作系统有关</em>)</li>
</ul>
<p>device与host并行的行为：</p>
<ol>
<li>内核启动与执行(可以通过将<code>CUDA_LAUNCH_BLOCKING</code>设为1，来禁止内核执行并行，debug使用)</li>
<li>设备端内部传输数据 <em>64KB及以下的 host-to-device数据传输</em> <ul>
<li>在使用<code>cudaMemcpy()</code>时，如果数据小于等于64KB，其实传输相对于CPU是异步的。 如果数据多于64KB，则CPU会阻塞到数据传输完成。</li>
</ul>
</li>
<li>使用流(带有<code>Async</code>前缀的内存传输函数)或内存映射传输数据（不再受64KB的限制）<ul>
<li>使用<code>Async</code>传输函数，不仅可以和CPU并行，而且可以和内核执行并行。</li>
<li>如果没有使用锁页内存，即使使用了<code>Async</code>函数，内存传输也不是并行的</li>
</ul>
</li>
<li>设备端memset函数(<code>cudaMemset()</code>)</li>
</ol>
<h4 id="内核并行执行"><a href="#内核并行执行" class="headerlink" title="内核并行执行"></a>内核并行执行</h4><p>计算能力2.x及以上的设备，支持多个内核函数同时执行。(可以通过检查<code>concurrentKernels</code>来确定)</p>
<ul>
<li><strong>执行多个内核函数，需要主机端不同的线程启动。如果一个线程依次启动多个内核，则这些内核会串行执行。同一线程的内核函数返回时会触发隐式的同步。</strong></li>
<li>另外，多个内核函数必须位于同一个CUDA上下文(CUDA context)上。不同CUDA上下文上的内核不能并行。这意味着，启动多个内核的多个线程必须使用相同的CUDA上下文。(<em>如何传递CUDA上下文？</em>)</li>
</ul>
<h4 id="数据并行传输-需要使用锁页内存"><a href="#数据并行传输-需要使用锁页内存" class="headerlink" title="数据并行传输(需要使用锁页内存)"></a>数据并行传输(需要使用锁页内存)</h4><ul>
<li>计算能力2.x及以上的设备，支持数据传入和传出并行。</li>
<li>一些设备支持数据传输(主机端&#x2F;设备端、设备端&#x2F;设备端)和内核执行并行，可通过检查<code>asyncEngineCount</code>来确认。</li>
<li>必须使用锁页内存。</li>
</ul>
<h2 id="流"><a href="#流" class="headerlink" title="流"></a>流</h2><p>在CUDA中，<strong>流(streams)</strong> 指的是在GPU上一连串执行的命令的操作队列，可以将其理解为数据的流动。CUDA通过流管理上面的并发操作。</p>
<ul>
<li>不同的线程，可以向同一个流填入任务。</li>
<li><strong>同一个流内的任务的执行是顺序和同步的</strong>；</li>
<li>同一设备上<strong>不同的流可以并行</strong>，其执行顺序不会有保证（当然是在GPU资源够用的情况下并行，不够用的话流就得排队了）<ul>
<li>CUDA流可以看作是一条<strong>命令流水线</strong>，每个CUDA流都有自己的计算资源，包括寄存器、共享内存、全局内存等，这些资源是独立的，不同流之间不会相互干扰。<br><img src="https://img-blog.csdnimg.cn/img_convert/87a785793d1839f95711d4484a38f9f0.png" alt="CUDA stream 与 CUDA event 详解_cudastreamwaitevent-CSDN博客"></li>
</ul>
</li>
<li><strong>多个流启动不同的内核函数</strong>，就实现了单GPU的网格级的并行</li>
</ul>
<p>要实现流操作，有四个条件：</p>
<ol>
<li>GPU设备支持设备重叠功能(device overlap)</li>
<li>主机内存应被分配为锁页内存<code>pinned memory</code>，并使用使用锁页内存传输数据。</li>
<li>在主机和 GPU 之间传输数据而不阻塞主机进程(cudaMemcpyAsync() 函数)。</li>
<li>将每个操作放到不同的 CUDA 流中管理，以实现并发操作。</li>
</ol>
<h4 id="流的创建和销毁"><a href="#流的创建和销毁" class="headerlink" title="流的创建和销毁"></a>流的创建和销毁</h4><p>下述代码是一个流的创建和销毁的例子。该程序创建了两个流，分配了两个锁页内存传输数据，依次启动了两个内核，最后销毁了这两个流。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">cudaStream_t stream[<span class="number">2</span>];     <span class="comment">//创建流</span></span><br><span class="line"><span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; <span class="number">2</span>; ++i)</span><br><span class="line">    cudaStreamCreate(&amp;stream[i]);    <span class="comment">//初始化流</span></span><br><span class="line"><span class="type">float</span>* hostPtr;</span><br><span class="line">cudaMallocHost(&amp;hostPtr, <span class="number">2</span> * size);  <span class="comment">//锁页内存</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; <span class="number">2</span>; ++i) &#123;  <span class="comment">//如果设备支持数据传输和内核执行并行，那么下面数据传输和两个流启动的内核是可以并行的；不支持的话就是串行</span></span><br><span class="line">    cudaMemcpyAsync(inputDevPtr + i * size, hostPtr + i * size,</span><br><span class="line">                    size, cudaMemcpyHostToDevice, stream[i]);  <span class="comment">//与普通的cudaMemcpy区别是:配合流使用异步数据传输，数据传输在后台copy引擎进行，不阻塞主机线程。要求是锁页内存</span></span><br><span class="line">                <span class="comment">//cudaMemcpy是同步，调用时会阻塞主机线程，直到数据传输完成。</span></span><br><span class="line">    MyKernel &lt;&lt;&lt;<span class="number">100</span>, <span class="number">512</span>, <span class="number">0</span>, stream[i]&gt;&gt;&gt;   </span><br><span class="line">        (outputDevPtr + i * size, inputDevPtr + i * size, size);  <span class="comment">//使用流执行内核</span></span><br><span class="line">    cudaMemcpyAsync(hostPtr + i * size, outputDevPtr + i * size,</span><br><span class="line">                    size, cudaMemcpyDeviceToHost, stream[i]);</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//for循环结束后,主机继续执行下面的代码，不会去等待上面的任何异步操作（当然同一个流中任务的执行是同步的，这样代码才执行正确）</span></span><br><span class="line">......</span><br><span class="line"><span class="comment">//同步主机和流。同步后才能释放内存</span></span><br><span class="line"><span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; <span class="number">2</span>; ++i)</span><br><span class="line">	cudaStreamSynchronize(stream[i]);</span><br><span class="line"><span class="comment">//释放内存</span></span><br><span class="line">cudaFreeHost(hostPtr);    </span><br><span class="line"><span class="comment">//销毁流，但会在流执行完毕后回收</span></span><br><span class="line"><span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; <span class="number">2</span>; ++i)</span><br><span class="line">    cudaStreamDestroy(stream[i]);</span><br></pre></td></tr></table></figure>

<p>流的创建需要定义<code>cudaStream_t</code>结构，并调用<code>cudaStreamCreate()</code>来初始化。<br>流的销毁需要调用<code>cudaStreamDestroy()</code>来实现。</p>
<p>当向流中添加内核函数任务时，不再是<code>&lt;&lt;&lt;blocksPerGrid, threadsPerBlock&gt;&gt;&gt;</code>，而是<code>&lt;&lt;&lt;blocksPerGrid, threadsPerBlock, dynamic_shared_memory, stream&gt;&gt;&gt;</code>。<br>	其中dynamic_shared_memory指的是动态共享内存的大小(<em>回去翻书</em>)； stream就是<code>cudaStream_t</code>结构。</p>
<p>当设备还在执行流中的任务，而用户调用<code>cudaStreamDestroy()</code>函数时，会等待当流中的任务完成后，与流相关的资源会自动释放。</p>
<p><strong>另外需要注意的是，上例中主机端线程、数据拷贝和内核执行完全异步，因此在”拷贝回主机端”这一操作完成之前，主机端的内存数据是不正确的。必须在数据返回的一步做同步操作，方能保证数据是正确的。</strong></p>
<h4 id="默认流-Default-Stream"><a href="#默认流-Default-Stream" class="headerlink" title="默认流(Default Stream)"></a>默认流(Default Stream)</h4><p>在调用内核函数时，不指定流或者将流指定为0，则代表使用了默认流(default stream)。<br>也就是说cuda任务的执行都是在流中进行。</p>
<p>如果在编译时使用了<code>--default-stream per-thread</code>，或是在include任何cuda头文件前<code>#define CUDA_API_PER_THREAD_DEFAULT_STREAM</code>，则主机端的每一个线程都有自己专属的默认流。<br>而如果在编译时未指定相关flag，或指定<code>--default-stream legacy</code>，则默认流是一个特殊的流，称作NULL stream。主机端的所有线程会共享这个NULL stream。NULL stream是一个同步流，所有命令会产生隐式同步。</p>
<h4 id="流的优先级-Stream-Priorities"><a href="#流的优先级-Stream-Priorities" class="headerlink" title="流的优先级(Stream Priorities)"></a>流的优先级(Stream Priorities)</h4><p>可以通过<code>cudaStreamCreateWithPriority()</code>来在创建流时指定流的优先级。可以指定的优先级可由<code>cudaDeviceGetStreamPriorityRange()</code>来获得。</p>
<p>运行时，高优先级stream中的线程块不能打断正在执行的低优先级stream的线程块(即不是抢占式的)。但是当低优先级stream的线程块退出SM时，高优先级stream中的线程块会被优先调度进SM。</p>
<h4 id="流同步"><a href="#流同步" class="headerlink" title="流同步"></a>流同步</h4><p>显式同步：<br><code>cudaDeviceSynchronize()</code>：直到<strong>所有线程</strong>向设备端的<strong>所有流</strong>的<strong>所有已送入指令</strong>完成，才会退出阻塞。<br><code>cudaStreamSynchronize()</code>：直到<strong>指定流</strong>的<strong>之前所有已送入指令</strong>完成，才会退出阻塞。此函数可以用作同步指定流，而其他流可以不受干扰地继续运行。  <br><code>cudaStreamWaitEvent()</code>：需要stream和event作为输入参数。在调用该函数之后的命令，需要等待该函数等待的事件(Event)发生后，才能执行。如果stream指定为0，则对于向所有stream加入的命令来说，只要加在了该函数之后，都会阻塞直到等待的时间发生方可执行。(不知道我理解的对不对：如果是Event-&gt;内核1-&gt;WaitEvent-&gt;内核2，则内核1不用等到Event发生就可以执行，而内核2必须等到Event发生才能执行。还是说内核1其实只有等待Event发生后才会执行？) (如果多个线程向同一个流压入了任务，然后线程0调用了cudaStreamWaitEvent()，则线程1会不会被阻塞？线程1压入的任务会不会被阻塞？) <br><code>cudaStreamQuery()</code>：查询流内所有压入的指令(preceding commands)是否全部完成。</p>
<p>注意，同步函数慎用，因为有可能会产生速度的下降。</p>
<p>隐时同步：不同流可以并行。但是当任何一个流执行如下的命令时，情况例外，不能并行：<br>	锁页内存的分配，设备端内存分配 ，设备端内存设置(memset)，设备内部拷贝 ，NULL stream内的命令， L1 cache｜共享内存空间的重新分配</p>
<h4 id="回调函数-Callbacks"><a href="#回调函数-Callbacks" class="headerlink" title="回调函数(Callbacks)"></a>回调函数(Callbacks)</h4><p><code>cudaStreamAddCallback()</code>函数，向流中添加callback。callback会在流中所有的任务完成后被调用。<br>	如果stream参数设为0，则代表之前的所有stream的任务执行完后就调用该callback。<br>	和<code>cudaStreamWaitEvent()</code>一样，对于在加在callback之后的指令，必须等待callback执行完成后，才会继续执行。<br>	<br>下例是一个使用回调的例子。该例中，两个stream将数据拷回主机端后，会调用回调函数。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> CUDART_CB <span class="title">MyCallback</span><span class="params">(cudaStream_t stream, cudaError_t status, <span class="type">void</span> *data)</span></span>&#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Inside callback %d\n&quot;</span>, (<span class="type">size_t</span>)data);</span><br><span class="line">&#125;</span><br><span class="line">...</span><br><span class="line"><span class="keyword">for</span> (<span class="type">size_t</span> i = <span class="number">0</span>; i &lt; <span class="number">2</span>; ++i) &#123;</span><br><span class="line">    <span class="built_in">cudaMemcpyAsync</span>(devPtrIn[i], hostPtr[i], size, cudaMemcpyHostToDevice, stream[i]);</span><br><span class="line">    MyKernel&lt;&lt;&lt;<span class="number">100</span>, <span class="number">512</span>, <span class="number">0</span>, stream[i]&gt;&gt;&gt;(devPtrOut[i], devPtrIn[i], size);</span><br><span class="line">    <span class="built_in">cudaMemcpyAsync</span>(hostPtr[i], devPtrOut[i], size, cudaMemcpyDeviceToHost, stream[i]);</span><br><span class="line">    <span class="comment">//调用回调函数MyCallback</span></span><br><span class="line">    <span class="built_in">cudaStreamAddCallback</span>(stream[i], MyCallback, (<span class="type">void</span>*)i, <span class="number">0</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>注意：回调函数中不能直接或间接的执行CUDA函数，否则会因为等待自己完成而造成死锁。</p>
<h4 id="事件"><a href="#事件" class="headerlink" title="事件"></a>事件</h4><p>事件(Event)可以被压入流中以监视流的运行情况，或者用于精确计时。有点像专用于流的printf</p>
<p>如果向stream 0压入事件，则当压入事件前向所有流压入的任务完成后，事件才被触发。</p>
<p>创建和销毁：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">cudaEvent_t start, stop;    <span class="comment">//创建</span></span><br><span class="line"><span class="built_in">cudaEventCreate</span>(&amp;start);</span><br><span class="line"><span class="built_in">cudaEventCreate</span>(&amp;stop);</span><br><span class="line">...</span><br><span class="line"><span class="built_in">cudaEventDestroy</span>(start);    <span class="comment">//销毁</span></span><br><span class="line"><span class="built_in">cudaEventDestroy</span>(stop);</span><br></pre></td></tr></table></figure>

<p>使用Event计算时间的例子</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cudaEventRecord</span>(start, <span class="number">0</span>);  <span class="comment">//记录事件(将事件压入流)，流0则代表所有流完成任务后事件才会被触发</span></span><br><span class="line"><span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; <span class="number">2</span>; ++i) &#123;</span><br><span class="line">    <span class="built_in">cudaMemcpyAsync</span>(inputDev + i * size, inputHost + i * size, size, cudaMemcpyHostToDevice, stream[i]);</span><br><span class="line">    MyKernel&lt;&lt;&lt;<span class="number">100</span>, <span class="number">512</span>, <span class="number">0</span>, stream[i]&gt;&gt;&gt;(outputDev + i * size, inputDev + i * size, size);</span><br><span class="line">    <span class="built_in">cudaMemcpyAsync</span>(outputHost + i * size, outputDev + i * size, size, cudaMemcpyDeviceToHost, stream[i]);</span><br><span class="line">&#125;</span><br><span class="line"><span class="built_in">cudaEventRecord</span>(stop, <span class="number">0</span>);</span><br><span class="line"><span class="built_in">cudaEventSynchronize</span>(stop);</span><br><span class="line"><span class="type">float</span> elapsedTime;</span><br><span class="line"><span class="built_in">cudaEventElapsedTime</span>(&amp;elapsedTime, start, stop);    <span class="comment">//获取两个事件发生的时间差(ms)</span></span><br></pre></td></tr></table></figure>



<h4 id="多设备下-流和事件的执行情况"><a href="#多设备下-流和事件的执行情况" class="headerlink" title="(多设备下)流和事件的执行情况"></a>(多设备下)流和事件的执行情况</h4><p>下面将讨论，如果对一个不属于当前设备的流或事件进行操作，哪些操作会成功，哪些操作会失败：</p>
<ul>
<li><strong>内核启动</strong>(will fail)：如果将内核压入不属于当前设备的流中，则内核会启动失败。也就是说，如果要向一个流中压入内核，必须先切换到流所在的设备：</li>
</ul>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cudaSetDevice</span>(<span class="number">0</span>);   <span class="comment">// Set device 0 as current</span></span><br><span class="line">cudaStream_t s0;</span><br><span class="line"><span class="built_in">cudaStreamCreate</span>(&amp;s0);  <span class="comment">// Create stream s0 on device 0</span></span><br><span class="line">MyKernel&lt;&lt;&lt;<span class="number">100</span>, <span class="number">64</span>, <span class="number">0</span>, s0&gt;&gt;&gt;(); <span class="comment">// Launch kernel on device 0 in s0</span></span><br><span class="line"><span class="built_in">cudaSetDevice</span>(<span class="number">1</span>);   <span class="comment">// Set device 1 as current</span></span><br><span class="line">cudaStream_t s1;</span><br><span class="line"><span class="built_in">cudaStreamCreate</span>(&amp;s1);  <span class="comment">// Create stream s1 on device 1</span></span><br><span class="line">MyKernel&lt;&lt;&lt;<span class="number">100</span>, <span class="number">64</span>, <span class="number">0</span>, s1&gt;&gt;&gt;(); <span class="comment">// Launch kernel on device 1 in s1</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// This kernel launch will fail:内核启动是向未与当前设备关联的流发出的，即流s0与设备1无关，启动失败</span></span><br><span class="line">MyKernel&lt;&lt;&lt;<span class="number">100</span>, <span class="number">64</span>, <span class="number">0</span>, s0&gt;&gt;&gt;(); <span class="comment">// Launch kernel on device 1 in s0</span></span><br></pre></td></tr></table></figure>

<ul>
<li><strong>内存拷贝</strong>(will success)：如果对一个不属于当前设备的流进行内存拷贝工作，内存拷贝会成功。</li>
<li><strong>cudaEventRecord()</strong>(will fail)：必须现将设备上下文切换过去，再向流压入事件。</li>
<li><strong>cudaEventElapsedTime()</strong>(will fail)：计算时间差前，必须先切换设备。</li>
<li><strong>cudaEventSynchronize() and cudaEventQuery()</strong>(will success)：即使处于不同的设备，事件同步和事件查询依然有效。</li>
<li><strong>cudaStreamWaitEvent()</strong>(will success)：比较特殊，即使函数输入的流和事件不在同一个设备上，也能成功执行。也就是说，可以让流等待另一个设备上(当然当前设备也可以)的事件。这个函数可以用作多个设备间的同步。</li>
</ul>
<p>另外需要注意，<strong>每个设备都有自己的默认流</strong>。因此在没有指定流的情况下，向不同设备分派的任务，实际上是压入了各个设备的默认流，他们之间是并行执行的。</p>

      </div>
    </div>
    
      <script src='https://unpkg.com/mermaid@latest/dist/mermaid.min.js'></script>
      <script>
        if (window.mermaid) {
          mermaid.initialize({"startOnload":true});
        }
      </script>
    
  </article>
  <div class="post__foot">
    
      <div class="like-author">
  <input type="checkbox" id="likeCode" />
  <div class="author-face">
    <img height="100px"
         width="100px"
         id="front-face"
         alt="author face"
         src="/assets/author-face.jpg" />
    <img height="100px"
         width="100px"
         id="back-face"
         alt="like code"
         src="/assets/pay-code.jpg" />
  </div>
  <div class="like-text">“给作者倒杯卡布奇诺”</div>
  <label for="likeCode" class="like-btn">
    <svg viewBox="0 0 1024 1024"
         width="20px"
         style="margin-right: 10px"
         height="20px">
      <path d="M466.88 908.96L113.824 563.296a270.08 270.08 0 0 1 0-387.392c108.8-106.56 284.896-106.56 393.696 0 1.504 1.472 2.976 2.944 4.448 4.48 1.472-1.536 2.944-3.008 4.448-4.48 108.8-106.56 284.896-106.56 393.696 0a269.952 269.952 0 0 1 34.016 347.072l-387.392 385.6a64 64 0 0 1-89.92 0.384z" p-id="13650" fill="#ee4242" />
    </svg>
    喜欢作者
  </label>
</div>

    
    <div class="post-nav">
  
    <a class="post-nav-item-left" href="/2024/11/24/note/cuda/CUDA%E7%AC%94%E8%AE%B0%E2%80%94%E2%80%94%E5%A4%9AGPU%E7%BC%96%E7%A8%8B/">
      <div class="text-align">
        <svg t="1670570876164"
             class="icon"
             viewBox="0 0 1024 1024"
             width="16"
             height="16">
          <path d="M384 512L731.733333 202.666667c17.066667-14.933333 19.2-42.666667 4.266667-59.733334-14.933333-17.066667-42.666667-19.2-59.733333-4.266666l-384 341.333333c-10.666667 8.533333-14.933333 19.2-14.933334 32s4.266667 23.466667 14.933334 32l384 341.333333c8.533333 6.4 19.2 10.666667 27.733333 10.666667 12.8 0 23.466667-4.266667 32-14.933333 14.933333-17.066667 14.933333-44.8-4.266667-59.733334L384 512z" p-id="14596" />
        </svg>
        <span class="text-small">上一篇</span>
      </div>
      <div>CUDA笔记——多GPU编程</div>
    </a>
  
  <div class="vhr"></div>
  
    <a class="post-nav-item-right" href="/2024/11/16/note/cuda/CUDA%E7%AC%94%E8%AE%B0%E2%80%94%E2%80%94%E6%B5%81%E4%B8%8E%E5%BC%82%E6%AD%A5%E5%B9%B6%E8%A1%8C%EF%BC%88%E4%B8%80%EF%BC%89/">
      <div class="text-align">
        <span class="text-small">下一篇</span>
        <svg t="1670570876164"
             class="icon"
             viewBox="0 0 1024 1024"
             transform="scale(-1,-1)"
             width="16"
             height="16">
          <path d="M384 512L731.733333 202.666667c17.066667-14.933333 19.2-42.666667 4.266667-59.733334-14.933333-17.066667-42.666667-19.2-59.733333-4.266666l-384 341.333333c-10.666667 8.533333-14.933333 19.2-14.933334 32s4.266667 23.466667 14.933334 32l384 341.333333c8.533333 6.4 19.2 10.666667 27.733333 10.666667 12.8 0 23.466667-4.266667 32-14.933333 14.933333-17.066667 14.933333-44.8-4.266667-59.733334L384 512z" p-id="14596" />
        </svg>
      </div>
      CUDA笔记——流与异步并行（一）
    </a>
  
</div>

    
    
  </div>

    </div>
    <div class="foot">
  <div class="foot-inner">
    <div class="foot__head">
      
        <div class="foot-line">
          <div class="matts">海</div><div class="matts">内</div><div class="matts">存</div><div class="matts">知</div><div class="matts">己</div>
        </div>
      
        <div class="foot-line">
          <div class="matts">天</div><div class="matts">涯</div><div class="matts">若</div><div class="matts">比</div><div class="matts">邻</div>
        </div>
      
    </div>
    <div class="foot__body">
      
      
        <div class="foot-item">
          <div class="foot-item__head">账号</div>
          <div class="foot-item__body">
            


  
  
    <div class="foot-link-group">
      
        
        
          <div class="text">
            <img alt="link"
                 height="20px"
                 width="20px"
                 src="/images/logo-github.svg" />
            <a class="foot-link" target="_blank" rel="noopener" href="https://github.com/Felt98">Felt's Github</a>
          </div>
        
      
        
        
          <div class="text">
            <img alt="link"
                 height="20px"
                 width="20px"
                 src="/images/logo-zh.svg" />
            <a class="foot-link" target="_blank" rel="noopener" href="https://www.zhihu.com/people/yi-ming-81-1">Felt</a>
          </div>
        
      
        
        
      
        
        
      
    </div>
  


          </div>
        </div>
      
      <div class="foot-item">
        <div class="foot-item__head">联系</div>
        <div class="foot-item__body">
          


  
  
    <div class="foot-link-group">
      
        
        
          <div class="text">
            <img alt="link"
                 height="20px"
                 width="20px"
                 src="/images/icon/icon-email.svg" />
            <a class="foot-link" href="mailto:haoqingqin@gmail.com">haoqingqin@gmail.com</a>
          </div>
        
      
        
        
      
        
        
      
        
        
      
    </div>
  


        </div>
      </div>
    </div>
    <div class="copyright">
      <a href="http://example.com">Felt's blog</a> &nbsp;|&nbsp;由&nbsp;<a target="_blank" rel="noopener" href="https://hexo.io/">Hexo</a>&nbsp;及&nbsp;
      <svg width="20" height="20" viewBox="0 0 725 725">
        <path fill-rule="evenodd" fill="rgb(221, 221, 221)" d="M145.870,236.632 L396.955,103.578 L431.292,419.44 L156.600,522.53 L145.870,236.632 Z" />
        <path fill-rule="evenodd" fill="rgb(159, 159, 159)" d="M396.955,103.578 L564.345,234.486 L611.558,513.469 L431.292,419.44 L396.955,103.578 Z" />
        <path fill-rule="evenodd" fill="rgb(0, 0, 0)" d="M431.292,419.44 L611.558,513.469 L358.327,595.18 L156.600,522.53 L431.292,419.44 Z" />
      </svg>
      <a target="_blank" rel="noopener" href="https://github.com/hooozen/hexo-theme-tranquility">致远</a>&nbsp;驱动
    </div>
  </div>
</div>

    
    
      <script src="/js/search.js"></script>
      <script>searchInitialize("/search.json")</script>
    
    <script src="/js/copy-code.js"></script>
    
  

  </body>
</html>
