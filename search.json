[{"title":"基于CUDA实现彩色圆形渲染器","url":"/2025/03/27/project/基于CUDA实现彩色圆形渲染器/","content":"## 概述\n本文根据 CMU15418-Assignment2，基于CUDA实现了一个简单的彩色圆形渲染器，能够加速彩色圆在空白图像上的渲染。\n目前可以渲染 bouncingballs, fireworks, hypnosis, snow等四幅动画图像。\n\n项目地址：https://github.com/Felt98/Simple-Parallel-Color-Circular-Renderer\n\n**运行环境**：\n- 操作系统：Ubuntu 22.04.3 LTS\n- 显卡：NVIDIA A100-SXM4-80GB\n- CUDA 版本：11.8\n\n## 渲染器类\n\n### 渲染器类设计\ncuda圆形渲染器类设计如下：\n- 成员变量包括一组圆的参数输入，如数量、相对位置、速度、半径、rgba颜色等；\n- 成员函数主要是对图像进行设置、圆位置更新、像素点颜色渲染等。\n\n```c\nclass CudaRenderer : public CircleRenderer\n{\n  private:\n    Image *image;\n    SceneName sceneName;\n    // 输入圆的host参数，包括数量、相对位置、速度、半径、颜色等\n    int numCircles;\n    float *position;\n    float *velocity;\n    float *color;\n    float *radius;\n\n\t// 输入圆的device参数\n    float *cudaDevicePosition;\n    float *cudaDeviceVelocity;\n    float *cudaDeviceColor;\n    float *cudaDeviceRadius;\n    float *cudaDeviceImageData;\n\n  \n  public:\n    CudaRenderer();\n    \n    virtual ~CudaRenderer();\n    \n    const Image *getImage();             //获取图像指针\n    \n    void setup();                        //复制host数据到device\n\n    void loadScene(SceneName name);      //加载Scene的初始状态\n\n    void allocOutputImage(int width, int height);  //为图像分配动态内存\n\n    void clearImage();                   //清空图像内容\n\n    void advanceAnimation();             //更新每一帧中圆的速度和位置\n\n    void render();                       //对空白图像上的圆进行渲染\n\n    void shadePixel(int circleIndex, float pixelCenterX, float pixelCenterY, float px, float py, float *pixelData); // 计算输入圆(px,py) 对输入像素(pixelCenterX, pixelCenterY) 的rgba贡献\n\n};\n```\n\n### 渲染器类的使用\n\n渲染器类的使用方式大致如下：\n\n```c\n\trenderer = new CudaRenderer();\n\t\n\t// 分配图像内存空间\n\trenderer->allocOutputImage(imageSize, imageSize);\n\t\n\t// 场景初始化，指定要渲染的图像sceneName，加载圆的host参数\n\trenderer->loadScene(sceneName);\n\t\n\t// 复制host数据到device\n\trenderer->setup();\n    bool dumpFrames = frameFilename.length() > 0;\n\n    // 渲染动画的每一帧\n    for (int frame = 0; frame < totalFrames; frame++)\n    {\n\t    // 清空图像内容\n        renderer->clearImage();\n        cudaDeviceSynchronize();\n        \n\t\t// 更新圆的位置\n        renderer->advanceAnimation();\n        cudaDeviceSynchronize();\n\n\t\t// 渲染图像\n        renderer->render();\n        cudaDeviceSynchronize();\n  \n        // 每一帧生成一个ppm文件\n        if (dumpFrames)\n           {\n              char filename[1024];\n              writePPMImage(renderer->getImage(), filename);\n           }\n        }\n    }\n```\n\n### 渲染流程实现\n\n#### 数据准备setup\n\n- 在 `loadScene` 获取了圆的host输入参数后，需要将圆的host参数通过`cudaMemcpy`搬运到device\n- device参数可以声明为常量内存，进一步优化读取速度\n```c\n// 将图像数据放置到常量内存cuConstRendererParams中\nstruct GlobalConstants\n{\n    SceneName sceneName;\n    int numCircles;\n    float *position;\n    float *velocity;\n    float *color;\n    float *radius;\n    int imageWidth;\n    int imageHeight;\n    float *imageData;\n};\n__constant__ GlobalConstants cuConstRendererParams;\n\nvoid CudaRenderer::setup()\n{\n\n    int deviceCount = 0;\n    std::string name;\n    cudaError_t err = cudaGetDeviceCount(&deviceCount);\n\n    printf(\"Initializing CUDA for CudaRenderer\\n\");\n\n    cudaMalloc(&cudaDevicePosition, sizeof(float) * 3 * numCircles);\n    cudaMalloc(&cudaDeviceVelocity, sizeof(float) * 3 * numCircles);\n    cudaMalloc(&cudaDeviceColor, sizeof(float) * 3 * numCircles);\n    cudaMalloc(&cudaDeviceRadius, sizeof(float) * numCircles);\n    cudaMalloc(&cudaDeviceImageData, sizeof(float) * 4 * image->width * image->height);\n\n  \n    cudaMemcpy(cudaDevicePosition, position, sizeof(float) * 3 * numCircles, cudaMemcpyHostToDevice);\n    cudaMemcpy(cudaDeviceVelocity, velocity, sizeof(float) * 3 * numCircles, cudaMemcpyHostToDevice);\n    cudaMemcpy(cudaDeviceColor, color, sizeof(float) * 3 * numCircles, cudaMemcpyHostToDevice);\n    cudaMemcpy(cudaDeviceRadius, radius, sizeof(float) * numCircles, cudaMemcpyHostToDevice);\n\n    GlobalConstants params;\n    params.sceneName = sceneName;\n    params.numCircles = numCircles;\n    params.imageWidth = image->width;\n    params.imageHeight = image->height;\n    params.position = cudaDevicePosition;\n    params.velocity = cudaDeviceVelocity;\n    params.color = cudaDeviceColor;\n    params.radius = cudaDeviceRadius;\n    params.imageData = cudaDeviceImageData;\n\n    cudaMemcpyToSymbol(cuConstRendererParams, &params, sizeof(GlobalConstants));\n}\n```\n#### 清空图像 clearImage\n\n- 清空图像内容，即将图像所有像素设置为白色 (1,1,1,1)\n- 清空图像可以使用cuda进行加速，每一个线程负责一个像素的设置，可以使用float4向量化写入\n```c\n__global__ void kernelClearImage()\n\n{\n    int imageX = blockIdx.x * blockDim.x + threadIdx.x;\n    int imageY = blockIdx.y * blockDim.y + threadIdx.y;\n    \n    int width = cuConstRendererParams.imageWidth;\n    int height = cuConstRendererParams.imageHeight;\n\n    if (imageX >= width || imageY >= height)\n        return;\n\n    int offset = 4 * (imageY * width + imageX);\n    float4 value = make_float4(1.f, 1.f, 1.f, 1.f);\n\n    *(float4 *)(&cuConstRendererParams.imageData[offset]) = value;\n}\n\nvoid CudaRenderer::clearImage()\n{\n    dim3 blockDim(16, 16, 1);\n\n    dim3 gridDim((image->width + blockDim.x - 1) / blockDim.x, (image->height + blockDim.y - 1) / blockDim.y);\n\n    kernelClearImage<<<gridDim, blockDim>>>();\n    cudaDeviceSynchronize();\n}\n```\n\n#### 更新器 advanceAnimation\n- 更新器更新圆当前帧所在的位置。不同动画图像的更新逻辑不同，但都可以使用cuda进行加速，让一个线程负责一个圆位置的更新即可\n```c\nvoid CudaRenderer::advanceAnimation()\n{\n    // 256 threads per block is a healthy number\n    dim3 blockDim(256, 1);\n    dim3 gridDim((numCircles + blockDim.x - 1) / blockDim.x);\n \n    // only the snowflake scene has animation\n    if (sceneName == SNOWFLAKES)\n    {\n        kernelAdvanceSnowflake<<<gridDim, blockDim>>>();\n    }\n    else if (sceneName == BOUNCING_BALLS)\n    {\n        kernelAdvanceBouncingBalls<<<gridDim, blockDim>>>();\n    }\n    else if (sceneName == HYPNOSIS)\n    {\n\n        kernelAdvanceHypnosis<<<gridDim, blockDim>>>();\n    }\n    else if (sceneName == FIREWORKS)\n    {\n        kernelAdvanceFireWorks<<<gridDim, blockDim>>>();\n    }\n}\n```\n\n#### 串行渲染的render实现\n\n渲染空白图像每个像素的伪代码如下：\n```text\nfor 每个圆\n    计算圆在图像的边界框  \n    for 边界框内的所有像素  \n        计算像素中心点  \n\n        if 中心点在圆内  \n            计算圆在该点的颜色  \n            将圆对该像素的颜色贡献混合到图像中\n```\n**注意**：\n- 仅当像素中心位于圆圈内时，圆圈才会为输出像素提供颜色。\n- 某个像素点的颜色是混合了所有与该像素重叠的半透明圆的颜色。也就是说如果一个像素点有多个圆重叠，那么这个像素点的颜色是这多个圆按输入顺序进行颜色渲染叠加的结果\n\n![|200](基于CUDA实现彩色圆形渲染器/img-基于CUDA实现彩色圆形渲染器-8.png)\n\n**串行实现**：\n```c\n#define CLAMP(x, minimum, maximum) std::max(minimum, std::min(x, maximum))\n\nvoid render()\n{\n    // 遍历所有圆\n    for (int circleIndex = 0; circleIndex < numCircles; circleIndex++)\n    {\n        int index3 = 3 * circleIndex; \n        \n        // 该圆中心点位置\n        float px = position[index3];\n        float py = position[index3 + 1];\n\n        float rad = radius[circleIndex]; // 半径\n\n        // 计算每个圆的二维的bounding box范围，输入数据均是归一化后的数据\n        float minX = px - rad;\n        float maxX = px + rad;\n        float minY = py - rad;\n        float maxY = py + rad;\n\n        // 将归一化的圆的bounding box边界（minX, maxX, minY, maxY）转换为实际的图像坐标\n        int screenMinX = CLAMP(static_cast<int>(minX * image->width), 0, image->width);\n        int screenMaxX = CLAMP(static_cast<int>(maxX * image->width) + 1, 0, image->width);\n        int screenMinY = CLAMP(static_cast<int>(minY * image->height), 0, image->height);\n        int screenMaxY = CLAMP(static_cast<int>(maxY * image->height) + 1, 0, image->height);\n\n\t\t// 图像width和height的倒数，用于对像素点坐标进行归一化\n        float invWidth = 1.f / image->width;\n        float invHeight = 1.f / image->height;\n\n        // 遍历 bounding box中的每一个像素。注意只有像素点在圆的范围内才会被渲染到\n        for (int pixelY = screenMinY; pixelY < screenMaxY; pixelY++)\n        {\n            // 像素点[pixelY,screenMinX]的rgba值的指针\n\t\t\tfloat *imgPtr =&image->data[4 *(pixelY * image->width +screenMinX)];\n\t\t\t\n            for (int pixelX = screenMinX; pixelX < screenMaxX; pixelX++)\n            {\n\t\t\t\t// 归一化像素点的中心位置\n                float pixelCenterNormX = invWidth * (static_cast<float>(pixelX) + 0.5f);\n                float pixelCenterNormY = invHeight * (static_cast<float>(pixelY) + 0.5f);\n                \n                // 渲染当前像素\n                shadePixel(circleIndex, pixelCenterNormX, pixelCenterNormY, px, py, imgPtr);\n                // 指针移到下一列的像素点\n                imgPtr += 4;\n            }\n        }\n    }\n\n}\n```\n\n渲染像素点的实现：\n```c\nvoid shadePixel(int circleIndex, float pixelCenterX, float pixelCenterY, float px, float py, float *pixelData)\n{\n    float diffX = px - pixelCenterX;\n    float diffY = py - pixelCenterY;\n    \n    // 圆心到像素点归一化坐标的欧式距离\n    float pixelDist = diffX * diffX + diffY * diffY;\n    \n    float rad = radius[circleIndex];\n    float maxDist = rad * rad;\n\n    // 当前像素不在圆形范围内，直接返回\n    if (pixelDist > maxDist)\n        return;\n\n    float colR, colG, colB;\n    float alpha;\n\n     // 加载当前圆的rgba值\n    int index3 = 3 * circleIndex;\n    colR = color[index3];\n    colG = color[index3 + 1];\n    colB = color[index3 + 2];\n    alpha = .5f;\n\n    // 圆的颜色按透明度比例叠加在原像素颜色上\n    pixelData[0] = alpha * colR + (1.f - alpha) * pixelData[0];\n    pixelData[1] = alpha * colG + (1.f - alpha) * pixelData[1];\n    pixelData[2] = alpha * colB + (1.f - alpha) * pixelData[2];\n    pixelData[3] += alpha;\n}\n```\n\n渲染一万个圆的图片，执行时间如下: \n- 渲染使用时间为395ms\n![](基于CUDA实现彩色圆形渲染器/基于CUDA实现彩色圆形渲染器-3.png)\n\n#### 并行渲染的render实现\n\n使用cuda并行实现图像渲染需要注意两个问题：\n- **原子性**：因为像素点的颜色渲染是对像素点rgba数据进行 **“读-改-写”** 的操作，不能让多个线程同时对同一个像素进行渲染，所以要保证像素点的颜色渲染是原子操作；\n- **顺序性**：渲染器必须按圆形输入顺序对图像像素执行更新。因为同一个像素点可能被不同的圆覆盖，不同的渲染顺序得到的颜色结果是不同（如下图所示），所以这里规定渲染的顺序需要是按照圆形输入的序号从小到大对像素进行渲染。\n\n![](基于CUDA实现彩色圆形渲染器/img-基于CUDA实现彩色圆形渲染器-7.png)\n\n---\n\n**Native 实现**\n因为要保证像素点颜色渲染的原子性，所以不能按圆并行，要按像素并行。\n- 我们可以为每个像素分配一个线程，让线程去遍历所有的圆，判断哪些圆覆盖到了线程负责的像素点，再用这些圆去渲染像素点。\n- 一个线程负责一个像素点的渲染，并且按顺序遍历圆，同时满足了渲染的**原子性和顺序性**\n```c\n__global__ void kernelRenderPixels_v1()\n{\n    int pixelX = blockIdx.x * blockDim.x + threadIdx.x;\n    int pixelY = blockIdx.y * blockDim.y + threadIdx.y;\n\n    int imageWidth = cuConstRendererParams.imageWidth;\n    int imageHeight = cuConstRendererParams.imageHeight;\n\n    if (pixelX >= imageWidth || pixelY >= imageHeight)\n        return;\n  \n\n    float invWidth = 1.f / imageWidth;\n    float invHeight = 1.f / imageHeight;\n\n    // 线程负责的像素中心的标准化坐标\n    float2 pixelCenterNorm =\n        make_float2(invWidth * (static_cast<float>(pixelX) + 0.5f), invHeight * (static_cast<float>(pixelY) + 0.5f));\n\n\t// 线程负责的像素点的rgba值\n    float4 *imgPtr = (float4 *)(&cuConstRendererParams.imageData[4 * (pixelY * imageWidth + pixelX)]);\n\n    // 遍历每个圆\n    for (int circleIndex = 0; circleIndex < cuConstRendererParams.numCircles; circleIndex++)\n    {\n        int index3 = 3 * circleIndex;\n        float3 p = *(float3 *)(&cuConstRendererParams.position[index3]); // 圆中心点坐标\n  \n\t\t// 计算圆心到像素点到欧式距离\n\t    float diffX = p.x - pixelCenter.x;\n\t    float diffY = p.y - pixelCenter.y;\n\t    float pixelDist = diffX * diffX + diffY * diffY;\n\t    float rad = cuConstRendererParams.radius[circleIndex];\n\t    float maxDist = rad * rad;\n\n\t    // 如果像素点不在该圆中\n\t    if (pixelDist > maxDist)\n\t\t    continue;\n        // 使用该圆渲染像素点\n\t    shadePixel(circleIndex, pixelCenterNorm, p, imgPtr);\n    }\n}\n```\n\n渲染一万个圆的图片，执行时间如下：\n- 相比cpu实现，渲染的加速比为 3.87\n![](基于CUDA实现彩色圆形渲染器/基于CUDA实现彩色圆形渲染器-4.png)\n\n使用Nsight Compute进行分析，发现带宽很低，且访问全局内存的次数非常多：\n![|500](基于CUDA实现彩色圆形渲染器/基于CUDA实现彩色圆形渲染器-2.png)\n\nNative实现可以优化的点：\n- **全局访存**： 线程读写全局内存的次数过多，多次读写像素点全局数据；\n- **遍历圆的次数**： 整个图像上可能只有少数圆对线程负责的像素点有颜色贡献，但是每个线程都需要重复遍历所有的圆。\n\n---\n\n**共享内存优化**：\n\n为了减少对全局内存的访问次数，以及减少对圆的遍历次数，我们可以通过共享内存的通信，让block中所有的线程共同遍历圆，具体的算法步骤如下：\n- 以一个block中的像素所围成的矩形区域为单位，筛选出与矩形区域有重叠的圆（与矩形无重叠的圆一定对矩形区域的像素无颜色贡献）；\n\t- 如下图所示，与block所围成的矩形区域的红色圆是可能对内部像素有贡献的，而不相交的蓝色圆一定对内部像素无贡献。\n![](基于CUDA实现彩色圆形渲染器/基于CUDA实现彩色圆形渲染器-6.png)\n- 这样就可以让每个线程负责一部分的圆，计算出与矩形区域有重叠的圆的位置，再用计算前缀和的方式收集圆的下标，最后让线程遍历这些重叠的圆对其负责的像素点进行渲染；\n- 另外，线程读写的像素点值可以使用寄存器保存，进一步减少对全局内存的访问。\n```c\n  __global__ void kernelRenderPixels_v2()\n{\n    int threadIndex = blockDim.x * threadIdx.y + threadIdx.x;\n    int pixelX = blockIdx.x * blockDim.x + threadIdx.x;\n    int pixelY = blockIdx.y * blockDim.y + threadIdx.y;\n    int imageWidth = cuConstRendererParams.imageWidth;\n    int imageHeight = cuConstRendererParams.imageHeight;\n\n    // if (pixelX >= imageWidth || pixelY >= imageHeight)\n    //     return;\n\n\n    // 像素中心的标准化坐标\n    float invWidth = 1.f / imageWidth;\n    float invHeight = 1.f / imageHeight;\n    float2 pixelCenterNorm =\n        make_float2(invWidth * (static_cast<float>(pixelX) + 0.5f), invHeight * (static_cast<float>(pixelY) + 0.5f));\n\n    float4 *imgPtr = (float4 *)(&cuConstRendererParams.imageData[4 * (pixelY * imageWidth + pixelX)]);\n    \n    // 像素数据加载到寄存器\n    float4 img_reg = *imgPtr;\n\n\n    // 线程块负责的矩形区域\n    uint boxL = blockDim.x * blockIdx.x;\n    uint boxR = boxL + blockDim.x < imageWidth ? boxL + blockDim.x : imageWidth;\n    uint boxB = blockDim.y * blockIdx.y;\n    uint boxT = boxB + blockDim.y < imageHeight ? boxB + blockDim.y : imageHeight;\n    float boxLNorm = (float)boxL * invWidth;\n    float boxRNorm = (float)boxR * invWidth;\n    float boxBNorm = (float)boxB * invHeight;\n    float boxTNorm = (float)boxT * invHeight;\n\n  \n\n    // 计算前缀和、相交圆需要用到的共享内存数组\n    __shared__ uint flag[THREADS_PER_BLOCK];\n    __shared__ uint prefixSumOutput[THREADS_PER_BLOCK];\n    __shared__ uint prefixSumScratch[2 * THREADS_PER_BLOCK]; // 计算前缀和需要用到的临时数组\n    __shared__ uint circlesConservative[THREADS_PER_BLOCK];\n\n\n    int numCircles = cuConstRendererParams.numCircles;\n    \n    // 遍历每个圆，步长为THREADS_PER_BLOCK\n    for (int index = 0; index < numCircles; index += THREADS_PER_BLOCK) \n    {\n\n        int circleIndex = index + threadIndex; // 每个线程对应计算的圆序号\n\n        \n        if (circleIndex < numCircles)\n        {\n            float3 p = *(float3 *)(&cuConstRendererParams.position[3 * circleIndex]); // 圆中心点坐标\n            float circleRadius = cuConstRendererParams.radius[circleIndex]; \n            \n\t\t\t// 判断该圆是否与block相交\n            flag[threadIndex] = circleInBox(p.x, p.y, circleRadius, boxLNorm, boxRNorm, boxTNorm, boxBNorm);\n        }\n        else\n        {\n            flag[threadIndex] = 0;\n        }\n        __syncthreads();\n\n        // 计算flag前缀和\n        sharedMemExclusiveScan(threadIndex, flag, prefixSumOutput, prefixSumScratch, THREADS_PER_BLOCK);\n        __syncthreads();\n\n        // 统计与block相交的圆下标\n        if (flag[threadIndex])\n            circlesConservative[prefixSumOutput[threadIndex]] = circleIndex;\n        __syncthreads();\n\n\n\t\t// 无效像素点不需要计算\n        if (pixelX >= imageWidth || pixelY >= imageHeight)\n            continue;\n\n        // 和block区域相交的圆的数量\n        int numConservative = prefixSumOutput[THREADS_PER_BLOCK - 1] + flag[BLOCKSIZE - 1];\n\n        // 用和block区域相交的圆渲染该像素点\n        for (int i = 0; i < numConservative; i++)\n        {\n            int circle = circlesConservative[i];\n            float3 p = *(float3 *)(&cuConstRendererParams.position[3 * circle]);\n            shadePixel(circle, pixelCenterNorm, p, &img_reg);\n        }\n    }\n\n    // 像素点数据写入全局内存\n    *imgPtr = img_reg;\n\n}\n```\n\n判断重叠的方法：\n```c\n// 判断圆是否和矩形有交叠\n__device__ __inline__ int\ncircleInBox(\n    float circleX, float circleY, float circleRadius,\n    float boxL, float boxR, float boxT, float boxB)\n{\n    // 找到矩形中最接近圆心的点\n    float closestX = (circleX > boxL) ? ((circleX < boxR) ? circleX : boxR) : boxL;\n    float closestY = (circleY > boxB) ? ((circleY < boxT) ? circleY : boxT) : boxB;\n\n\t// 计算圆心到最近点的欧式距离\n    float distX = closestX - circleX;\n    float distY = closestY - circleY;\n\n\t// 是否在圆内\n    if ( ((distX*distX) + (distY*distY)) <= (circleRadius*circleRadius) ) {\n        return 1;\n    } else {\n        return 0;\n    }\n}\n```\n\n\n修改后的渲染算法将每个线程从遍历N次圆，减少到了遍历 N / THREADS_PER_BLOCK 次圆，大幅减少了计算次数，同时也减少了全局内存的访存次数。\n\n渲染一万个圆的图片，渲染执行时间如下：\n- 相比Native实现，加速比为12.75倍； 相比CPU实现，加速比为49倍\n![](基于CUDA实现彩色圆形渲染器/基于CUDA实现彩色圆形渲染器-7.png)\n\n使用Nsight Compute进行分析，内存带宽得到大幅度的提升，同时访存指令和全局内存的读写也大大减少。\n![|600](基于CUDA实现彩色圆形渲染器/基于CUDA实现彩色圆形渲染器-9.png)\n\n因为是按行读写全局内存，期间也没有发生bank conflict\n![](基于CUDA实现彩色圆形渲染器/基于CUDA实现彩色圆形渲染器-10.png)\n\n\n## 总结\n\n最后实现的渲染器相比普通CPU实现，加速比为49倍，整体运行速度得到了巨大的提升，不过这一算法比较适合圆数量非常大的情况，对圆数量较少时的渲染效果欠佳。\n后续可以尝试采用批量处理的方式，当收集到的圆达到一定数量后，再集中进行渲染，对于与block相交圆数量比较少的情况效果可能会好一些。\n\n图像结果展示：\n- 一万个彩色圆\n![|400](基于CUDA实现彩色圆形渲染器/img-基于CUDA实现彩色圆形渲染器-1.png)\n\n- 跳动小球\n![|300](基于CUDA实现彩色圆形渲染器/bouncingballs.gif)\n\n- 雪花\n![|200](基于CUDA实现彩色圆形渲染器/snow.gif)","tags":["cuda"],"categories":["project"]},{"title":"CUDA笔记——CUDA线程模型","url":"/2025/03/26/note/cuda/CUDA笔记——CUDA线程模型/","content":"## CUDA\n**CUDA**：一个NVIDIA GPU程序的编译器和工具集，使用C++编写的高抽象软件栈。\n软件开发人员从此可以使用CUDA在英伟达的GPU上进行并行编程。\n\n### CUDA软件栈\n![|500](CUDA笔记——CUDA线程模型/img-CUDA笔记——CUDA线程模型-8.png)\nCUDA **Runtime** 软件栈主要包括：\n- **CUDA API 层**（Runtime API vs Driver API）\n- **CUDA 编译器**（NVCC & PTX）\n- **CUDA 运行时 & 驱动**（CUDA Runtime & Driver）\n- **CUDA 内存管理**（全局/共享/常量/寄存器）\n- **CUDA 执行模型**（线程模型 & 流调度）\n\nCUDA中的**异构编程** (Heterogeneous Programming)： 指的是在**CPU和GPU之间以及GPU内部，任务可以不必等待前一个任务完成后再启动下一个任务**\n- 例如CPU在启动GPU内核计算后不必等待GPU内核完成便可以继续执行接下来的指令，让GPU在后台完成计算。CPU与GPU的内存空间是独立，它们之间通过PCI Bus交换数据\n\n### 线程组织结构\n### Thread\nGPU处理数据的基本单位\n\t- **一个sp执行一个thread**\n\t- thread ID 是三维的，即通过（x,y,z)在block中定位\n\t- thread总数=block总数×每个block的thread数\n\t- 每个线程都有自己的本地内存，有自己的数据空间(寄存器)；\n\t\t- 线程的本地内存通常是使用的全局内存，因此速度非常慢\n\t\t- 当线程发生**寄存器溢出**时才会使用本地内存\n\t- 同一个block中的线程都可以读写其blcok的共享内存shared memory\n\n![|400](CUDA笔记——CUDA线程模型/img-CUDA笔记——CUDA线程模型-3%201.png)\n\n### **Block**\n多个thread组成一个block，一个block最多拥有1024个线程\n\t- 同一个block中的threads可以同步，也可以共享数据\n\t- 不同block中的threads是不可以同步的，除非使用Thread Block Clusters（Hopper 架构）\n\t- **同一个block中的所有线程一定在同一個SM中执行**（即block不能切换到其他SM执行）\n\t\t- 这也是block中的线程数量受限制的原因，不能超过单个SM的负载\n\t- **每个SM可以同时执行多个block**，通常上限是16\n\t\t- 在同一个 SM 上，多个 block 的 warps 可能会交替执行。因此不同block之间是不同步的，它们之间执行也是无序的（对应到算法设计block之间也应该是无序的）\n\t\t- 当一个block执行完成后才会被释放\n\t- block ID和维度也是三维的\n\t\t- block三维的乘积=该block的thread数\n\t\t- block的dim3范围：**(1024,1024,64)**\n\t- **每个block最多分配1024个thread** （CUDA 2.0）\n\t\t- 即**block的dim中x × y × z 三者的乘积不能超过1024**\n\t\t- block的线程数最好是32的倍数（不满32的也会被塞入无效线程强行凑够32个）\n\n### Grid\ngrid由多个block组成，可以拥有**数万到百万**的block数量\n\t- **一个grid执行一个kernel函数**（可以视作kernel=grid）\n\t\t- 一个grid里面的所有thread均执行同一个kernel函数\n\t\t- GPU可以同时执行多个grid（即多个kernel）\n\t- grid的dim也是三维的，表示grid里面block的范围，grid三维的乘积=block总数\n\t\t- grid的dim3范围：**(2^31-1, 65535,65535)**\n\t\t- grid里面的所有block维度都一样，即线程数是一样的\n\t- 每个grid最多分配 65535（CUDA3前） 或 2^31-1 （CUDA3后）个block\n\t\t- 因此grid的dim中xyz乘积不能超过最大block数\n\nGrid、Block、Thread示意图：\n- 图中grid的维度为（2,2,1），block的维度为（4,2,2）\n![|350](CUDA笔记——CUDA线程模型/img-CUDA笔记——CUDA线程模型-6.png)\n![|500](https://pic1.zhimg.com/v2-39e09678a49d71094c5ac420d8ba43a4_r.jpg)\n\n\n### warp\n32个thread为一个warp，SM执行任务的调度单元\n\t- 同一时间，**一个SM可以同时执行多个warp（取决于架构的warp scheduler数量）**\n\t- **Warp内隐式同步**：\n\t\t  - warp中的32个thread里面的代码执行在指令级别是隐式同步的\n\t\t  - 因此同一warp内的线程**无需额外的同步指令**\n\t- **延迟隐藏**：类比于CPU中的进程、当一个warp阻塞时（比如等待资源），SM将切换执行另一个warp\n\t\t- GPU的warp切换是0开销的，CPU切换开销就很大\n\t\t- 例如当一个warp进行数据访存的时候，就让这个warp stall，而后调度器再选一个warp进行计算，通过这种方式交错开计算和访存，让访存单元一直忙碌，带宽打满\n\t- **线程束分化**：GPU对分支的处理，产生分支会导致warp中的线程串行执行线程\n\t\t- 如果warp中的所有线程都只执行一个分支，则不会有任何性能影响\n\t\t- 不满足分支条件的线程，处于未激活，等待其他线程执行分支\n\t\t\t- 也因此线程分化会导致硬件利用率下降，warp中的分支判断也是一个优化点\n```c\n__global__ void func()\n{\n\tif(some condition).     //所有线程执行\n\t\tdo a;               //warp中部分线程执行a\n\telse                    \n\t\tdo b;               //warp中部分线程执行b，执行b的线程可能需要先等待a执行完\n}\n```\n *\n\n硬件与软件层的映射图：\n![](CUDA笔记——CUDA线程模型/img-CUDA笔记——CUDA线程模型-3.png)\n\n#### **自动可拓展性**\n\nblock之间执行的无序性确保了自动可拓展性Automatic Scalability，如下图，同一个CUDA程序，不同的GPU执行时会根据具体的SM数分配不同的Block组数\n![|550](CUDA笔记——CUDA线程模型/img-CUDA笔记——CUDA线程模型-9.png)\n\n\n\n### GPU的Occupancy限制\nGPU 的 **Occupancy（占用率）** 指的是 **一个 SM上正在执行的 warp 数量与SM可支持的最大 warp 数量的比值**。它衡量的是 GPU 计算资源的利用率。\n*例如在Ampere架构上，支持的最大 Warp 数量为 64*\n\n- **Occupancy计算公式**：\n\n\t\t$\\large \\text{Occupancy} = \\frac{\\text{Active Warps per SM}}{\\text{Maximum Warps per SM}}$\n\n- **一个 SM上活跃的 warp 数量计算公式**：\n$\\text{Active Warps per SM} = \\min \\left( \\frac{\\text{Total Threads per SM}}{32}, \\frac{\\text{Max Threads per SM}}{32}, \\frac{\\text{Register Limit per SM}}{\\text{Register per Thread} \\times 32}, \\frac{\\text{Shared Memory Limit per SM}}{\\text{Shared Memory per Block}} \\right)$\n\t其中：\n\n| 参数名称                       | 含义                                      |\n| -------------------------- | --------------------------------------- |\n| Total Threads per SM       | SM 上所有活动线程数 (SM上活跃的block数 ✖️ BLOCKSIZE) |\n| Max Threads per SM         | 每个 SM 支持的最大线程数（如 Ampere 架构为 **2048**）。  |\n| Register Limit per SM      | SM 可用的寄存器总数（如 Ampere 架构通常为 64K）。        |\n| Register per Thread        | 每个线程使用的寄存器数量。                           |\n| Shared Memory Limit per SM | 每个 SM 的共享内存上限（如 100 KB）。                |\n| Shared Memory per Block    | 单个线程块所使用的共享内存。                          |\n从公式可以看出，可以**影响occupancy的因素**有：\n1. 每个thread的SM register 数量 → 限制了可同时执行的thread数\n\t- 当寄存器占用过多时，每个线程块可以容纳的线程数量减少，导致每个SM上的活跃线程数降低\n2. 每个block的shared memory 数量 →限制了可同时执行的block数\n\t- ，较多的使用共享内存会减少GPU上可并行执行的线程块数量\n3. 每个block的thread数，即BLOCKSIZE\n\t- 如果线程块太大，会导致SM不能启动更多线程块，减少了SM上活跃的block数，从而降低Occupancy。\n\t- 相反，如果线程块过小，可能无法充分利用GPU的计算能力。\n\t- **一个 SM上活跃的 block 最大数量计算公式**：\n\t    $\\text{Max Active Blocks per SM} = \\min \\left( \\frac{\\text{Max Threads per SM}}{\\text{Threads per Block}}, \\text{Max Blocks per SM ()} \\right)$\n\n**误区**：并不是Occupancy越高，性能越好。过高的占用率可能会导致寄存器溢出，影响性能。\n    - 每个线程完成的工作越独立，对Occupancy的要求就越低\n    - 如果是memory - bound 的工作（即频繁读写内存），则需要高Occupancy\n\n\n### block中线程数量BLOCKSIZE的选择\n单个block线程数量太少，会导致GPU资源利用率下降，**那么单个block线程数量越大越好吗？**\n\n答案是否定的，如果线程数量过多，可能会导致下面的问题：\n1. 片上分配的资源不足，增加对全局内存的访问，提高延迟。\n2. 减少可以并行的block数量，降低Occupancy\n因此SM和block限制了最大线程数量。\n\n**如何选择线程和块数量**？\n1. 首先保证block线程的数量是**32**的倍数\n2. **共享内存和寄存器的分配不能超过上限**。如果使用的共享内存和寄存器越多，那么可以适当减少线程数，以增加block的占有率\n3. 单块线程数量可以在开始选择为  $\\frac{\\text{Max Threads per SM}}{\\text{Max Blocks per SM}} = 128$ 的倍数， 再根据通过性能测试和调优来实现最优配置\n3. Grid包含的线程块可以尽可能多，确保GPU的SM能够同时调度尽可能多的线程块。\n>最佳实践： BLOCKSIZE的大小可以从128的倍数选择。\n>可以使用 NVIDIA 的 cudaOccupancyMaxPotentialBlockSize() 工具来计算系统推荐的 block size","tags":["cuda"],"categories":["note","cuda"]},{"title":"c++学习笔记——智能指针—weak_ptr","url":"/2025/03/12/note/c++学习笔记/智能指针—weak_ptr/","content":"## weak_ptr\nweak_ptr旨在解决循环引用的问题。当需要可以**查看和使用共享资源但不参与该资源的所有权**的智能指针时，可以使用 weak_ptr。\n\tweak_ptr的最大优点是它可以检查它引用的对象是否过期（销毁）。原始指针无法执行此操作。\n\tweak_ptr 是一个观察者 —— 它可以观察和访问与 std：：shared_ptr（或其他 std：：weak_ptrs）相同的对象，但它不被视为所有者。\n\t当 std：：shared 指针超出范围时，它只考虑其他 std：：shared_ptr 是否共同拥有该对象。std：：weak_ptr 不算数！\n\t下面的案例中，当 ricky 超出范围时，它会看到没有其他 std：：shared_ptr 指向 “Ricky”（来自 “Lucy” 的 std：：weak_ptr 不计算在内）。因此，它将解除分配 “Ricky”。Lucy也是如此。\n```cpp\nclass Person\n{\n\tstd::string m_name;\n\tstd::weak_ptr<Person> m_partner; // note: This is now a std::weak_ptr\n\npublic:\n\n\tPerson(const std::string &name) : m_name(name)\n\t{\n\t\tstd::cout << m_name << \" created\\n\";\n\t}\n\t~Person()\n\t{\n\t\tstd::cout << m_name << \" destroyed\\n\";\n\t}\n\n\tfriend bool partnerUp(std::shared_ptr<Person> &p1, std::shared_ptr<Person> &p2)\n\t{\n\t\tif (!p1 || !p2)\n\t\t\treturn false;\n\n\t\tp1->m_partner = p2;\n\t\tp2->m_partner = p1;\n\n\t\tstd::cout << p1->m_name << \" is now partnered with \" << p2->m_name << '\\n';\n\n\t\treturn true;\n\t}\n\n\tstd::shared_ptr<Person> getPartner() const { return m_partner.lock(); } // 使用lock()函数将weak_ptr转换为shared_ptr，才能使用weak_ptr\n\t\n\tconst std::string& getName() const { return m_name; }\n};\n\nint main()\n{\n\tauto lucy { std::make_shared<Person>(\"Lucy\") };\n\tauto ricky { std::make_shared<Person>(\"Ricky\") };\n\n\tpartnerUp(lucy, ricky);\n\n\tauto partner = ricky->getPartner(); // get shared_ptr to Ricky's partner\n\tstd::cout << ricky->getName() << \"'s partner is: \" << partner->getName() << '\\n';\n\n\treturn 0;\n}\n```\n\n**避免使用 std：：weak_ptr 的悬空指针**\n\t由于 std：：weak_ptr 不会使拥有的资源的所有权，因此 std：：weak_ptr 指向的资源有可能已被 std：：shared_ptr 释放\n\t然而，std：：weak_ptr 有一个巧妙的技巧 —— 因为它**可以访问对象的引用计数**，所以它可以确定它是否指向一个有效的对象！如果**引用计数不为零，则资源仍然有效**。\n\t测试 std：：weak_ptr 是否有效的最简单方法是使用 `expired（）` 成员函数，如果 std：：weak_ptr 指向无效对象，则返回 `true`，否则返回 `false`\n\n- 下面的例子中，`getDumbPtr（）` 和 `getWeakPtr（）` 都使用智能指针来分配 Resource —— 这个智能指针确保分配的 Resource 在函数结束时被销毁。当 `getDumbPtr（）` 返回 Resource* 时，它会返回一个悬空指针（因为 std：：unique_ptr 在函数结束时销毁了 Resource）。当 `getWeakPtr（）` 返回 std：：weak_ptr 时，该 std：：weak_ptr 同样指向一个无效的对象（因为 std：：shared_ptr 在函数结束时销毁了 Resource）。\n- 在 main（） 中，我们首先测试返回的哑指针是否为 `nullptr`。由于哑指针仍保存已释放资源的地址，因此此测试失败。`main（）` 无法判断此指针是否悬空。在这种情况下，因为它是一个悬空指针，如果我们要取消引用这个指针，将导致 undefined 的行为。\n- 我们测试 `weak.expired（）` 是否为 `true`。由于 `weak` 指向的对象的引用计数为 `0`（因为所指向的对象已被销毁），因此这将解析为 `true`。因此，`main（）` 中的代码可以判断 `weak` 指向无效对象，我们可以根据需要对代码进行条件化\n- 请注意，如果 std：：weak_ptr 过期，那么我们不应该对它调用 `lock（），`因为指向的对象已经被销毁，所以没有对象可以共享。如果你对过期的 std：：weak_ptr 调用 `lock（`），它会将 std：：shared_ptr 返回给 `nullptr`。\n```cpp\nclass Resource\n{\npublic:\n\tResource() { std::cerr << \"Resource acquired\\n\"; }\n\t~Resource() { std::cerr << \"Resource destroyed\\n\"; }\n};\n\n// Returns a std::weak_ptr to an invalid object\nstd::weak_ptr<Resource> getWeakPtr()\n{\n\tauto ptr{ std::make_shared<Resource>() };\n\treturn std::weak_ptr<Resource>{ ptr };\n} // ptr goes out of scope, Resource destroyed\n\n// Returns a dumb pointer to an invalid object\nResource* getDumbPtr()\n{\n\tauto ptr{ std::make_unique<Resource>() };\n\treturn ptr.get();\n} // ptr goes out of scope, Resource destroyed\n\nint main()\n{\n\tauto dumb{ getDumbPtr() };\n\tstd::cout << \"Our dumb ptr is: \" << ((dumb == nullptr) ? \"nullptr\\n\" : \"non-null\\n\");\n\n\tauto weak{ getWeakPtr() };\n\tstd::cout << \"Our weak ptr is: \" << ((weak.expired()) ? \"expired\\n\" : \"valid\\n\");\n\n\treturn 0;\n}\n```\n\n一个经典的案例，二叉树的指针的使用，`shared_ptr` 用于管理子节点的所有权，而父节点和子节点互相指向的话，可能会出现互相引用\n- 使用 `weak_ptr` 指向父节点，用于避免父节点和子节点之间的循环引用。这样可以确保内存被正确管理，不会发生内存泄漏。\n```c\nstruct TreeNode { \n\tint value; \n\tshared_ptr<TreeNode> left; \n\tshared_ptr<TreeNode> right;\n\tweak_ptr<TreeNode> parent; // 使用 weak_ptr 打破循环引用 TreeNode(int val) : value(val) {} };\n```\n\n### API\n| API                        | 作用                               | 示例                               | 备注                             |\n|----------------------------|----------------------------------|----------------------------------|--------------------------------|\n| weak_ptr<T>(shared_ptr<T>) | 从 shared_ptr 创建 weak_ptr         | weak_ptr<int> wp = sp;           | weak_ptr 只是观察者，不增加引用计数         |\n| lock()                     | 尝试提升为 shared_ptr                 | shared_ptr<int> sp2 = wp.lock(); | 如果资源仍然存在，返回有效 shared_ptr，否则返回空 |\n| expired()                  | 检查管理的对象是否已销毁                     | if (wp.expired()) { ... }        | 如果 shared_ptr 已销毁，返回 true      |\n| use_count()                | 获取 weak_ptr 观察的 shared_ptr 的引用计数 | size_t count = wp.use_count();   | 只有在对象未销毁时有效                    |\n| reset()                    | 释放 weak_ptr 所观察的资源               | wp.reset();                      | 使 weak_ptr 不再观察任何对象            |\n- **expired()** 方法可以检查所观察的对象是否已被销毁，适合需要检查资源是否仍然有效的场景\n### 其他\n##### 指针转换\n- **unique_ptr可以转换为shared_ptr**，反之不行：\n\t可以通过`std::move`将`unique_ptr`的所有权转移给`shared_ptr`\n```c\n   std::unique_ptr<int> uptr = std::make_unique<int>(42);\n   std::shared_ptr<int> sptr = std::move(uptr);  // 合法，uptr变为nullptr\n```\n.\n    但反过来，`shared_ptr` 不能安全地转换为 `unique_ptr`，因为会违反`unique_ptr`的独占性语义\n\n- **weak_ptr和shared_ptr可以互相转换**\n\t`weak_ptr`本身不能直接使用（它们没有运算符->）。\n\t要使用 `weak_ptr`，必须先将其使用`lock()`方法转换为 `shared_ptr`，然后你可以使用 `shared_ptr`。\n```c\n    shared_ptr<int> sp = make_shared<int>(42); // 创建一个 shared_ptr\n    weak_ptr<int> wp = sp;  // 由 shared_ptr 创建 weak_ptr\n\n    if (shared_ptr<int> sp2 = wp.lock()) {  // 尝试提升 weak_ptr，如果所有 shared_ptr 都已释放，就会转换失败\n        cout << \"成功转换，值为：\" << *sp2 << std::endl;\n    } else {\n        cout << \"转换失败，资源已释放\" << std::endl;\n    }\n```\n\n- weak_ptr和shared_ptr完全不能互相转换\n\n##### 三种指针区别总结\n\n| 特性             | std::shared_ptr                                      | std::unique_ptr                                      | std::weak_ptr                                     |\n|----------------|------------------------------------------------------|------------------------------------------------------|---------------------------------------------------|\n| 所有权            | 共享所有权 (多个 shared_ptr 可以管理同一对象)                       | 独占所有权 (唯一 unique_ptr 管理对象)                           | 无所有权 (只是观察 shared_ptr，不影响对象生命周期)                  |\n| 引用计数           | 有 (多个 shared_ptr 共享管理)                               | 无 (独占管理)                                             | 有 (但不增加对象引用计数)                                    |\n| 可否为空           | 可以为空                                                 | 可以为空                                                 | 可以为空                                              |\n| 可否拷贝           | 可以拷贝 (增加引用计数)                                        | 不可拷贝 (只能移动)                                          | 可以拷贝 (但不会增加引用计数)                                  |\n| 可否移动           | 可以移动 (引用计数保持一致)                                      | 可以移动 (转移所有权)                                         | 可以移动 (不会影响原对象)                                    |\n| 适用场景           | 需要多个对象共享资源                                           | 需要独占资源                                               | 需要观察但不管理资源                                        |\n| 如何释放           | 所有 shared_ptr 释放后，资源自动销毁                             | 离开作用域或 reset() 时销毁                                   | 不影响资源，shared_ptr 释放后对象销毁                          |\n| 转换到 shared_ptr | 不需要转换，直接使用                                           | 不能直接转换                                               | 需要使用 lock() 方法                                    |\n| 线程安全           | use_count 线程安全，修改对象本身需要额外同步                          | 线程不安全，需手动同步                                          | 线程安全，lock() 是原子操作                                 |\n| 示例             | std::shared_ptr<int> sp = std::make_shared<int>(10); | std::unique_ptr<int> up = std::make_unique<int>(10); | std::weak_ptr<int> wp = sp; auto sp2 = wp.lock(); |\n","tags":["c++"],"categories":["note","c++学习笔记"]},{"title":"c++学习笔记——智能指针—shared_ptr","url":"/2025/03/12/note/c++学习笔记/智能指针—shared_ptr/","content":"## shared_ptr\nshared_ptr 旨在解决需要多个智能指针共同拥有资源的情况，因此有多个 std：：shared_ptr 指向同一个资源是可以的\n\t- 在内部，std：：shared_ptr 会跟踪有多少 std：：shared_ptr 共享资源\n\t- 当只要至少有一个 std：：shared_ptr 指向资源时，，即使单个 std：：shared_ptr 被销毁，也不会释放该资源。即当最后一个 std：：shared_ptr 超出范围（或被重新分配以指向其他内容），资源将被解除分配\n- 注意创建共享指针的方式，后续的指针要复制现有的指针来创建\n```cpp\n{\n// allocate a Resource object and have it owned by std::shared_ptr\n\tResource* res { new Resource };\n\tstd::shared_ptr<Resource> ptr1{ res };\n\t{\n\t\t//请注意，我们从第一个共享指针创建了第二个共享指针\n\t\tstd::shared_ptr<Resource> ptr2 { ptr1 }; // make another std::shared_ptr pointing to the same thing\n\t\t\n\t\t//错误做法：\n\t\t//相当于创建了两个彼此独立的 std：：shared_ptr。因此，即使它们都指向同一个 Resource，它们也不知道彼此。\n\t\t//shared_ptr<Resource> ptr2 { res };\n\n\t\tstd::cout << \"Killing one shared pointer\\n\";\n\t} // 当 ptr2 超出范围时，不会解除分配 Resource，因为 ptr1 仍指向 Resource。ptr2 goes out of scope here, but nothing happens\n\n\tstd::cout << \"Killing another shared pointer\\n\";\n}//当 ptr1 超出范围时，ptr1 会注意到没有更多的 std：：shared_ptr 来管理 Resource，因此它会解除分配 Resource。\n```\n\n也可以使用make_shared（）创建，更简单、更安全（使用此方法无法创建两个指向同一资源但彼此不知道的独立 std：：shared_ptr）。\n```cpp\n\t// allocate a Resource object and have it owned by std::shared_ptr\n\tauto ptr1 { make_shared<Resource>() };\n\t{\n\t\tauto ptr2 { ptr1 }; // create ptr2 using copy of ptr1\n\n\t\tstd::cout << \"Killing one shared pointer\\n\";\n\t} // ptr2 goes out of scope here, but nothing happens\n\n\tstd::cout << \"Killing another shared pointer\\n\";\n```\n\n**shared_ptr的原理**：\n\tshared_ptr 在内部使用**两个指针**。\n\t- 一个指针指向正在管理的资源。\n\t- 另一个指向 “控制块”，这是一个动态分配的对象，用于跟踪一堆东西，包括有多少 std：：shared_ptr 指向资源（**引用计数**）。**拷贝或赋值构造的shared_ptr会共享同一个控制块**\n- 当shared_ptr超出范围时，它的析构函数会检查引用计数是否为0，为0就释放资源\n- 通过 std：：shared_ptr 构造函数创建 std：：shared_ptr 时，托管对象（通常传入）和控制块（构造函数创建）的内存将单独分配。\n- 但是，当使用 std：：make_shared（） 时，可以将为资源和控制块优化为单个连续的内存分配，从而获得更好的性能。\n- 当使用复制分配克隆 std：：shared_ptr 时，可以适当地更新控制块中的数据，以指示现在有其他 std：：shared_ptr 共同管理资源\n\n\n**存在的问题**：\n\tshared_ptr 有一些与unique_ptr 相同的挑战 -- 如果 std：：shared_ptr 没有被正确释放（要么是因为它是动态分配的并且从未被删除，要么是动态分配的对象的一部分，从未被删除），那么它所管理的资源也不会被释放。\n\t使用 std：：unique_ptr，你只需要担心一个智能指针被正确处理。使用 std：：shared_ptr，你得操心。**如果管理资源的任何 std：：shared_ptr 未正确销毁，则不会正确释放该资源**\n\t\n**循环引用**：每个对象引用下一个对象，最后一个对象引用回第一个对象，从而产生引用循环。对于三个指针，当 A 指向 B，B 指向 C，C 指向 A 时，你会得到同样的结果\n\t例如下面的shared_ptr的循环引用，当 ptr1 超出范围时，不会释放 Resource，因为 Resource 的 m_ptr 正在共享 Resource。\n\t释放 Resource 的唯一方法是将 m_ptr 设置为其他内容（因此不再共享 Resource）。但是我们无法访问 m_ptr因为 ptr1 超出了范围，因此我们不再有办法执行此操作。\n```cpp\nclass Resource\n{\npublic:\n\tstd::shared_ptr<Resource> m_ptr {}; // initially created empty\n\n\tResource() { std::cout << \"Resource acquired\\n\"; }\n\t~Resource() { std::cout << \"Resource destroyed\\n\"; }\n};\n\nint main()\n{\n\tauto ptr1 { std::make_shared<Resource>() };\n\n\tptr1->m_ptr = ptr1; // m_ptr is now sharing the Resource that contains it\n\n\treturn 0;\n}\n```\n对于循环引用的问题需要weak_ptr解决\n\n### 线程安全性\n\n1.  **引用计数**是线程安全的：\n- `shared_ptr`内部通过原子操作管理**引用计数**（`use_count`）和**弱引用计数**（`weak_count`）\n- 因此对不同线程创建和释放各自的`shared_ptr`实例（即使它们指向同一对象），是线程安全的\n```c\n// 线程1操作 ptr1，线程2操作 ptr2（两者指向同一对象）\nstd::shared_ptr<int> ptr1 = std::make_shared<int>(42);\nstd::shared_ptr<int> ptr2 = ptr1;  // 拷贝构造，引用计数原子增加\n\n// 线程1操作 ptr1.reset()，线程2操作 ptr2.reset()：安全\n```\n2. **指向对象的操作不是线程安全的**：\n- `shared_ptr`仅管理对象的生命周期，**不保证对象内部数据的线程安全**。\n- 若多个线程通过不同的`shared_ptr`实例访问同一对象，仍需通过锁或其他机制保护对象的数据\n```c\nstd::shared_ptr<Data> data_ptr = std::make_shared<Data>();\n\n// 线程1：\n{\n    std::lock_guard<std::mutex> lock(data_mutex);\n    data_ptr->modify();  // 需加锁保护对象\n}\n\n// 线程2：\n{\n    std::lock_guard<std::mutex> lock(data_mutex);\n    data_ptr->read();  // 需加锁保护对象\n}\n\n```\n\nC++20 引入了`std::atomic<std::shared_ptr>`，允许原子地修改`shared_ptr`实例\n```c\n#include <atomic>\nstd::atomic<std::shared_ptr<int>> atomic_ptr;\n\n// 线程1：\natomic_ptr.store(std::make_shared<int>(42), std::memory_order_release);\n\n// 线程2：\nauto ptr = atomic_ptr.load(std::memory_order_acquire);\n\n```\n\n顺便一提weak_ptr的线程安全性：在多线程环境中，`weak_ptr`可用于跨线程观察资源状态，而无需担心引用计数的线程安全问题\n\n### API\n\n| API                     | 作用              | 示例                               | 备注                                  |\n| ----------------------- | --------------- | -------------------------------- | ----------------------------------- |\n| shared_ptr<T>           | 创建 shared_ptr   | shared_ptr<int> sp(new int(10)); | 直接使用 new 可能导致异常时内存泄漏，推荐 make_shared |\n| make_shared<T>(args...) | 创建 shared_ptr   | auto sp = make_shared<int>(10);  | 推荐使用，比 new 性能更好（减少一次内存分配）           |\n| operator*               | 解引用获取对象         | int val = *sp;                   | 访问指针管理的对象                           |\n| operator->              | 访问对象成员          | sp->method();                    | 适用于指向类对象的 shared_ptr                |\n| use_count()             | 获取引用计数          | size_t count = sp.use_count();   | 仅供调试，不建议用于逻辑控制                      |\n| unique()                | 判断是否是唯一所有者      | if (sp.unique()) { ... }         | true 表示当前 shared_ptr 是唯一拥有者         |\n| get()                   | 获取原始指针          | int* rawPtr = sp.get();          | 不会增加引用计数                            |\n| reset(ptr = nullptr)    | 释放当前对象并管理新对象    | sp.reset(new int(20));           | 释放旧对象，避免内存泄漏                        |\n| swap(other)             | 交换两个 shared_ptr | sp1.swap(sp2);                   | 交换管理的对象                             |\n| operator bool           | 检查是否为空          | if (sp) { ... }                  |                                     |\n\n\n### 手撕shared_ptr\n参考：https://zhuanlan.zhihu.com/p/384894475\n##### 结构\n\n- 基础构造函数\n- 复制语义\n- 移动语义\n- 一些[工具函数](https://zhida.zhihu.com/search?content_id=169441123&content_type=Article&match_order=1&q=%E5%B7%A5%E5%85%B7%E5%87%BD%E6%95%B0&zhida_source=entity)\n- 析构函数\n\n##### 基础构造函数\n\n假设我们现在在技术面现场, 面试官让手写一个`shared_ptr`, `shared_ptr`里面有多少东西呀一团乱麻怎么开始写? 别慌, 我们先把最简单的结构写上:\n\n```text\ntemplate<class T>\nclass my_shared_ptr\n{\n    private:\n    T * m_ptr = nullptr;\n    unsigned int * m_ref_count = nullptr;\n    public:\n    //默认构造函数\n    my_shared_ptr(): m_ptr(nullptr), m_ref_count(nullptr){}\n    my_shared_ptr(T * ptr): m_ptr(ptr), m_ref_count(new unsigned int(1)){}\n};\n```\n\n##### 复制语义 (Copy Semantics)\n\n接下来我们加上复制构造函数(copy constructor)和复制赋值运算符(copy assignment operator):\n\n```text\n/* 复制语义 */\n//复制构造函数\nmy_shared_ptr(const my_shared_ptr & obj)\n{\n    m_ptr = obj.m_ptr;\n    m_ref_count = obj.m_ref_count;\n    if(m_ref_count!=nullptr)\n    {\n        (*m_ref_count)++;\n    }    \n}\n\n//赋值运算符\nmy_shared_ptr& operator=(const my_shared_ptr & obj)\n{\n    if(obj.m_ptr == m_ptr)\n    {\n        return *this;\n    }\n\n    //先处理原有的指针和引用计数\n    if(m_ref_count!=nullptr)\n    {\n        (*m_ref_count)--;\n        if(*m_ref_count==0)\n        {\n            delete m_ptr;\n            delete m_ref_count;\n        }\n    }\n\n    //再处理赋值\n    m_ptr = obj.m_ptr;\n    m_ref_count = obj.m_ref_count;\n\n    if(m_ref_count!=nullptr)\n    {\n        (*m_ref_count)++;\n    }\n    return *this;\n}\n```\n\n##### 移动语义 (Move Semantics)\n\n接着我们写移动构造函数(move constructor)和移动赋值运算符(move assignment operator):\n\n```text\n/*移动语义*/\n    //移动构造函数\n    my_shared_ptr(my_shared_ptr && dying_obj): \n    m_ptr(nullptr),\n    m_ref_count(nullptr)\n    {\n        //初始化后交换指针和引用计数, 等于清除了原shared_ptr的内容\n        dying_obj.swap(*this);\n    }\n\n    //移动赋值运算符\n    my_shared_ptr & operator=(my_shared_ptr && dying_obj)\n    {\n        //my_shared_ptr(std::move(dying_obj))用移动构造函数创建出一个新的shared_ptr(此时dying_obj的内容被清除了)\n        //再和this交换指针和引用计数\n        //因为this的内容被交换到了当前的临时创建的my_shared_ptr里，原this指向的引用计数-1\n        my_shared_ptr(std::move(dying_obj)).swap(*this);\n        return *this;\n    }\n\n    void swap(my_shared_ptr & other)\n    {\n        std::swap(m_ptr, other.m_ptr);\n        std::swap(m_ref_count, other.m_ref_count);\n    }\n```\n\n##### 一些工具函数\n\n指针相关的运算符重载以及获取引用计数\n\n```text\nT* operator->() const\n    {\n        return m_ptr;\n    }\n\n    T& operator*() const\n    {\n        return *m_ptr;\n    }\n\n    T* get() const\n    {\n        return m_ptr;\n    }\n\n    //以及获取引用计数\n    unsigned int use_count() const\n    {\n        return *m_ref_count;\n    }\n```\n\n##### 析构函数\n\n```text\n//析构函数\n    ~my_shared_ptr()\n    {\n        if(m_ref_count==nullptr)\n        {\n            return;\n        }\n        (*m_ref_count)--;\n        if (*m_ref_count > 0)\n        {\n            return;\n        }\n\n        if (m_ptr != nullptr)\n        {\n            delete m_ptr;\n        }\n        delete m_ref_count;\n    }\n```\n\n##### 整合以及测试\n\n```text\n#include <iostream>\n#include <memory>\n\nusing namespace std;\n\ntemplate<class T>\nclass my_shared_ptr\n{\n    private:\n    T * m_ptr = nullptr;\n    unsigned int * m_ref_count = nullptr;\n    public:\n    //默认构造函数\n    my_shared_ptr(): m_ptr(nullptr), m_ref_count(nullptr){}\n    my_shared_ptr(T * ptr): m_ptr(ptr), m_ref_count(new unsigned int(1)){}\n\n    /* 复制语义 */\n    //复制构造函数\n    my_shared_ptr(const my_shared_ptr & obj)\n    {\n        m_ptr = obj.m_ptr;\n        m_ref_count = obj.m_ref_count;\n        if(m_ref_count!=nullptr)\n        {\n            (*m_ref_count)++;\n        }    \n    }\n\n    //赋值运算符\n    my_shared_ptr& operator=(const my_shared_ptr & obj)\n    {\n        if(obj.m_ptr == m_ptr)\n        {\n            return *this;\n        }\n\n        //先处理原有的指针和引用计数\n        if(m_ref_count!=nullptr)\n        {\n            (*m_ref_count)--;\n            if(*m_ref_count==0)\n            {\n                delete m_ptr;\n                delete m_ref_count;\n            }\n        }\n\n        //再处理赋值\n        m_ptr = obj.m_ptr;\n        m_ref_count = obj.m_ref_count;\n\n        if(m_ref_count!=nullptr)\n        {\n            (*m_ref_count)++;\n        }\n        return *this;\n    }\n\n    /*移动语义*/\n    //移动构造函数\n    my_shared_ptr(my_shared_ptr && dying_obj): \n    m_ptr(nullptr),\n    m_ref_count(nullptr)\n    {\n        //初始化后交换指针和引用计数, 等于清除了原shared_ptr的内容\n        dying_obj.swap(*this);\n    }\n\n    //移动赋值运算符\n    my_shared_ptr & operator=(my_shared_ptr && dying_obj)\n    {\n        //my_shared_ptr(std::move(dying_obj))用移动构造函数创建出一个新的shared_ptr(此时dying_obj的内容被清除了)\n        //再和this交换指针和引用计数\n        //因为this被交换到了当前的临时创建的my_shared_ptr里，this的引用计数-1\n        my_shared_ptr(std::move(dying_obj)).swap(*this);\n        return *this;\n    }\n\n    void swap(my_shared_ptr & other)\n    {\n        std::swap(m_ptr, other.m_ptr);\n        std::swap(m_ref_count, other.m_ref_count);\n    }\n\n    T* operator->() const\n    {\n        return m_ptr;\n    }\n\n    T& operator*() const\n    {\n        return m_ptr;\n    }\n\n    T* get() const\n    {\n        return m_ptr;\n    }\n\n    //以及获取引用计数\n    unsigned int use_count() const\n    {\n\n        return m_ref_count!=nullptr? *m_ref_count : 0;\n    }\n\n    //析构函数\n    ~my_shared_ptr()\n    {\n        if(m_ref_count==nullptr)\n        {\n            return;\n        }\n        (*m_ref_count)--;\n        if (*m_ref_count > 0)\n        {\n            return;\n        }\n\n        if (m_ptr != nullptr)\n        {\n            delete m_ptr;\n        }\n        delete m_ref_count;\n    }\n\n};\n\nstruct A{\n    std::string m_str;\n    A(std::string s): m_str(s)\n    {\n        cout<<\"ctor:\"<<m_str<<endl;\n    }\n\n    ~A()\n    {\n        cout<<\"dtor:\"<<m_str<<endl;\n    }\n};\n\n\nint main()\n{\n    cout<< \"default constructor\" <<endl;\n    my_shared_ptr<A> empty_ptr;\n    cout << (empty_ptr.use_count()==0) << endl;\n    my_shared_ptr<A> a_ptr(new A(\"a\"));\n    cout << (a_ptr.use_count()==1) << endl;\n\n    cout<< \"copy constructor\" <<endl;\n    my_shared_ptr<A> copied_ptr(a_ptr);\n    cout << (a_ptr.use_count()==2) << endl;\n    cout << (copied_ptr.use_count()==2) << endl;\n\n    cout<< \"copy assignment\" <<endl;\n    my_shared_ptr<A> b_ptr(new A(\"b\"));\n    b_ptr = b_ptr;\n    cout << (b_ptr.use_count()==1) << endl;\n    my_shared_ptr<A> b_copy(b_ptr);\n    b_ptr = a_ptr;\n    cout << (a_ptr.use_count()==3) << endl;\n    cout << (b_ptr.use_count()==3) << endl;\n    cout << (b_copy.use_count()==1) << endl;\n\n    cout<<\"move constructor\"<<endl;\n    my_shared_ptr<A> move_ctor_ptr(std::move(a_ptr));\n    cout << (move_ctor_ptr.use_count()==3) << endl;\n    cout << (a_ptr.use_count()==0) << endl;\n\n    cout<<\"move assignment\"<<endl;\n    my_shared_ptr<A> b_ptr_observer = b_ptr;\n    cout << (b_ptr.use_count()==4) << endl;\n    cout << (b_ptr_observer.use_count()==4) << endl;\n\n    my_shared_ptr<A> move_assign_ptr(new A(\"c\"));\n    my_shared_ptr<A> move_assign_ptr_observer=move_assign_ptr;\n    cout << (move_assign_ptr.use_count()==2) << endl;\n    cout << (move_assign_ptr_observer.use_count()==2) << endl;\n\n    move_assign_ptr = std::move(b_ptr);\n    cout << (b_ptr.use_count()==0) << endl;\n    cout << (move_assign_ptr.use_count()==b_ptr_observer.use_count()) << endl;\n    cout << (b_ptr_observer.use_count()==4) << endl;\n    cout << (move_assign_ptr_observer.use_count()==1) << endl;\n\n    return 0;\n}\n```","tags":["c++"],"categories":["note","c++学习笔记"]},{"title":"c++学习笔记——智能指针—unique_ptr","url":"/2025/03/12/note/c++学习笔记/智能指针—unique_ptr/","content":"\n## unique_ptr\n作为auto_ptr的替代，unique_ptr单独拥有和管理资源， 位于 < memory>中\n```c\n#include <iostream>\n#include <memory> // for std::unique_ptr\n\nclass Resource\n{\npublic:\n\tResource() { std::cout << \"Resource acquired\\n\"; }\n\t~Resource() { std::cout << \"Resource destroyed\\n\"; }\n};\n\nint main()\n{\n\t// allocate a Resource object and have it owned by std::unique_ptr\n\tstd::unique_ptr<Resource> res{ new Resource() };\n\n\treturn 0;\n} // res goes out of scope here, and the allocated Resource is destroyed\n```\n\nunique_ptr正确实现了移动语义，禁用了复制初始化和复制分配\n```cpp\n\t// res2 = res1; //无法复制和赋值 Won't compile: copy assignment is disabled\n\tres2 = move(res1); // 将 res1 转换为 r 值，然后res1的资源将转移到res2 ， res 1就变为nullptr\n```\n\nunique_ptr 可能并不总是在管理对象 -- 要么是因为它是空的（使用默认构造函数或传入 nullptr 作为参数），要么是因为它管理的资源被移动到另一个 unique_ptr。\n\t可以检查unique_ptr是否在管理资源\n```cpp\n\tif (res) // use implicit cast to bool to ensure res contains a Resource\n\t\tstd::cout << *res << '\\n'; // print the Resource that res is owning\n```\n\nauto_ptr 不同，unique_ptr 足够智能，可以用于标量对象和数组。\n\n### make_unique\nC++14 附带一个名为 std：：make_unique（） 的附加函数来构造unique指针，建议使用make_unique（）创建\n1. 创建单个对象\n通过模板指定对象类型，并传递构造参数：\n```c\nauto ptr = std::make_unique<MyClass>(arg1, arg2);  // 调用 MyClass 的构造函数\n   auto int_ptr = std::make_unique<int>(10);\n```\n2. 创建动态数组\n使用 make_unique<T[]>(size) 创建数组，但需手动初始化元素：\n```c\nauto arr = std::make_unique<int[]>(5);  // 创建含 5 个 int 元素的数组   \n   for (int i = 0; i < 5; ++i) {\n       arr[i] = i;  // 手动初始化元素\n   }\n```\n   \n   \n```cpp\n\t// Create a single dynamically allocated Fraction with numerator 3 and denominator 5\n\t// We can also use automatic type deduction to good effect here\n\tauto f1{ make_unique<Fraction>(3, 5) };\n\tstd::cout << *f1 << '\\n';\n\n\t// Create a dynamically allocated array of Fractions of length 4\n\tauto f2{ make_unique<Fraction[]>(4) };\n\tstd::cout << f2[0] << '\\n';\n```\n**异常安全**: make_unique封装了new操作，将对象的内存分配和构造封装为一个原子操作，完成后立即由unique_ptr管理，避免了因异常导致的内存泄漏。\n因此优先用 make_unique 代替 new + unique_ptr 的组合。\n### 返回unique_ptr\nunique_ptr 可以按值安全地从函数返回：\n\t这里将采用移动语义将 Resource 从createResource的临时返回值（右值）传输到分配给的对象ptr（C++17 或更高版本中，返回将被省略）\n```cpp\nstd::unique_ptr<Resource> createResource()\n{\n     return std::make_unique<Resource>();\n}\n\nint main()\n{\n    auto ptr{ createResource() };\n\n    // do whatever\n\n    return 0;\n}\n```\n\n#### 传递unique_ptr\n如果希望函数获取指针内容的所有权，请按值传递 unique_ptr。\n\t请注意，由于复制语义已被禁用，unique_ptr不能直接按值传递\n\t因此您需要使用 move 来实际传入变量。\n```cpp\n// This function takes ownership of the Resource, which isn't what we want\nvoid takeOwnership(std::unique_ptr<Resource> res)    //传入的unique_ptr将所有权转移到了res，而当函数调用结束res也将被销毁（也就是说会导致传入的unique_ptr所指向的对象将不存在）\n{\n     if (res)\n          std::cout << *res << '\\n';\n} // the Resource is destroyed here\n\nint main()\n{\n    auto ptr{ std::make_unique<Resource>() };\n\n//    takeOwnership(ptr); // 错误，This doesn't work, need to use move semantics\n    takeOwnership(std::move(ptr)); // 将左值转换为右值，触发移动语义\n\n    std::cout << \"Ending program\\n\";\n\n    return 0;\n}\n```\n\n若不需要转移所有权，可以按引用传递unique_ptr\n```cpp\n// The function only uses the resource, so we'll accept a pointer to the resource, not a reference to the whole std::unique_ptr<Resource>\nvoid useResource(const unique_ptr<Resource>& resUPtr)\n{\n\tif (resUPtr)\n\t\tstd::cout << *resUPtr << '\\n';\n\telse\n\t\tstd::cout << \"No resource\\n\";\n}\n\nint main()\n{\n\tauto ptr{ std::make_unique<Resource>() };\n\n\tuseResource(ptr.get()); // note: get() used here to get a pointer to the Resource\n\n\tstd::cout << \"Ending program\\n\";\n\n\treturn 0;\n} // The Resource is destroyed here\n```\n\n也可以通过const 的**对象指针**只传递对象本身，然后使用 unique_ptr 的get（） 成员函数，获取原始指针\n```cpp\n// The function only uses the resource, so we'll accept a pointer to the resource, not a reference to the whole std::unique_ptr<Resource>\nvoid useResource(const Resource* resPtr)\n{\n\tif (resPtr)\n\t\tstd::cout << *resPtr << '\\n';\n\telse\n\t\tstd::cout << \"No resource\\n\";\n}\n\nint main()\n{\n\tauto ptr{ std::make_unique<Resource>() };\n\n\tuseResource(ptr.get()); // note: get() used here to get a pointer to the Resource\n\n\tstd::cout << \"Ending program\\n\";\n\n\treturn 0;\n} // The Resource is destroyed here\n```\n\n**NOTE**：\n\t1. 不要让多个unique_ptr对象管理同一个资源。\n\t虽然这在语法上是合法的，但最终结果是 res1 和 res2 都将尝试删除 Resource，这将导致未定义的行为\n```cpp\nstd::unique_ptr<Resource> res1{ res };\nstd::unique_ptr<Resource> res2{ res };\n\t```\n.\n\t2.不要从 构造unique_ptr 之后又手动删除资源\n\t如果这样做，unique_ptr 将尝试删除已删除的资源，再次导致未定义的行为。\n```cpp\nstd::unique_ptr<Resource> res1{ res };\ndelete res;\n```\n- make_unique（） 可以防止上述两种情况无意中发生\n\n### API\n\n| API                                 | 作用              | 示例                                   | 备注                                  |\n| ----------------------------------- | --------------- | ------------------------------------ | ----------------------------------- |\n| unique_ptr<T>                       | 创建 unique_ptr   | unique_ptr<int> uptr(new int(10));   | 直接使用 new 可能导致异常时内存泄漏，推荐 make_unique |\n| make_unique<T>(args...)             | 创建 unique_ptr   | auto uptr = make_unique<int>(10);    | 安全高效，推荐使用                           |\n| operator*                           | 解引用获取对象         | int val = *uptr;                     | 访问指针管理的对象                           |\n| operator->                          | 访问对象成员          | uptr->method();                      | 适用于指向类对象的 unique_ptr                |\n| get()                               | 获取原始指针          | int* rawPtr = uptr.get();            | **不会释放所有权**                         |\n| release()                           | 释放所有权并返回原始指针    | int* rawPtr = uptr.release();        | 需要手动 delete rawPtr                  |\n| reset(ptr = nullptr)                | 释放当前对象并管理新对象    | uptr.reset(new int(20));             | 释放旧对象，避免内存泄漏                        |\n| swap(other)                         | 交换两个 unique_ptr | uptr1.swap(uptr2);                   | 交换管理的对象                             |\n| operator bool                       | 检查是否为空          | if (uptr) { ... }                    | 为空时返回 false                         |\n| 移动构造 unique_ptr<T>(unique_ptr<T>&&) | 通过移动构造函数转移所有权   | unique_ptr<int> uptr2 = move(uptr1); | uptr1 变为空，uptr2 接管所有权               |\n| 移动赋值 operator=(unique_ptr<T>&&)     | 通过移动赋值转移所有权     | uptr2 = move(uptr1);                 |                                     |\n**NOTE**：\n- **避免直接使用 new**，推荐使用 make_unique。\n- **慎用 release()**，调用后 unique_ptr 不再管理对象，需手动 delete\n- **使用 reset() 替换对象**，避免内存泄漏","tags":["c++"],"categories":["note","c++学习笔记"]},{"title":"CUDA笔记——LayerNorm算子","url":"/2025/03/03/note/cuda/AI infra/CUDA笔记——LayerNorm算子/","content":"Layer Normalization 目的为减少深度神经网络中层与层之间的 [Covariate Shift](https://zhida.zhihu.com/search?content_id=242568926&content_type=Article&match_order=1&q=Covariate+Shift&zhida_source=entity)，提高网络收敛速度。\n具体实现见：[layernorm_forward.cu](https://github.com/karpathy/llm.c/blob/master/dev/cuda/layernorm_forward.cu#L98C1-L111C2)\n## [LayerNorm](https://zhida.zhihu.com/search?content_id=242568926&content_type=Article&match_order=1&q=LayerNorm&zhida_source=entity) 前向过程的实现\n\n假设待归一化的 m 维向量为x，均值和标准差分别是 μ 和 σ，LayerNorm的参数是w  和 b ，那么层归一化后的输出为：\n\t![|400](CUDA笔记——LayerNorm算子/img-LayerNorm-4.png)\n\t这里的乘法是element_wise乘法\n\t均值：  $\\mu = \\frac{1}{m} \\sum_{i=1}^{m} x_i$\n\t标准差：\t  $\\sigma = \\sqrt{\\frac{1}{m} \\sum_{i=1}^{m} (x_i - \\mu)^2}$\n\n例如对于输入 x 形状为 `(N, C, H, W)`， normalized_shape 为 (H, W) 的情况，可以理解为输入 x\n为 `(N*C, H*W)`，在 `N*C` 个行上，每行有 `H*W `个元素，**对每行的元素求这一行的均值和标准差**，得到 `N*C` 个 μ 和 σ，再对输入按上面的 LayerNorm 的计算公式对**每一行的每个元素**进行计算得到 y\n### cpu实现\n\n输入输出参数：\n```text\nint B, int T, int C  // 输入输出shape，默认为 8, 1024, 768\nconst float* inp   // 输入x，shape为 [B, T, C]\nfloat* mean, float* rstd  // 输入x的均值\\mu, 及标准差的倒数 1/\\sigma, 该值随机初始化后传入，前向完成后得到结果并在反向过程中重复使用\nconst float* weight, const float* bias  // 可学习的权重及偏置，随机初始化后传入\nfloat* out  // 输出，shape为 [B, T, C]\n```\n\n计算步骤：\n- 计算数组x=\\[b\\]\\[c\\] 在维度 C 上的均值及方差\n- 计算标准差的倒数 rstd\n- 对数组x上每一个点x\\[i\\]进行归一化，写回output\\[i\\]\n```c\nvoid layernorm_forward_cpu(float* out, float* mean, float* rstd,\n                       const float* inp, const float* weight, const float* bias,\n                       int B, int T, int C) {\n    float eps = 1e-5f;\n    for (int b = 0; b < B; b++) {\n        for (int t = 0; t < T; t++) {\n            // seek to the input position inp[b,t,:]\n            // 在C维度进行归一化的数组开始位置,即[b][t][0]\n            const float* x = inp + b * T * C + t * C;\n            // calculate the mean\n            float m = 0.0f;\n            for (int i = 0; i < C; i++) {\n                m += x[i];\n            }\n            m = m/C;\n            \n            // calculate the variance (without any bias correction)\n            float v = 0.0f;\n            for (int i = 0; i < C; i++) {\n                float xshift = x[i] - m;\n                v += xshift * xshift;\n            }\n            v = v/C;\n            \n            // calculate the rstd\n            float s = 1.0f / sqrtf(v + eps);\n            // seek to the output position in out[b,t,:]\n            float* out_bt = out + b * T * C + t * C;\n            for (int i = 0; i < C; i++) {\n                float n = (s * (x[i] - m)); // normalized output\n                float o = n * weight[i] + bias[i]; // scale and shift it\n                out_bt[i] = o; // write\n            }\n            // cache the mean and rstd for the backward pass later\n            mean[b * T + t] = m;\n            rstd[b * T + t] = s;\n        }\n    }\n}\n```\n\n### cuda实现 V1\n由于 LayerNorm 的计算都是在维度 C 上进行，因此将 \\[B, T\\] 维度映射到一维，然后对外循环进行并行，一个线程负责一个C维度数组x的所有元素归一化\n```c\n// naive drag and drop implementation into kernel, parallelize over B,T, loop over C\n__global__ void layernorm_forward_kernel1(float* out, float* mean, float* rstd,\n                                 const float* inp, const float* weight, const float* bias,\n                                 int N, int C) {\n    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n    float eps = 1e-5f;\n\n    if (idx < N) {\n        // seek to the input position inp[idx,:]\n        //该线程负责的x数组\n        const float* x = inp + idx * C;\n        // calculate the mean\n        float m = 0.0f;\n        for (int i = 0; i < C; i++) {\n            m += x[i];\n        }\n        m = m / C;\n        // calculate the variance (without any bias correction)\n        float v = 0.0f;\n        for (int i = 0; i < C; i++) {\n            float xshift = x[i] - m;\n            v += xshift * xshift;\n        }\n        v = v / C;\n        // calculate the rstd\n        float s = 1.0f / sqrtf(v + eps);\n        // seek to the output position in out[idx,:]\n        float* out_idx = out + idx * C;\n        for (int i = 0; i < C; i++) {\n            float n = (s * (x[i] - m)); // normalized output\n            float o = n * weight[i] + bias[i]; // scale and shift it\n            out_idx[i] = o; // write\n        }\n        // cache the mean and rstd for the backward pass later\n        mean[idx] = m;\n        rstd[idx] = s;\n    }\n}\n```\n\n调用kernel\n```c\nvoid layernorm_forward1(float* out, float* mean, float* rstd,\n                           const float* inp, const float* weight, const float* bias,\n                           int B, int T, int C,\n                           const int block_size) {\n    const int N = B * T;     //B、T维度合并\n    const int grid_size = ceil_div(N, block_size);\n    layernorm_forward_kernel1<<<grid_size, block_size>>>(out, mean, rstd, inp, weight, bias, N, C);\n    cudaCheck(cudaGetLastError());\n}\n```\n\n### cuda实现 V2\n求均值和标准差可以使用规约求和实现，因此可以使用3个算子分别实现 求均值、求标准差、归一化\n求均值算子：\n\t上一个算子中，是一个线程负责一个C维度数组x的计算\n\t这里一个block负责一个C维度数组x的均值计算\n```c\n__global__ void mean_kernel(float* mean, const float* inp, int N, int C, int block_size) {\n    extern __shared__ float shared[];    //shared[block_size]\n    int idx = blockIdx.x; // range [0, B*T)\n    int tid = threadIdx.x; // range [0, block_size)\n    const float* x = inp + idx * C;       //一个block负责一个x\n    // thread coarsening\n    // x折叠到block_size大小\n    float sum = 0.0f;\n    for (int i = tid; i < C; i += block_size) {\n        sum += x[i];\n    }\n    shared[tid] = sum;\n    __syncthreads();\n    // reductions\n    for (int stride = block_size / 2; stride >= 1; stride /= 2) {\n        __syncthreads();\n        if (tid < stride) {\n            shared[tid] += shared[tid + stride];\n        }\n    }\n    // write the final result (at thread 0) to global memory\n    if (tid == 0) {\n        mean[idx] = shared[0] / C;\n    }\n}\n```\n\n归一化算子：\n\t三维映射到一维，一个线程负责一个x\\[i\\]的归一化\n```c\n__global__ void normalization_kernel(float* out, const float* inp, float* mean, float* rstd,\n                                     const float* weight, const float* bias, int B, int T, int C) {\n    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n\t//[bt][c]\n    int bt = idx / C;\n    int c = idx % C;\n\n    float m = mean[bt];\n    float s = rstd[bt];\n    float xi = inp[idx];\n    float n = s * (xi - m);\n    float o = n * weight[c] + bias[c];\n\n    out[idx] = o;\n}\n```\n3个算子调用：\n```c\n    int N = B * T;\n    // in mean and rstd, threads cooperate within blocks via reductions\n    mean_kernel<<<N, block_size, block_size * sizeof(float)>>>(mean, inp, N, C, block_size);\n\n    rstd_kernel<<<N, block_size, block_size * sizeof(float)>>>(rstd, inp, mean, N, C, block_size);\n\n    // in the normalization, everything just gets flattened out\n    const int block_size2 = 256;\n    const int grid_size = ceil_div(B * T * C, block_size2);\n    normalization_kernel<<<grid_size, block_size2>>>(out, inp, mean, rstd, weight, bias, B, T, C);\n\n\n```\n\n也可以全部写在一个算子里\n```c\ntemplate <typename T>\n\n__global__ void layerNormKernel(const T *pInput, const T *gamma, const T *beta, T *pOutput, const int block_size,\n\nconst int nDim)\n\n{\n\nconst int tx = threadIdx.x;\n\nconst int index = blockIdx.x * nDim;\n\n  \n\n// 每个 block 处理一行nDim大小的样本的入口\n\nconst T *input = pInput + index;\n\n  \n\n// 动态共享内存声明（只声明一次）\n\n// __shared__ T temp[256] blocksize=256\n\nextern __shared__ T temp[];\n\n  \n\n// 计算均值：每个线程累加部分和\n\nT sum = 0;\n\nfor (int i = tx; i < nDim; i += block_size)\n\n{\n\nsum += input[i];\n\n}\n\ntemp[tx] = sum;\n\n__syncthreads();\n\n  \n\nfor (int stride = block_size / 2; stride >= 1; stride /= 2)\n\n{\n\nif (tx < stride)\n\n{\n\ntemp[tx] += temp[tx + stride];\n\n}\n\n__syncthreads();\n\n}\n\nT mean = temp[0] / static_cast<T>(nDim); // 均值\n\n__syncthreads();\n\n  \n\n// 计算方差：每个线程计算自己的平方差部分和\n\nsum = 0;\n\nfor (int i = tx; i < nDim; i += block_size)\n\n{\n\nT diff = input[i] - mean;\n\nsum += diff * diff;\n\n}\n\ntemp[tx] = sum;\n\n__syncthreads();\n\n  \n\nfor (int stride = block_size / 2; stride >= 1; stride /= 2)\n\n{\n\nif (tx < stride)\n\n{\n\ntemp[tx] += temp[tx + stride];\n\n}\n\n__syncthreads();\n\n}\n\nT var = temp[0] / static_cast<T>(nDim); // 方差\n\n  \n\n// 对每个输入做归一化并应用 gamma, beta\n\nT *output = pOutput + index;\n\nconst T epsilon = 6e-6;\n\nfor (int i = tx; i < nDim; i += block_size)\n\n{\n\noutput[i] = (input[i] - mean) * static_cast<T>(rsqrtf(var + epsilon)) * gamma[i] + beta[i];\n\n}\n\n}\n```","tags":["cuda"],"categories":["note","cuda","AI infra"]},{"title":"CUDA笔记——内存模型","url":"/2025/02/18/note/cuda/CUDA笔记——内存模型/","content":"CUDA内存模型总览：\n![|400](CUDA笔记——内存模型/img-CUDA笔记——内存模型-0.png)\n### 全局内存\n容量大，延迟高，所有线程共享\n分配的device端内存默认都是使用的全局内存\n- 静态分配：\\_ \\_device\\_ \\_声明，cudaMemcpyToSymbol分配\n```c\n\t__device__ int globalArray[256];\n\tint main (){\n\n    // 将数据从主机拷贝到设备全局内存\n    cudaMemcpyToSymbol(globalArray, hostData, sizeof(int) * 256);\n    \n   // 将数据从设备全局内存拷回主机\n    cudaMemcpyFromSymbol(hostData, globalArray, sizeof(int) * 256);\n\t}\n```\n\n- 动态分配：cudaMalloc 和 cudaFree\n\t```c\n\tint* devArray;\n\tcudaMalloc((void**)&devArray, sizeof(int) * 256); // 分配全局内存\n\n\tcudaMemcpy(devArray, hostData, sizeof(int) * 256, cudaMemcpyHostToDevice); // 拷贝数据到设备\n\n\t// 将数据从设备拷回主机\n    cudaMemcpy(hostData, devArray, sizeof(int) * 256, cudaMemcpyDeviceToHost);\n    // 释放全局内存\n    cudaFree(devArray);\n\t```\n\n- 全局内存最小访问单元是1个 **sector**(32字节)。\n\t- 也就是说warpy一次访存最少读取32字节\n\n>访问全局内存的次序： L1-> L2-> 全局内存\n>**L1 cache**：cache miss时最小访问单元是 4 sector（原则上）。\n>**L2 cache**：cache miss时最小访问单元是1 sector。\n\n### 共享内存\n位于**片内**，靠近每个sm处理器内核的轻量级低延迟内存（类似于L1缓存）\n每个SM都有一个共享内存，被执行的block划分，GPU通常会限制单个block使用的共享内存大小\n\t- 使用方法：使用__shared__声明，详情请看共享内存一章\n\n### 寄存器\n位于片内。寄存器直接集成在GPU核心中，数据读写几乎没有延迟，访问速度是所有GPU内存中最快的。\n- 每个线程拥有自己的寄存器空间，不同线程之间的寄存器是私有的，互不共享。\n- 如果线程使用的寄存器过多，可能会导致寄存器溢出，从而导致性能下降。GPU通常会将超出寄存器的变量存储到本地内存（片外）中，但本地内存访问速度较慢。\n\n### 缓存\nGPU有两级**L1缓存**和**L2缓存**\n\n**1. L1缓存**\n• **位置**：L1缓存位于片内，每个**SM**的本地，接近于SP。\n• **功能**：L1缓存存储的是频繁访问的局部数据、寄存器内容以及常用的全局内存数据。\n• **容量**：通常每个SM的L1缓存容量较小，在16KB到64KB之间。\n• **专用性**：L1缓存主要服务于本地线程和线程块，减少跨线程块或跨SM的共享负载。\n\n\n\n**2. L2缓存**\n\n• **位置**：L2缓存位于GPU的全局层次，跨越整个GPU的多个SM。\n• **功能**：L2缓存用于存储较大范围的共享数据，帮助多个SM之间的数据交换。它通常缓存从全局内存加载的数据，以减少全局内存访问延迟。\n• **较大容量**：L2缓存的容量通常比L1缓存大，可能达到数百KB到几MB。\n• **共享性**：L2缓存用于多个SM之间的数据共享，帮助减少全局内存访问的瓶颈。\n• **较高的访问延迟**：虽然L2缓存比全局内存快，但相对于L1缓存来说，访问延迟更高。\n\n**合并访存**：缓存会尽可能合并warp的访存请求，减少对内存的访问次数\n### 常量内存\n位于**片外**，设备端只读，生命周期为整个应用。\n一般为 64KB，因此适合存储小型、频繁访问的**常量数据**。\n\t- 当所有线程访问同一地址时，常量内存的访问效率最高（广播机制）。\n\t- 因为是只读，不存在缓存一致性的问题\n\t- 使用方法,\\_ \\_constant\\_ \\_声明，cudaMemcpyToSymbol从主机拷贝数据，在kernel中直接使用，无需手动释放\n```c\n\t__constant__ float constData[256];\n\tint main（）{\n\t    cudaMemcpyToSymbol(constData, hostData, sizeof(float) * 256);\n\t}\n```\n\n延迟：全局内存>常量内存>共享内存>寄存器\n\n| 内存类型 | 描述                                | 特点                         |\n|------|-----------------------------------|----------------------------|\n| 全局内存 | 存储在GPU上的主内存，所有线程都可以访问             | 容量大，访问延迟高，适合存储大量数据         |\n| 共享内存 | 每个线程块（Block）内的线程可以共享的内存区域         | 访问速度快，容量小，仅限于同一线程块内的线程使用   |\n| 常量内存 | 用于存储只读数据，所有线程都可以访问                | 高效读取，适合存储不经常修改的数据（例如常量）    |\n| 纹理内存 | 用于存储纹理数据，适用于图像处理和渲染相关操作           | 支持缓存，适合处理空间局部性较强的数据        |\n| 寄存器  | 每个线程拥有自己的私有寄存器用于存储局部变量            | 访问速度极快，但数量有限，且线程之间不可共享     |\n| 设备内存 | GPU上的物理内存，可以分配给不同的内存类型，如全局内存和共享内存 | 包括所有的内存层次，指的是GPU上所有类型的物理内存 |\n| 统一内存 | 在CPU和GPU之间共享的内存区域，允许两者直接访问        | 提供统一的内存空间，简化开发，但性能较低       |\n| 本地内存 | 每个线程独立的内存区域，通常用于存储无法放入寄存器的变量      | 容量较小，速度较慢，通常用于存储大于寄存器空间的数据 |\n","tags":["cuda"],"categories":["note","cuda"]},{"title":"c++学习笔记——模板","url":"/2025/02/17/note/c++学习笔记/模板/","content":"**泛型编程**：运行程序员在编写代码时使用一些以后才指定的类型，在[实例化](https://zh.wikipedia.org/wiki/%E5%AE%9E%E4%BE%8B \"实例\")时作为参数指明这些类型。C++中称之为模板\n\tC++使用关键字` template <typename T>` 设置模板。模板类型参数T将作为占位符类型，被替换为参数传入的类型。\n> <\\> 中也可以传入非类型参数，如 template <typename T, int size\\>， 其中size是非类型参数\n> 非类型参数包括：整型、指针引用、浮点类型（c++20） 。 使用时，**传入非类型参数的值必须是constexpr值**\n\n\n模板类实例：\n```cpp\ntemplate <typename T> // added\nclass Array\n{\nprivate:\n    int m_length{};\n    T* m_data{}; // changed type to T\n\npublic:\n\n    Array(int length)\n    {\n        assert(length > 0);\n        m_data = new T[length]{}; // allocated an array of objects of type T\n        m_length = length;\n    }\n\n    Array(const Array&) = delete;\n    Array& operator=(const Array&) = delete;\n\n    ~Array()\n    {\n        delete[] m_data;\n    }\n\n    void erase()\n    {\n        delete[] m_data;\n        // We need to make sure we set m_data to 0 here, otherwise it will\n        // be left pointing at deallocated memory!\n        m_data = nullptr;\n        m_length = 0;\n    }\n\n    // templated operator[] function defined below\n    T& operator[](int index); // now returns a T&\n\n    int getLength() const { return m_length; }\n};\n// member functions defined outside the class need their own template declaration\ntemplate <typename T>\nT& Array<T>::operator[](int index) // now returns a T&\n{\n    assert(index >= 0 && index < m_length);\n    return m_data[index];\n}\n\nint main()\n{\n\tconst int length { 12 };\n\tArray<int> intArray { length };\n\tArray<double> doubleArray { length };\n\treturn 0;\n}\n```\nNOTE:\n\t1. 在类声明外部定义的每个模板化成员函数都需要自己的模板声明 Array<T\\>。 类内部的Array使用可以省略<T\\>\n\n### 模板实例化\n模板的实例化方式：编译器制作一个**副本**，将模板参数替换为用户需要的实际数据类型，然后编译该副本。\n\t模板未被使用时，编译器不会对其代码进行完整的语法检查和编译\n\n**模板类的实例化**：\n- 与普通类不同，为了执行实例化，编译器必须同时看到完整的类模板定义（而不仅仅是声明）和所需的特定模板类型。\n- 因此不能将类定义放在标头中，而将成员函数定义放在 .cpp 文件中。\n\n解决模板类函数未实例化的方法：\n\t1. 将所有模板类代码放在头文件.h中,而不是将模板定义放在.cpp文件中\n\t2. 也可以将模板的.cpp 的内容移动到名为 .inl 内联文件中，在.h文件中包含.inl\n\t3. 添加第三个文件管理模板，并在这个文件中包含所有要实例化的类。\n\t\t 例如下面实例中，“template class” 命令使编译器显式实例化 template 类。编译器将在 templates.cpp 中模版化 Array<int\\> 和 Array<double\\> 的定义。\n```cpp\n// Ensure the full Array template definition can be seen\n#include \"Array.h\"\n#include \"Array.cpp\" // we're breaking best practices here, but only in this one place\n\n// #include other .h and .cpp template definitions you need here\n\ntemplate class Array<int>; // Explicitly instantiate template Array<int>\ntemplate class Array<double>; // Explicitly instantiate template Array<double>\n\n// instantiate other templates here\n```\n\n### 函数模版专用化\n允许我们为特定类型或值显式定义模板的不同实现。\n- 当所有模板参数都是专用化时，它称为**完全专用化**。\n- 当只有某些模板参数是专用化的时，它称为**部分专用化**。\n\t- 部分模板专用化只能用于类成员函数，而不能用于模板函数\n\t- 模板函数必须是完全专用化的\n```cpp\n// Here's our primary template (must come first)\ntemplate <typename T>\nvoid print(const T& t)\n{\n    std::cout << t << '\\n';\n}\n\n// A full specialization of primary template print<T> for type double\n// Full specializations are not implicitly inline, so make this inline if put in header file\ntemplate<>                          // template parameter declaration containing no template parameters\nvoid print<double>(const double& d) // specialized for type double\n{\n    std::cout << std::scientific << d << '\\n';\n}\n\nint main()\n{\n    print(5);\n\tprint(6.7);            //调用print<double>(const double& d)\n\n    return 0;\n}\n```\n\n上面例子中的模板专有化\n\t1. 首先，我们需要一个模板参数声明，这样编译器就知道我们正在做一些与模板相关的事情。但是，在这种情况下，我们实际上不需要任何模板参数，因此我们使用一对空的尖括号。\n\t2. 专用化必须与主模板具有相同的签名（除了专用化在主模板使用 `T` 的任何地方都会替换 `double`）。由于主模板具有 `const T&` 类型的参数，因此专用化必须具有 `const double&` 类型的参数。当主模板使用 引用传参时，专用化不能使用值传参（反之亦然）。\n```cpp\ntemplate<>                          // template parameter declaration containing no template parameters\nvoid print<double>(const double& d) // specialized for type double\n```\n注意，匹配时永远是精确匹配的非模板函数优先于模板函数。\n通常，应尽可能避免使用函数模板专用化，而应使用非模板函数。\n\n>完全特化不是隐式内联的（部分特化是隐式内联的）。\n>如果您将完整的专用化放在头文件中，则应将其标记为`内联`，以便在包含在多个翻译单元中时不会导致 ODR 冲突。\n\n### 类模版专用化\n类模板特化允许我们为特定数据类型（或数据类型，如果有多个模板参数）专门化模板类。\n**类模板特化被视为完全独立的类**，即使它们的实例化方式与模板化类相同。\n\t相当于允许有多个同名但不同实现的类\n```cpp\n#include <cstdint>\n\n// First define our non-specialized class template\ntemplate <typename T>\nclass Storage8\n{\nprivate:\n    T m_array[8];\n\npublic:\n    void set(int index, const T& value)\n    {\n        m_array[index] = value;\n    }\n\n    const T& get(int index) const\n    {\n        return m_array[index];\n    }\n};\n\n// Now define our specialized class template\ntemplate <> // the following is a template class with no templated parameters\nclass Storage8<bool> // we're specializing Storage8 for bool\n{\n// What follows is just standard class implementation details\n\nprivate:\n    std::uint8_t m_data{};\n\npublic:\n    // Don't worry about the details of the implementation of these functions\n    void set(int index, bool value)\n    {\n        // Figure out which bit we're setting/unsetting\n        // This will put a 1 in the bit we're interested in turning on/off\n        auto mask{ 1 << index };\n\n        if (value)  // If we're setting a bit\n            m_data |= mask;   // use bitwise-or to turn that bit on\n        else  // if we're turning a bit off\n            m_data &= ~mask;  // bitwise-and the inverse mask to turn that bit off\n\t}\n\n    bool get(int index)\n    {\n        // Figure out which bit we're getting\n        auto mask{ 1 << index };\n        // bitwise-and to get the value of the bit we're interested in\n        // Then implicit cast to boolean\n        return (m_data & mask);\n    }\n};\n\n// Same example as before\nint main()\n{\n    // Define a Storage8 for integers (instantiates Storage8<T>, where T = int)\n    Storage8<int> intStorage;\n\n    for (int count{ 0 }; count < 8; ++count)\n    {\n        intStorage.set(count, count);\n\t}\n\n    for (int count{ 0 }; count < 8; ++count)\n    {\n        std::cout << intStorage.get(count) << '\\n';\n    }\n\n    // Define a Storage8 for bool  (instantiates Storage8<bool> specialization)\n    Storage8<bool> boolStorage;\n\n    for (int count{ 0 }; count < 8; ++count)\n    {\n        boolStorage.set(count, count & 3);\n    }\n\n\tstd::cout << std::boolalpha;\n\n    for (int count{ 0 }; count < 8; ++count)\n    {\n        std::cout << boolStorage.get(count) << '\\n';\n    }\n\n    return 0;\n}\n```\n上面例子中，当我们实例化对象类型 `Storage<T>`（其中 `T` 不是bool值）时，我们将从泛型模板化 `Storage8<T>` 类中获得一个版本模板。当我们实例化 `Storage8<bool>` 类型的对象时，我们将获得专用版本。\n\n**NOTE**：\n\t- 为了使用专用类，编译器必须能够看到非专用类和专用类的完整定义。因此专用类和函数通常在非专用类定义正下方的头文件中定义\n\t- 单独在文件中使用专用类：如果在单个翻译单元中只需要专用化，则可以在该翻译单元的源文件中定义该专业化。由于其他翻译单位将无法看到专业化的定义，因此它们将继续使用非专业化版本。\n#### 成员函数的专有化\n例如下面我们需要专有化`Storage`的成员函数`print()`, 使其使用科学计数法打印double类型变量。\n- 我们不需要我们显式地专用化 `Storage<double>` 来显式专用化 `Storage<double>：:p rint（）`\n- 可以让编译器从 `Storage<T>` 隐式特化 `Storage<double>`，并仅提供 `Storage<double>：:p rint（） 的`显式特化！这是它的样子：\n```cpp\ntemplate <typename T>\nclass Storage\n{\nprivate:\n    T m_value {};\npublic:\n    Storage(T value)\n      : m_value { value }\n    {\n    }\n\n    void print()\n    {\n        std::cout << m_value << '\\n';\n    }\n};\n\n// This is a specialized member function definition\n// Explicit function specializations are not implicitly inline, so make this inline if put in header file\ntemplate<>\nvoid Storage<double>::print()\n{\n    std::cout << std::scientific << m_value << '\\n';\n}\nint main()\n{\n    // Define some storage units\n    Storage i { 5 };\n    Storage d { 6.7 }; // will cause Storage<double> to be implicitly instantiated\n\n    // Print out some values\n    i.print(); // calls Storage<int>::print (instantiated from Storage<T>)\n    d.print(); // calls Storage<double>::print (called from explicit specialization of Storage<double>::print())\n}\n```\n注意，显式函数特化不是隐式内联的，因此，如果在头文件中定义了 `Storage<double>：:p rint（）` 的特化，我们应该将其标记为内联。","tags":["c++"],"categories":["note","c++学习笔记"]},{"title":"CUDA笔记——合并访存和矩阵转置","url":"/2025/02/16/note/cuda/CUDA笔记——合并访存和矩阵转置/","content":"## 合并访存\n\n合并访存：当同一**warp**中的线程访问**连续且对齐**的全局内存地址时，硬件可将这些访问合并为单个或更少的内存事务。这样通过合并访问内存事务来增加内存带宽利用率\n> \t- 例如，32个线程（一个warp）访问连续的32个`float`（每个4字节），合并为一次128字节的事务。\n 读全局内存的基本单位是1 sector，即32 byte\n\n合并率： warp请求的字节数 /  请求传输的总字节数。 合并率越高，访存性能越好\n合并访存是在一个wrap中，因此要以wrap负责的数据来调整\n\n### add1\n正常的读写连续且对齐的内存，每天指令请求的4个sector中的数据都得到了利用，合并率100%\n![](CUDA笔记——合并访存和矩阵转置/img-合并访存-ddac88da-c650-45c8-acce-c0b0fe975fc0.png)\n\n### add2\n不对齐的读取数据（不从头开始访问），会造成多发送了一个sector，合并率 = 128/ （32 * 5）= 80%\n![](CUDA笔记——合并访存和矩阵转置/img-合并访存-a069dde9-4db2-405e-a9c5-38375f0aebef.png)\n\n### add3\n线程乱序访问，当warp整体访问的内存还是连续且对齐的，性能与add1一样\n![](CUDA笔记——合并访存和矩阵转置/img-合并访存-fa49fec4-b295-4153-88b9-6fcfa7e68d16.png)\n### add4\nwarp中每个线程都读写同一个数据，虽然只要一个float，但读取内存至少要1个sector，造成了浪费\n![](CUDA笔记——合并访存和矩阵转置/img-合并访存-71e359d4-611f-4d43-9cd4-acf89c938fd7.png)\n### add5\n每个线程读写的数据之间间隔4，导致了线程读写内存之间是不连续的，要读取16个连续的sector才能将请求的数据覆盖到，合并率 = 4/16 = 25%\n![](CUDA笔记——合并访存和矩阵转置/img-合并访存-1ab0f54a-eee4-4c2d-83d7-f70f2ac4c274.png)\n\n## 矩阵转置\nnative实现：\n```cpp\n/* N是长，M是宽*/\n__global__ void transpose_naive(float* input, float* output,int N, int M)\n{\n    // 原矩阵上点列id和行id\n    //注意y是行\n    int col_idx = blockIdx.x * blockDim.x + threadIdx.x;\n    int row_idx = blockIdx.y * blockDim.y + threadIdx.y;\n\n    // 这里input和output使用的都是一级指针，因此需要算出来每个点\n    // 在原始matrix上相对于Input的偏移\n    // 在transpose后的matrix上相对于output的偏移\n    if (col_idx < N && row_idx < M) {\n       // M * N的矩阵\n       int idx = row_idx * N + col_idx;\n       // N * M的矩阵\n       // 原matrix上的行、列变成新matrix上的列、行\n       int trans_idx = col_idx * M + row_idx;\n       output[trans_idx] = input[idx];\n    }\n}\n```\n### 改变线程的排布\n改变线程的排布可以提高合并率\n#### v1\n- 对于输入M=2048， N=512的矩阵，block_size取width=32, height=8,结果如下:\n![](CUDA笔记——合并访存和矩阵转置/img-合并访存-96c60767-dcc0-43b9-aeb0-4c5fcc553714.png)\n读数据是没有问题的，32个线程取32个float，一共128 byte，即4个sector\n**但写数据时出现了问题**： 32个float写入时的数据是完全不连续的，但每次访存至少读取1个sector，这就造成了28byte * 32 的浪费\n> 这里写数据的合并率为 4/32= 12.5%\n\n#### v2\n- 将线程的排布变成(16,16)\n![](CUDA笔记——合并访存和矩阵转置/img-合并访存-e3c06d15-bc4c-4f15-8c0a-882badb8ca94.png)\n这时4个sector分布在两行，这样增加了写数据的合并率。\n写数据的时候就减少了一个float的浪费，浪费的数据为 24 byte * 32\n\n- 将线程的排布变成(16,16)\n![](CUDA笔记——合并访存和矩阵转置/img-合并访存-3159b4a1-33e5-47f9-943a-d1d7d6fc9215.png)\n这时4个sector分布在4行\n写数据的时候一个sector 里面可以写入4个float的数据，浪费的数据为 16 byte * 32\n\n为什么不能将线程行数一直缩小变成(4,64),(2,128)来提高write的合并率: \n\t这样做会使读数据的时候降低数据的合并率。因为一个float 4 byte，那么读一个sector最多被8个线程利用，如果这8个线程分布在不同行，一次访存取出的sector就会有浪费。\n\t这也启示我们，设置线程数量要尽量确保读写连续的内存，且一次读写至少是32字节，这样就能合并访存\n\t\n### 使用float4\n一个线程处理多个数据，可以提高写数据的合并率\n#### v1_float4\nblockSize还是(32,8)的排布，但是一个线程处理一个4 * 4的矩阵（4个float4数据），先在寄存器中进行转置，然后写会\n写数据的合并率 = 4 * 4 /32 =50%\n![](CUDA笔记——合并访存和矩阵转置/img-合并访存-be147936-6872-49f9-94c7-faec41930de4.png)\n```c\n__global__ void tanspose(float *input, float *output, int N, int M)\n\n{\n    // 先在寄存器内做好转置，再写回output\n    // 因此先声明两个4*4的寄存器数组\n    // 也可以使用共享内存，在block内进行转置，不过可能会出现bank conflict\n\n    int col = (blockDim.x * blockIdx.x + threadIdx.x) * 4; // x是列\n    int row = (blockDim.y * blockIdx.y + threadIdx.y) * 4;\n    if (col >= N || row >= M)\n        return;\n\n    float r_input[4][4];\n    float r_output[4][4];\n\t//取intput[row+i][col]到r_input[i]\n    for (int i = 0; i < 4; i++)\n    {\n        FLOAT4(r_input[i]) = FLOAT4(intput[(row + i) * N + col]);\n    }\n\n    // 4*4矩阵内转置\n    for (int i = 0; i < 4; i++)\n    {\n        FLOAT4(r_output[i]) = make_float4(r_input[0][i], r_input[1][i], r_input[2][i],r_input[3][i]); // 把rinput的列变成float4然后写入routput的行\n    }\n    \n\t// r_output[i]写入output[col+i][row]转置矩阵\n    for (int i = 0; i < 4; i++)\n    {\n        FLOAT4(output[(col + i) * M + row]) = FLOAT4(r_output[i]); \n    }\n\n    return;\n\n}\n```\n\n#### v2_float4\nblockSize修改为(16,16)的排布，那么写入数据就能尽可能地合并访存了\n![](CUDA笔记——合并访存和矩阵转置/img-合并访存-cb75a8fd-0159-48a5-b1af-eff052030fc3.png)\n```c\nint main()\n{\n    dim3 block_size(16, 16);\n    // dim3 grid_size(N / 16, M / 16);\n    dim3 grid_size(CEIL(N/4  /16), CEIL(M/4  / 16));\n}\n```\n\n","tags":["cuda"],"categories":["note","cuda"]},{"title":"CUDA笔记——Nsight调优","url":"/2025/02/11/note/cuda/CUDA笔记——Nsight调优/","content":"\ncuda 的profiling可以简单地分为粗粒度和细粒度。\n- 粗粒度主要是判断瓶颈是不是在GPU上，具体又是哪个kernel，典型代表就是nsight system工具，会显示出整个程序的timeline。可以从timeline上直接清晰明了地看到瓶颈是在CPU还是GPU，如果是GPU，那又是在GPU的哪个kernel上。\n- 细粒度主要是判断kernel或者一个函数里面的性能瓶颈在哪，代表就是nsight compute工具\n## Nsight systems\nsystems主要是用来看timeline，看看程序中的瓶颈是在CPU还是GPU上。\n教程：[Nsight systems](https://docs.nvidia.com/nsight-systems/UserGuide/index.html)\n- 如果是timeline中GPU kernel的占比很小，CPU占比很大，那说明瓶颈在CPU侧，需要注意是不是数据读取花了太多时间。\n- 如果GPU kernel的占比很大，说明瓶颈在GPU侧，需要重点花精力去优化GPU kernel实现。\n- 还有一种情况是，如果数据一直放在GPU上，但是kernel的时间占比不是特别多，那可能是因为kernel本身不太耗时，可能只运行了4us。但kernel lauch就花了6us。这个时间就要想着采用kernel fusion (算子融合) 的方式，尽可能地在一个kernel里面多干点活。\n\n![](CUDA笔记——Nsight调优/img-Nsight调优-6.png)\n\n## Nsight compute\nCompute主要是用来分析具体的kernel实现瓶颈。\n教程：[Nsight compute](https://docs.nvidia.com/nsight-compute/NsightCompute/index.html)\n\n启动ncu：\n```c++\n>ncu-ui\n```\n或者在服务器上用ncu分析出report之后，用自己的电脑上安装的nisght compute打开图形界面\n\nlanch后会显示main中执行的kernel函数\n![[img/Nsight调优-1.png]]\n\n打开kernel后，顶部可以切换kernel\n![[img/Nsight调优-6.png]]\n\n在page处选detail的话，可以先看看的大致的Roofline分析，compute会给出一些建议。\n![[img/Nsight调优-3.png]]\n\n然后是访存图，因为add只访问全局内存，因此其他访存都是0\n![[img/Nsight调优-4.png]]\n\nshare memory表\n![[img/Nsight调优-5.png]]\n\nL1 cache表\n\t下面sector/Req，即每个指令请求的sector数，为5，出现了访存不合并的情况\n\tload是读数据，store是写数据\n![[img/Nsight调优-7.png]]\n\n翻到最后，这里会告诉哪条指令访存没有合并\n![[img/Nsight调优-8.png]]\n\n","tags":["cuda"],"categories":["note","cuda"]},{"title":"c++学习笔记——结构体","url":"/2025/02/02/note/c++学习笔记/结构体/","content":"结构体和类都是C++的复合类型。\n\n#### 初始化\n结构体的初始化可以使用**聚合初始化**\n```cpp\nstruct Employee\n{\n    int id {};\n    int age {};\n    double wage {};\n};\nint main()\n{\n    Employee frank = { 1, 32, 60000.0 }; // copy-list initialization using braced list\n    Employee joe { 2, 28, 45000.0 };     // list initialization using braced list (preferred)\n\n    return 0;\n}\n```\n\n>**聚合数据类型**:是可以包含多个数据成员的任何类型。\n>C++ 中的聚合要么是 C 样式数组，要么是具有以下特征的类类型（结构、类或联合）：\n>\t1. 没有用户声明的构造函数\n>\t2. 无私有或受保护的非静态数据成员\n>\t3. 无虚函数\n>关键是，仅包含数据成员的结构是聚合的\n\n\n如果初始化了聚合，**但初始化值的数量少于成员的数量**，则每个没有显式初始值设定项的成员都将按如下方式初始化：\n\t1. 如果成员具有默认成员初始值设定项，则使用该初始值设定项。\n\t2. 否则，将从空初始值设定项列表复制初始化成员。在大多数情况下，这将对这些成员执行值初始化（在类类型上，即使存在列表构造函数，这也将调用默认构造函数）。\n>-  **结构体也有隐式默认构造函数**，但**不初始化基本类型成员**。\n```cpp\nstruct Employee\n{\n    int id {};\n    int age {};\n    double wage { 76000.0 };\n    double whatever;\n};\n\nint main()\n{\n    Employee joe { 2, 28 }; // joe.whatever will be value-initialized to 0.0\n\n    return 0;\n}\n\njoe.id 将使用值 2 进行初始化，而 joe.age 将使用值 28 进行初始化。由于 joe.wage 没有获得显式初始值设定项，但具有默认成员初始值设定项，因此 joe.wage 将初始化为 76000.0。最后，由于 joe.whatever 没有被赋予显式初始化器，因此 joe.whatever 的值初始化为 0.0。\n```\n\n如果使用空{}初始化，则使用默认成员初始值设定项\n```cpp\nstruct Something\n{\n    int x;       // no default initialization value (bad)\n    int y {};    // value-initialized by default\n    int z { 2 }; // explicit default value\n};\n\nint main()\n{\n    Something s1; // s1.x is uninitialized, s1.y is 0, and s1.z is 2\n    Something s2 {}; // value initialize s2.x, use default values for s2.y and s2.z. s2.x is 0 , s2.y is 0, and s2.z is 2\n\n    return 0;\n}\n\ns1 对象没有初始化器，因此 s1 的成员被初始化为默认值。s1.x 没有默认初始化器，因此它保持未初始化状态。s1.y是默认初始化的值，因此它的值为 0。s1.z 初始化为值 2。\ns2.x（没有默认成员初始值设定项）的值初始化为 0，s2.y 的值初始化为 0，s2.z 的默认值为 2。\n```\n\nC++20 添加了一种称为**指定初始值设定项**的新方法来初始化结构成员。使用指定的初始值设定项，可以显式定义哪些初始化值映射到哪些成员。\n\t必须按照它们在结构中声明的顺序进行初始化，否则将导致警告或错误。\n```cpp\nstruct Foo\n{\n    int a{ };\n    int b{ };\n    int c{ };\n};\n\nint main()\n{\n    Foo f1{ .a{ 1 }, .c{ 3 } }; // ok: f1.a = 1, f1.b = 0 (value initialized), f1.c = 3\n    Foo f2{ .a = 1, .c = 3 };   // ok: f2.a = 1, f2.b = 0 (value initialized), f2.c = 3\n    Foo f3{ .b{ 2 }, .a{ 1 } }; // error: initialization order does not match order of declaration in struct\n\n    return 0;\n}\n```\n\n一个结构也可以使用另一个相同类型的结构进行初始化：\n```cpp\n    Foo foo { 1, 2, 3 };\n\n    Foo x = foo; // copy-initialization\n    Foo y(foo);  // direct-initialization\n    Foo z {foo}; // direct-list-initialization\n```\n\n\n重载 `operator<<` 来打印结构体成员\n```cpp\nstd::ostream& operator<<(std::ostream& out, const Employee& e)\n{\n    out << e.id << ' ' << e.age << ' ' << e.wage;\n    return out;\n}\n\nint main()\n{\n    Employee joe { 2, 28 }; // joe.wage will be value-initialized to 0.0\n    std::cout << joe << '\\n';\n\n    return 0;\n}\n```\n\n#### 传入和返回结构体\n\n通常使用引用传入结构体，避免复制临时对象。\n也可以传入临时的结构体对象\n```cpp\nstruct Employee\n{\n    int id {};\n    int age {};\n    double wage {};\n};\n\nvoid printEmployee(const Employee& employee) // note pass by reference here\n{\n    std::cout << \"ID:   \" << employee.id << '\\n';\n    std::cout << \"Age:  \" << employee.age << '\\n';\n    std::cout << \"Wage: \" << employee.wage << '\\n';\n}\n\nint main()\n{\n    Employee joe { 14, 32, 24.15 };\n    Employee frank { 15, 28, 18.27 };\n\n    // Print Joe's information\n    printEmployee(joe);\n    \n    // Print Joe's information\n    printEmployee(Employee { 14, 32, 24.15 }); // construct a temporary Employee to pass to function (type explicitly specified) (preferred)\n\n    std::cout << '\\n';\n\n    // Print Frank's information\n    printEmployee({ 15, 28, 18.27 }); // construct a temporary Employee to pass to function (type deduced from parameter)\n\n    return 0;\n}\n```\n\n结构体返回通常使用按值返回，避免悬空引用的问题。\n\t例如，返回坐标点结构\n```cpp\nstruct Point3d\n{\n    double x { 0.0 };\n    double y { 0.0 };\n    double z { 0.0 };\n};\n\nPoint3d getZeroPoint()\n{\n    // We can create a variable and return the variable (we'll improve this below)\n    Point3d temp { 0.0, 0.0, 0.0 };\n    return temp;        //temp在表达式结束时销毁\n\n\t/*等价写法\n    return Point3d { 0.0, 0.0, 0.0 }; // return an unnamed Point3d \n\treturn { 0.0, 0.0, 0.0 }; // return an unnamed Point3d \n    return {}; \n\t*/\n}\n\nint main()\n{\n    Point3d zero{ getZeroPoint() };\n}\n```\n\n#### 结构体嵌套\nEmployee作为Company结构对一部分\n```cpp\nstruct Company\n{\n    struct Employee // accessed via Company::Employee\n    {\n        int id{};\n        int age{};\n        double wage{};\n    };\n\n    int numberOfEmployees{};\n    Employee CEO{}; // Employee is a struct within the Company struct\n};\n\nint main()\n{\n    Company myCompany{ 7, { 1, 32, 55000.0 } }; // Nested initialization list to initialize Employee\n    std::cout << myCompany.CEO.wage << '\\n'; // print the CEO's wage\n\n    return 0;\n}\n```\n#### 结构体大小\n结构体会对成员数据进行数据对齐\n对齐规则：\n\t1、第一个成员在与结构体偏移量为0的地址处。\n\t2、其他成员变量要对齐到某个数字（对齐数）的整数倍的地址处\n\t\t**对齐数 = 编译器默认的对齐数与该成员大小的较小值。**\n\t\t**数组的对齐数** = **数组类型的对齐数**\n\t\t在前一个成员结束的偏移量之后，编译器会寻找满足其对齐数的整数倍下一个地址偏移。如果当前偏移量不能满足该成员的对齐数的整数倍，则在成员前插入若干个字节的“对齐填充（Padding）”，以让该成员对齐到正确的地址。\n\t3、结构体总大小为最大对齐数的整数倍。\n>**自然对齐**：数据的内存地址是数据大小的倍数，这样 CPU能最有效地执行对内存的读写，因为cpu取数据是按n位数据取，例如32位系统每次取数据按32位也就是4字节整数倍取。例如，在 32 位体系结构中，如果数据存储在 4 个连续字节中，并且第一个字节位于 4 字节边界上，则数据可能会对齐。\n>**数据对齐**是元素根据其自然对齐方式进行对齐。为了确保自然对齐，可能需要在结构元素之间或结构的最后一个元素之后插入一些填充。\n>\n```cpp\nstruct Foo\n{\n    short a {};\n    int b {};\n    double c {};\n};\n\nint main()\n{\n    std::cout << \"The size of short is \" << sizeof(short) << \" bytes\\n\";\n    std::cout << \"The size of int is \" << sizeof(int) << \" bytes\\n\";\n    std::cout << \"The size of double is \" << sizeof(double) << \" bytes\\n\";\n\n    std::cout << \"The size of Foo is \" << sizeof(Foo) << \" bytes\\n\";\n\n    return 0;\n}\n\nshort + int + double 的大小是 14 字节，但 Foo 的大小是 16 字节！\n```\n\n不同的声明顺序会导致不同的结构体大小。\n\t可以通过按照类型大小降序声明来实现最小化填充\n```cpp\nstruct Foo1\n{\n    short a{}; // will have 2 bytes of padding after a\n    int b{};\n    short c{}; // will have 2 bytes of padding after c\n};\n\nstruct Foo2\n{\n    int b{};\n    short a{};\n    short c{};\n};\n\nint main()\n{\n    std::cout << sizeof(Foo1) << '\\n'; // prints 12\n    std::cout << sizeof(Foo2) << '\\n'; // prints 8\n\n    return 0;\n}\n```\n\n再举个例子\n```c\nstruct MixedData\n{\n    char  Data1;  // 1字节\n    short Data2;  // 2字节\n    int   Data3;  // 4字节\n    char  Data4;  // 1字节\n};\n```\n1. **最大对齐单位**\n结构体内部成员的最大类型为 int，其对齐要求是 4 字节，因此整个结构体的对齐单位也将是 4 字节。换言之，结构体的总大小需要是 4 的整数倍。\n2. **成员排布和填充**\n• Data1（1 字节）位于偏移量 0 处。写入后指针移动到偏移量 1。\n• **为了保证 Data2（2 字节）按照 2 字节对齐**，编译器会在 Data1 后面插入 1 字节的 **对齐填充（padding）**，使得 Data2 的起始地址是 2 的倍数。此时偏移量变为 2。\n• Data2 写入后占用 2 字节（偏移量 [2, 3]），接着偏移量变为 4。\n• Data3（4 字节）要求 4 字节对齐，当前偏移量正好是 4，满足要求，因此直接写入占用偏移量 [4, 7]，随后偏移量变为 8。\n• Data4（1 字节）写入后占用偏移量 8（仅 1 字节），结束后偏移量变为 9。\n3. **结构体结尾对齐**\n由于结构体整体要对齐到 4 的倍数，所以在末尾需要补足 3 个字节的填充，使得结构体总大小变为 12。\n\n下面重新排布顺序后，结构体大小将是8字节\n```c\nstruct MixedData  /* after reordering */\n{\n    char Data1;\n    char Data4;   /* reordered */\n    short Data2;\n    int Data3;\n};\n```","tags":["c++"],"categories":["note","c++学习笔记"]},{"title":"c++学习笔记——引用和指针","url":"/2025/01/26/note/c++学习笔记/引用和指针/","content":"## 左值和右值\n左值表达式是计算结果为函数或可识别对象（包括变量）的表达式，这些表达式在表达式末尾之后仍然存在。\n右值表达式是计算结果为值的表达式，包括文本和临时对象，这些表达式不会在表达式末尾之后保留。\n\t临时对象：它们是在定义时创建和初始化的，并且在创建它们的完整表达式结束时销毁。\n\n左值在等号右边的时候将隐式转换为右值，而右值不会隐式转换为左值。\n```cpp\n    int x{ 1 };\n    int y{ 2 };\n\n    x = y; // y is not an rvalue, but this is legal\n```\n\n接受右值的参数：**按值传递和按 const 引用传递**可以接受右值，不包括按非 const 引用传递和按地址传递。\n\n## 引用\n**引用**是现有对象的别名。引用本质上与被引用的对象相同（**指向同一内存地址**），我们可以使用引用来读取或修改被引用的对象。\n\t- 与常量非常相似，所有引用都必须在开始初始化。\n\t- 当一个引用被一个对象（或函数）初始化时，我们说它被**绑定到**那个对象（或函数）。\n\t- 如果尝试将引用绑定到与其引用类型不匹配的对象，编译器将尝试将**对象隐式转换**为引用类型，然后将引用绑定到该类型。\n\t- **引用的生命周期和引用对象的生命周期是独立的**\n\t\t- 临时引用被销毁不会影响被引用的对象\n\t\t- 当被引用的对象在引用之前被销毁时，该引用将引用不再存在的对象。此类引用称为**悬空引用**。访问悬空引用会导致未定义的行为。\n\t- 引用在 C++ 中不是对象。**引用不需要存在或占用存储空间**。\n\t- 引用绑定后，无法重新绑定新引用的对象\n```cpp\n    int x { 5 };\n    int y { 6 };\n\n    int& ref { x }; // ref is now an alias for x\n\n    ref = y; // assigns 6 (the value of y) to x (the object being referenced by ref)\n    // The above line does NOT change ref into a reference to variable y!\n\n    std::cout << x << '\\n'; // user is expecting this to print 5\n\n输出：6\nref并没有从x重新绑定到y，而是将x=y，让x的值变成了y\n```\n\n可以用引用来初始化引用，两个引用都会绑定同一对象\n```cpp\nint var{};\nint& ref1{ var };  // an lvalue reference bound to var\nint& ref2{ ref1 }; // an lvalue reference bound to var\n```\n#### 左值引用\n##### 非 const 左值引用\n只能绑定到非 const 左值的引用，**不能绑定到const左值和右值**\n```cpp\n    int x { 5 }; // normal integer variable\n    int& ref { x }; // ref is an lvalue reference variable that can now be used as an alias for variable x\n    std::cout << x << ref << '\\n'; // print 55\n\n    x = 6; // x now has value 6\n\n    std::cout << x << ref << '\\n'; // prints 66\n\n定义引用时，通常将 & 符号放在类型旁边\n```\n非 const 左值引用不能绑定到不同类型的对象，这是因为**对象隐式转换的结果是右值**，非 const 左值引用不能绑定右值\n```cpp\n    int x { 5 };\n    int& ref { x };            // okay: referenced type (int) matches type of initializer\n\n    double d { 6.0 };\n    int& invalidRef { d };     // invalid: conversion of double to int is narrowing conversion, disallowed by list initialization\n    double& invalidRef2 { x }; // invalid: non-const lvalue reference can't bind to rvalue (result of converting x to double)\n```\n\n##### const 左值引用\n可以绑定到几乎所有值，包括右值和可以隐式转换为引用类型的不同类型的值\n\n为了避免出现悬空引用，C++ 有一个特殊规则：当 const 左值引用直接绑定到临时对象时，**临时对象的生存期将延长以匹配引用的生存期**。\n\t注意，当将不同类型的参数传递给 const 左值引用时，将会**拷贝一个原类型参数的副本**来进行隐式类型转换，然后再将临时副本绑定到引用\n```cpp\n    // case 1\n    const double& r1 { 5 };  // temporary double initialized with value 5, r1 binds to temporary\n    std::cout << r1 << '\\n'; // prints 5\n\n    // case 2\n    char c { 'a' };\n    const int& r2 { c };     // temporary int initialized with value 'a', r2 binds to temporary\n    std::cout << r2 << '\\n'; // prints 97 (since r2 is a reference to int)\n\n在情况 1 中，将创建一个 `double` 类型的临时对象，并使用 int 值 `5` 进行初始化。然后 `const double& r1` 被绑定到那个临时的 double 对象。\n\n在情况 2 中，将创建一个 `int` 类型的临时对象，并使用 char 值 `a` 进行初始化。然后 `const int& r2` 绑定到那个临时的 int 对象。\n```\n\nconst 的左值引用绑定到可修改的左值时，就不能通过引用修改被引用的对象。\n```cpp\n    int x { 5 };          // x is a modifiable lvalue\n    const int& ref { x }; // okay: we can bind a const reference to a modifiable lvalue\n    ref = 7;                  // error: we can not modify an object through a const reference\n    x--;                   //ok\n```\n\n\n\n##### constexpr 左值引用\n因为限制较多，用的较少\nConstexpr 引用有一个特殊的限制：它们**只能绑定到具有静态持续时间的对象**（全局或静态局部变量）。constexpr 引用不能绑定到 （非静态） 局部变量。\n\t这是因为编译器知道 static 对象将在内存中的哪个位置实例化，因此它可以将该地址视为编译时常量。\n```cpp\nint g_x { 5 };\n\nint main()\n{\n    [[maybe_unused]] constexpr int& ref1 { g_x }; // ok, can bind to global\n\n    static int s_x { 6 };\n    [[maybe_unused]] constexpr int& ref2 { s_x }; // ok, can bind to static local\n\n    int x { 6 };\n    [[maybe_unused]] constexpr int& ref3 { x }; // compile error: can't bind to non-static object\n\n    return 0;\n}\n```\n当定义对 const 变量的 constexpr 引用时，我们需要同时应用 `constexpr`（适用于引用）和 `const`（适用于被引用的类型）。\n```cpp\n    static const int s_x { 6 }; // a const int\n    [[maybe_unused]] constexpr const int& ref2 { s_x }; // needs both constexpr and const\n```\n\n##### 按左值引用传参\n按值传递参数的话，会创建原参数的临时副本，然后在函数调用结束后销毁。按值传递本身性能上就比较差，而且对于某些大参数来说复制的成本很高\n\n**按引用传递**则可以避免成本高昂的参数复制\n```cpp\nvoid printValue(string& y) // type changed to std::string&\n{\n    std::cout << y << '\\n';\n} // y is destroyed here\n```\n\n由于非 const 左值引用绑定的限制，非const左值引用只能传递非const左值变量\n```cpp\n    const int z { 5 };\n    printValue(z); // error: z is a non-modifiable lvalue\n\n    printValue(5); // error: 5 is an rvalue\n\n传递const左值和右值都会报错\n```\n\n而const左值引用，则可以传递const和非const左值、右值，同时还保证函数无法更改被引用的值。\n```cpp\nvoid printRef(const int& y) // y is a const reference\n{\n    std::cout << y << '\\n';\n}\n\nint main()\n{\n    int x { 5 };\n    printRef(x);   // ok: x is a modifiable lvalue, y binds to x\n\n    const int z { 5 };\n    printRef(z);   // ok: z is a non-modifiable lvalue, y binds to z\n\n    printRef(5);   // ok: 5 is rvalue literal, y binds to temporary int object\n\n    return 0;\n}\n```\n\n注意，如果将不同类型的参数传递给 const 左值引用参数，该值会转换为引用的类型。**转换的过程将创建一个临时对象**，然后引用参数可以绑定到该对象。\n\t因为对象副本的创建，按不同类型的参数传递给 const 左值引用参数的性能可能还不如按值传递\n\t因此使用按引用传递时，请**确保参数的类型与引用的类型匹配**，否则将导致意外的（并且可能代价高昂的）转换。\n```cpp\nvoid printVal(double d)\n{\n    std::cout << d << '\\n';\n}\n\nvoid printRef(const double& d)\n{\n    std::cout << d << '\\n';\n}\n\nint main()\n{\n    printVal(5); // 5 converted to temporary double, copied to parameter d\n    printRef(5); // 5 converted to temporary double, bound to parameter d\n\n    return 0;\n}\n```\n\n>按值传递与按引用传递的成本比较\n>\t- 考虑创建参数的成本：按值传递要进行对象的复制，成本与对象的大小和实例化设置有关。而引用绑定则不需要复制，但绑定也需要一定的成本\n>\t- 考虑使用参数的成本：\n>\t\t- 编译器可以通过将按值传递参数的引用或副本（如果它很小）放入 CPU 寄存器（访问速度较快）而不是 RAM（访问速度较慢）来进行优化。值参数的每次使用都是**单个 CPU 寄存器或 RAM 访问**\n>\t\t- 但是，当使用引用参数时，通常会有一个额外的步骤。正在运行的程序必须首先直接访问分配给引用的存储位置（CPU 寄存器或 RAM），以确定正在引用的对象。只有这样，它才能访问被引用对象的存储位置（在 RAM 中）。因此引用参数的每次使用都是单个 CPU 寄存器或 RAM 访问，**再加上第二个 RAM 访问**。\n>\t- 编译器有时可以更有效地优化使用按值传递的代码\n>综上，按值传递的效率并不总是比按引用传递的差。\n>\t对于复制成本较低的对象，复制的成本与绑定的成本相似，但访问对象的速度更快，并且编译器可能能够更好地优化。\n>\t因此对于复制成本较低的对象，推荐使用按值传递\n\n#### 按引用返回\n按值返回也会出现拷贝返回对象的情况\n```cpp\nstring returnByValue(); // returns a copy of a std::string (expensive)\n```\n\n使用按引用返回，返回一个绑定到所返回对象的引用，避免返回对象的拷贝\n```cpp\nconst string& getProgramName() // returns a const reference\n{\n    static const string s_programName { \"Calculator\" }; // has static duration, destroyed at end of program\n\n    return s_programName;\n}\n```\n\n注意：必须确保**被引用的对象比返回引用的函数长寿**。否则，返回的引用将悬空（引用已销毁的对象），并且使用该引用将导致未定义的行为。\n\t在上面的程序中，由于 `s_programName` 是const static，具有静态持续时间，`因此 s_programName` 将一直存在，直到程序结束，比返回的函数`getProgramName`寿命长。\n\n**永远不要返回 （非const static） 局部变量或临时对象的引用**\n修改上面的程序：由于 `programName` 是具有自动持续时间的局部变量，`因此 programName` 在函数结束时被销毁。**这意味着返回的引用现在是悬空的**\n```cpp\nconst string& getProgramName()\n{\n    const string programName { \"Calculator\" }; // now a non-static local variable, destroyed when function ends\n\n    return programName;\n}\n```\n\n如果参数通过引用传递到函数中，**则通过引用返回该参数是安全的**。\n```cpp\n// Takes two std::string objects, returns the one that comes first alphabetically\nconst std::string& firstAlphabetical(const std::string& a, const std::string& b)\n{\n\treturn (a < b) ? a : b; // We can use operator< on std::string to determine which comes first alphabetically\n}\n```\n\n当 const 引用参数的参数是右值时，通过 const 引用返回该参数仍然是可以的。\n\t这是因为在创建右值的完整表达式结束之前，右值不会被销毁。\n```cpp\nconst std::string& foo(const std::string& s)\n{\n    return s;\n}\n\nstd::string getHello()\n{\n    return \"Hello\"; // implicit conversion to std::string\n}\n\nint main()\n{\n    const std::string s{ foo(getHello()) };\n\n    std::cout << s;\n\n    return 0;\n}\n```\n\n更高级的用法，使用返回的引用改变传入的引用参数值\n```cpp\n// takes two integers by non-const reference, and returns the greater by reference\nint& max(int& x, int& y)\n{\n    return (x > y) ? x : y;\n}\n\nint main()\n{\n    int a{ 5 };\n    int b{ 6 };\n\n    max(a, b) = 7; // sets the greater of a or b to 7\n\n    std::cout << a << b << '\\n';\n\n    return 0;\n}\n\n输出：5 7\n```\n\n**直接返回static 局部变量的问题：**\n\t下面程序中，因为 `id1` 和 `id2` 引用了同一个对象（静态变量 `s_x`），所以当任何内容（例如 `getNextId（）`）修改该值时，所有引用现在都在访问修改后的值。\n```cpp\nconst int& getNextId()\n{\n    static int s_x{ 0 }; // note: variable is non-const\n    ++s_x; // generate the next id\n    return s_x; // and return a reference to it\n}\n\nint main()\n{\n    const int& id1 { getNextId() }; // id1 is a reference\n    const int& id2 { getNextId() }; // id2 is a reference\n\n    std::cout << id1 << id2 << '\\n';\n\n    return 0;\n}\n\n输出：2 2\n```\n可以将上面的程序中， `id1` 和 `id2` 改为非引用的变量，这样即使`getNextId（）` 返回一个引用，但 `id1` 和 `id2` 是非引用变量。在这种情况下，返回引用的值就会复制给它们\n\t函数返回引用，并且该引用用于初始化或分配给非引用变量，则**返回值将被复制**\n```cpp\nconst int& getNextId()\n{\n    static int s_x{ 0 };\n    ++s_x;\n    return s_x;\n}\n\nint main()\n{\n    const int id1 { getNextId() }; // id1 is a normal variable now and receives a copy of the value returned by reference from getNextId()\n    const int id2 { getNextId() }; // id2 is a normal variable now and receives a copy of the value returned by reference from getNextId()\n\n    std::cout << id1 << id2 << '\\n';\n\n    return 0;\n}\n\n输出：1 2\n```\n还要注意，如果程序返回一个悬空引用，那么在创建副本之前，该引用会保持悬空状态，这将导致未定义的行为：\n```cpp\nconst std::string& getProgramName() // will return a const reference\n{\n    const std::string programName{ \"Calculator\" };\n\n    return programName;\n}\n\nint main()\n{\n    std::string name { getProgramName() }; // makes a copy of a dangling reference\n    std::cout << \"This program is named \" << name << '\\n'; // undefined behavior\n\n    return 0;\n}\n```\n#### 右值引用和移动语义\n右值引用：使用双 && 符号创建的右值的引用。R 值引用不能用 L 值初始化或绑定（不过const L值引用可以绑定到R值） 。最好不要返回右值引用\nR 值引用的属性：\n\t1. r 值引用将初始化它们的对象的生命周期延长到 r 值引用的生命周期（对 const 对象的左值引用也可以这么延长）\n\t2. 非 const 的r 值引用允许您修改 r 值\n```cpp\n    int&& rref{ 5 }; // because we're initializing an r-value reference with a literal, a temporary with value 5 is created here\n    rref = 10;\n    std::cout << rref << '\\n';\n```\n.\n\t3. **右值引用是一个变量**（左值），其具有地址\n```c\n    std::cout << rref << std::endl; // 输出 10\n    std::cout << &rref << std::endl; // ✅ 输出 `rref` 的地址\n\n\tint* p = &rref         //可以使用指针指向右值引用\n```\n>R 值引用更常用作函数参数。当您希望对 l 值和 r 值参数具有不同的行为时，这对于函数重载最有用。\n>如下面的案例，r值和l值的函数表现了不同的行为\n```cpp\nvoid fun(const int& lref) // l-value arguments will select this function\n{\n\tstd::cout << \"l-value reference to const: \" << lref << '\\n';\n}\n\nvoid fun(int&& rref) // r-value arguments will select this function\n{\n\tstd::cout << \"r-value reference: \" << rref << '\\n';\n}\n\nint main()\n{\n\tint x{ 5 };\n\tfun(x); // l-value argument calls l-value version of function\n\tfun(5); // r-value argument calls r-value version of function\n\n\n    int&& ref{ 5 };\n    fun(ref);        //注意，这会调用左值的版本，因为ref虽然是右值引用，但其本身是左值\n\treturn 0;\n}\n```\n\n**隐式移动**：如果满足以下所有条件，编译器将创建隐式移动构造函数和移动赋值运算符，将复制指针，而不是移动指针。：\n\t1. - 没有用户声明的复制构造函数或复制赋值运算符。\n\t2. - 没有用户声明的移动构造函数或移动赋值运算符。\n\t3. - 没有用户声明的析构函数。\n\n## 指针\n#### 访问变量的内存地址\n使用**取地址符**&，获取变量的地址\n```cpp\n    int x{ 5 };\n    std::cout << x << '\\n';  // print the value of variable x\n    std::cout << &x << '\\n'; // print the memory address of variable x\n```\n\n#### 解引用\n对变量的地址，使用 * 访问存储在该地址的对象（注意，返回的是左值，即原变量）\n```cpp\n    std::cout << *(&x) << '\\n'; // print the value at the memory address of variable x (parentheses not required, but make it easier to read)\n```\n\n#### 指针\n指针：保存内存地址的对象\n野指针：未初始化的指针。野指针包含垃圾地址，解引用野指针会导致未定义行为。\n\t和引用类似，应该在尽量在开始时，初始化指针\n```cpp\n    int* ptr;        // an uninitialized pointer (holds a garbage address)\n    int* ptr2{};     // a null pointer (we'll discuss these in the next lesson)\n    int* ptr3{ &x }; // a pointer initialized with the address of variable x\n```\n\n一旦我们有一个包含另一个对象地址的指针，我们就可以使用解引用运算符 （ * ） 来访问该地址的值。\n```cpp\n    int* ptr{ &x }; // ptr holds the address of x\n    std::cout << *ptr << '\\n'; // use dereference operator to print the value at the address that ptr is holding (which is x's address)\n```\n![[引用和指针-1.png]]\n\n就像引用的类型必须与所引用的对象类型匹配一样，指针的类型也必须与所指向的对象的类型匹配\n```cpp\n    int i{ 5 };\n    double d{ 7.0 };\n\n    int* iPtr{ &i };     // ok: a pointer to an int can point to an int object\n    int* iPtr2 { &d };   // not okay: a pointer to an int can't point to a double object\n    double* dPtr{ &d };  // ok: a pointer to a double can point to a double object\n    double* dPtr2{ &i }; // not okay: a pointer to a double can't point to an int object\n```\n\n不允许使用文本值初始化指针：\n```cpp\nint* ptr{ 5 }; // not okay\nint* ptr{ 0x0012FF7C }; // not okay, 0x0012FF7C is treated as an integer literal\n```\n\n可以更改指针所指向的对象或其值\n#### 悬空指针\n**悬空指针**：保存已销毁对象的地址的指针。解引用悬空指针也会导致未定义行为。\n```cpp\n    int x{ 5 };\n    int* ptr{ &x };\n\n    std::cout << *ptr << '\\n'; // valid\n\n    {\n        int y{ 6 };\n        ptr = &y;\n\n        std::cout << *ptr << '\\n'; // valid\n    } // y goes out of scope, and ptr is now dangling\n\n    std::cout << *ptr << '\\n'; // undefined behavior from dereferencing a dangling pointer\n```\n\n#### 空指针\n**空指针**：未指向任何内容的指针\n```cpp\n    int* ptr {}; // ptr is now a null pointer, and is not holding an address\n    int* ptr { nullptr }; // can use nullptr to initialize a pointer to be a null pointer\n```\n解引用 空指针也会导致未定义的行为。不过我们可以使用if条件语句判断空指针\n\t但if语句并不能区分悬空指针。\n```cpp\n    if (ptr == nullptr) // explicit test for equivalence\n```\n\n#### 指向const的指针和const指针\n**指向const的指针**\n和非const引用类似，非指向const类型的指针不能指向const变量。\n```cpp\n    const int x { 5 }; // x is now const\n    int* ptr { &x };   // compile error: cannot convert from const int* to int*\n```\n只有指向const的指针才能指向const值\n声明指向 const 值的指针，请在指针的数据类型之前使用 `const` 关键字\n\t当然**指向const的指针也不能修改指向的变量内容**\n```cpp\n    const int x{ 5 };\n    const int* ptr { &x }; // okay: ptr is pointing to a \"const int\"\n\n    *ptr = 6; // not allowed: we can't change a const value\n```\n\n注意，由于**指向 const 的指针本身不是 const** （它只指向 const 值），因此我们可以通过为指针分配新地址来更改指针的指向：\n```cpp\n    const int x{ 5 };\n    const int* ptr { &x }; // ptr points to const int x\n\n    const int y{ 6 };\n    ptr = &y; // okay: ptr now points at const int y\n```\n\n类似于const引用，指向 const 的指针也可以指向非 const 变量。\n```cpp\n    int x{ 5 }; // non-const\n    const int* ptr { &x }; // ptr points to a \"const int\"\n\n    *ptr = 6;  // not allowed: ptr points to a \"const int\" so we can't change the value through ptr\n    x = 6; // allowed: the value is still non-const when accessed through non-const identifier x\n```\n\n**const指针**\n要使指针成为常量，在指针声明中星号后使用 `const` 关键字：\n```cpp\n    int x{ 5 };\n    int* const ptr { &x }; // const after the asterisk means this is a const pointer\n```\n\nconst指针因为是常量，所以不能重新修改指针的指向\n```cpp\n    int* const ptr { &x }; // okay: the const pointer is initialized to the address of x\n    ptr = &y; // error: once initialized, a const pointer can not be changed.\n```\n\nconst指针可以修改指向的非const变量\n```cpp\n    int x{ 5 };\n    int* const ptr { &x }; // ptr will always point to x\n\n    *ptr = 6; // okay: the value being pointed to is non-const\n```\n\n我们也可以声明一个指向 const 值的 const 指针\n\t这个指针不能更改其地址，也不能通过指针更改它指向的值。只能解引用来获取其值\n```cpp\n    int value { 5 };\n    const int* const ptr { &value }; // a const pointer to a const value\n```\n\n#### 按地址传递\n传递地址也可以避免创建参数临时对象的情况，但是会复制临时指针变量。\n\t指针只有 4 或 8 个字节，因此复制指针总是很快的\n\t在对指针解引用时注意判空指针\n```cpp\n#include <iostream>\n\nvoid changeValue(int* ptr) // note: ptr is a pointer to non-const in this example\n{\n\tif(!ptr)\n\t\treturn;\n\n\t*ptr = 6; // change the value to 6\n}\n\nint main()\n{\n    int x{ 5 };\n\n    std::cout << \"x = \" << x << '\\n';\n\n    changeValue(&x); // we're passing the address of x to the function\n\n    std::cout << \"x = \" << x << '\\n';\n\n    return 0;\n}\n```\n如果函数不应该修改传入的对象，则可以将函数参数设置为指向 const 的指针：\n```cpp\nvoid changeValue(const int* ptr) // note: ptr is now a pointer to a const\n{\n\tif(!ptr)\n\t\treturn;\n\t*ptr = 6; // error: can not change const value\n}\n```\n\n如果永远不应该将 null 指针传递给函数，则可以使用 `assert`\n```cpp\nvoid print(const int* ptr) // now a pointer to a const int\n{\n\tassert(ptr); // fail the program in debug mode if a null pointer is passed (since this should never happen)\n\t\n\t// (optionally) handle this as an error case in production mode so we don't crash if it does happen\n\tif (!ptr)\n\t\treturn;\n\n\tstd::cout << *ptr << '\\n';\n}\n```\n\n> 按引用传递 vs 按地址传递\n> 按引用传递本质上也是按地址传递，但按引用传递有一些好处：\n> \t1. const引用传递可以传递左值和右值。但按地址传递的对象必须有地址，因此按地址传递只能传递左值\n> \t2. 按引用传递的语法是自然的，因为我们可以直接传入文字或对象。使用按地址传递时，我们的代码最终会散布着 & 符号 （&） 和星号 （ * ） \n#### 指针与引用的区别\n虽然引用通常由编译器使用指针实现（引用也可能会被编译器优化掉）\n主要区别在于，对于指针，我们需要显式地获取要指向的地址，并且我们必须显式地解引用指针才能获取值。\n而引用的获取地址和解引用都是隐式发生的\n其他的差异：\n\t1. 引用必须在开始时初始化，指针不需要初始化（但应该初始化）\n\t2.引用不是对象，指针是。\n\t3.引用不能更改为引用其他内容，指针可以更改它们所指向的内容\n\t4.引用必须始终绑定到对象，不能是空的，指针可以指向任何内容，可以为空指针\n\t5.引用是 “安全的” （除了悬空的引用），指针本质上是危险的","tags":["c++"],"categories":["note","c++学习笔记"]},{"title":"c++学习笔记——常用关键字static与const","url":"/2025/01/24/note/c++学习笔记/常用关键字static与const/","content":"## static\nstatic主要作用是限制变量或函数的作用范围\n\t- static 全局变量和static函数，为全局变量和函数提供内部链接，将其作用域限制在定义它的文件中\n\t- static局部变量，相当于将一个全局变量的范围限制在函数体内\n\t- static类成员变量和函数，可以不经过实例化对象就调用\n#### static全局变量\n**内部变量**：具有**内部链接**的全局变量。\n\t使用 `static`可以使non-constant的全局变量内部化\n\t默认情况下，`const` 和 `constexpr` 全局变量具有内部链接（因此不需要 `static` 关键字）\n```cpp\n#include <iostream>\n\nstatic int g_x{}; // non-constant globals have external linkage by default, but can be given internal linkage via the static keyword\n\nconst int g_y{ 1 }; // const globals have internal linkage by default\nconstexpr int g_z{ 2 }; // constexpr globals have internal linkage by default\n\nint main()\n{\n    std::cout << g_x << ' ' << g_y << ' ' << g_z << '\\n';\n    return 0;\n}\n```\n\n内部变量仅限于本文件内访问，其他文件不能直接使用，即**内部变量的作用域限制在定义它的翻译单元（即源文件）中**\n- 例如，在a.cpp内声明了内部变量 `g_x`\n```cpp\n[[maybe_unused]] constexpr int g_x { 2 }; // this internal g_x is only accessible within a.cpp\n```\n- main.cpp内也有一个static声明的内部变量 `g_x`。但因为 `g_x` 是每个文件的内部变量，所以main.cpp不知道 `a.cpp` 还有一个名为 `g_x` 的变量（反之亦然）\n```cpp\n#include <iostream>\n\nstatic int g_x { 3 }; // this separate internal g_x is only accessible within main.cpp\n\nint main()\n{\n    std::cout << g_x << '\\n'; // uses main.cpp's g_x, prints 3\n\n    return 0;\n}\n```\n\n>C++11 标准（附录 C）提供了 const 变量默认具有内部链接的基本原理：\n>\t“由于 const 对象可以用作 C++ 中的编译时值，因此此功能敦促程序员为每个 const 提供显式初始值设定项值。此功能允许用户将 const 对象放在包含在许多编译单元中的头文件中。\"\n>将 const 变量设为内部链接意味着每个翻译单元都获得自己的变量副本，在内部中被视为独立实体，，因此不会违反 ODR。（**ODR规则（one-definition rule）**：全局变量、函数、类等实体具有唯一定义）\n\n#### static函数\n函数默认为**外部链接**的。通过 `static` 关键字将函数设置为内部链接，仅限于本文件中使用\n```cpp\nstatic int add(int x, int y)\n{\n    return x + y;\n}\n```\n\n>`static` vs `unnamed namespaces`\n>在现代 C++ 中，使用 `static` 关键字为标识符提供内部链接已不再受欢迎。未命名的命名空间`unnamed namespaces`可以为更广泛的标识符（例如类型标识符）提供内部链接，并且它们更适合为许多标识符提供内部链接。\n\n#### static局部变量\nstatic局部变量类似于**作用域为函数体内的全局变量**\n\t没有初始值设定项或非 constexpr 初始值设定项的静态局部变量在程序启动时进行零初始化。\n\n**static局部变量与普通局部变量的区别**\n\t其实就是全局变量和局部变量的区别\n\t1. static局部变量只初始化一次，声明周期是整个程序，在程序开始时创建，并在程序结束时销毁（就像全局变量一样），值不会在函数调用间丢失。\n\t   普通局部变量声明周期是在函数体内，在调用函数时创建，超出函数范围将被销毁\n\t2. static局部变量存储在**数据段**，普通局部变量存储在栈上\n\n```cpp\nvoid incrementAndPrint()\n{\n    static int s_value{ 1 }; // static duration via static keyword.  This initializer is only executed once.\n    ++s_value;\n    std::cout << s_value << '\\n';\n} // s_value is not destroyed here, but becomes inaccessible because it goes out of scope\n\nint main()\n{\n    incrementAndPrint();\n    incrementAndPrint();\n    incrementAndPrint();\n\n    return 0;\n}\n\n输出：\n\t2\n\t3\n\t4\n由于 s_value 已声明为 static，因此它是在程序启动时创建的。在后续调用中跳过该定义，因此不会发生进一步的重新初始化。\n当 s_value在函数结束时超出范围时，它不会被销毁。每次调用函数 incrementAndPrint（） 时，s_value 的值都保持为我们之前保留的值。\n```\n\n\n**应用场景**：当您需要局部变量在函数调用中记住其值时，或者避免每次调用函数时进行昂贵的本地对象初始化，可以使用静态局部变量。\n- 例如，唯一 ID 生成器。\n\t-想象一个程序，其中有许多相似的对象（例如，您被许多僵尸攻击的游戏，或者您显示许多三角形的模拟）。您注意到缺陷，几乎不可能区分哪个对象有问题。但是，如果在创建时为每个对象提供唯一标识符，则可以更轻松地区分对象以进行进一步调试。\n```cpp\nint generateID()\n{\n    static int s_itemID{ 0 };\n    return s_itemID++; // makes copy of s_itemID, increments the real s_itemID, then returns the value in the copy\n}\n```\n- 静态局部变量可以设为 const （或 constexpr）。const 静态局部变量的一个很好的用途是，当你有一个函数需要使用 const 值，但创建或初始化对象很昂贵时（例如，你需要从数据库中读取值）。使用 const/constexpr 静态局部变量，您可以创建并初始化一次昂贵的对象，然后在调用函数时重用它。\n\n#### static类成员变量\n\n**静态成员变量**：不与某个类对象关联，而是由类的**所有对象**共享，可以当成专属于这个类的全局变量。\n\t- 和static局部变量一样，在程序开始时创建的，在程序结束时销毁，生命周期不像普通成员变量那样绑定到类对象。\n\t-因为在在程序开始就创建了， **即使没有实例化该类的对象，静态成员变量也存在**\n```cpp\nclass Something\n{\npublic:\n    static int s_value; // declare s_value as static (initializer moved below)\n};\n\nint Something::s_value{ 1 }; // define and initialize s_value to 1 (we'll discuss this section below)\n\nint main()\n{\n    Something first{};\n    Something second{};\n\n    first.s_value = 2;\n\n    std::cout << first.s_value << '\\n';\n    std::cout << second.s_value << '\\n';\n    return 0;\n}\n\n输出\n\t2\n\t2\n\t\n由于 s_value 是静态成员变量，因此 s_value 在类的所有对象之间共享\n所以first.s_value 与 second.s_value 是相同的变量，输出的值自然是一样的\n```\n\n如果静态成员变量是 public的，即使没有实例化该类的对象，也**可以使用类名和范围解析运算符 :: 直接初始化或访问静态成员**\n\t- 注意，静态成员的定义和初始化不受访问控制的约束，因为定义不被视为一种访问形式\n```cpp\nint main()\n{\n    // note: we're not instantiating any objects of type Something\n\n    Something::s_value = 2;\n    std::cout << Something::s_value << '\\n';\n    return 0;\n}\n\n即使没有实例化 Something 类型的对象，也可以使用范围解析运算符::初始化静态成员变量s_value\n```\n如果静态成员变量设置是私有private，则不能直接访问，需要使用静态成员函数访问\n```cpp\nclass Something\n{\nprivate: // now private\n    static inline int s_value { 1 };\n};\n\nint main()\n{\n    std::cout << Something::s_value; // 不能直接访问，error: s_value is private and can't be accessed directly outside the class\n}\n```\n\n**应用场景**： 类似于静态局部变量，静态成员变量可以为类的每个实例分配一个唯一的 ID\n- 在调试时，为每个对象提供唯一的 ID 会有所帮助，因为它可用于区分原本具有相同数据的对象。\n```cpp\nclass Something\n{\nprivate:\n    static inline int s_idGenerator { 1 };\n    int m_id {};\n\npublic:\n    // grab the next value from the id generator\n    Something() : m_id { s_idGenerator++ }\n    {\n    }\n\n    int getID() const { return m_id; }\n};\n\nint main()\n{\n    Something first{};\n    Something second{};\n    Something third{};\n\n    std::cout << first.getID() << '\\n';\n    std::cout << second.getID() << '\\n';\n    std::cout << third.getID() << '\\n';\n    return 0;\n}\n```\n- 当类需要**使用查找表**（例如，用于存储一组预先计算值的数组）时，静态成员变量也很有用。通过使查找表成为静态的，所有对象只存在一个副本，而不是为每个实例化的对象创建一个副本。\n\n**NOTE**：\n- 静态成员变量定义通常放在该类的关联代码文件中（例如 `Something.cpp`）。\n- **不要将静态成员变量定义放在头文件中**（与全局变量非常相似，如果该头文件被多次包含，则最终会得到多个定义，这将导致链接器错误）。\n- 对于模板类，（模板化的）静态成员定义通常直接放置在头文件中模板类定义的下方\n- 可以将静态成员设`为 inline` 或 `constexpr`，以便可以在类定义中初始化它们。\n\n#### static类成员函数\n和static成员对象类似，静态成员函数不与特定对象关联。\n\t- 因此也可以使用类名和范围解析运算符::（例如 `Something：：getValue（）`）直接调用它们。\n\t- 也可以通过对象调用，但不建议这样做。\n\n**静态成员函数可以直接访问类的静态成员（变量或函数），但不能访问非静态成员**。这是因为非静态成员必须属于类对象，而静态成员函数没有要使用的类对象。\n\t因此可以设置一个public静态成员函数访问私有private静态成员\n```cpp\nclass Something\n{\nprivate:\n    static inline int s_value { 1 };\n\npublic:\n    static int getValue() { return s_value; } // static member function\n};\n\nint main()\n{\n    std::cout << Something::getValue() << '\\n';\n}\n```\n\n静态成员函数也可以在类声明之外定义。其工作方式与普通成员函数相同。\n```cpp\nclass IDGenerator\n{\nprivate:\n    static inline int s_nextID { 1 };\n\npublic:\n     static int getNextID(); // Here's the declaration for a static function\n};\n\n// Here's the definition of the static function outside of the class.  Note we don't use the static keyword here.\nint IDGenerator::getNextID() { return s_nextID++; }\n\nint main()\n{\n    for (int count{ 0 }; count < 5; ++count)\n        std::cout << \"The next ID is: \" << IDGenerator::getNextID() << '\\n';\n\n    return 0;\n}\n```\n**NOTE**:\n- 静态成员函数没有附加到对象，**所以它们没有** `this` **指针**\n- 在类定义之外定义的成员函数不是隐式内联的，但可以使用 `inline` 关键字进行内联。因此，在头文件中定义的静态成员函数`应内联，`以便在该头随后包含在多个翻译单元中时不会违反单定义规则\n- C++ 不支持静态构造函数  \n- 静态函数不能定义为虚函数\n\t- 原因：静态函数是属于类的，不与任何类对象关联，所以它们不具备`this`指针和虚函数表指针。这意味着它们无法实现动态多态，也就不能实现虚函数的多态特性。\n应用实例：单例模式\n## const\n**常量**是在程序执行期间不能更改的值。\n\tconst变量是最常见的命名常量类型\n\t\nconst 变量必须在定义它们时初始化，然后不能通过赋值来更改该值。\n```cpp\nconst double gravity { 9.8 };  // preferred use of const before type\n```\n\n可以使用非const 的变量来初始化const变量\n```cpp\nconst int constAge { age }; // initialize const variable using non-const value\n```\n\n函数参数可以通过 `const` 关键字成为常量：\n\t在**按引用传递和按地址传递**时，使用const常量可以避免修改参数的值\n```cpp\nvoid printInt(const int &x)\n{\n    std::cout << x << '\\n';\n}\n```\n\n函数的返回值也可以设为 const：\n\t按值返回 const 对象通常没有什么意义，因为它们是临时副本，无论如何都会被销毁\n```cpp\nconst int getValue()\n{\n    return 5;\n}\n```\n\n**为什么需要常量**：\n\t如果变量可以变为常量，则通常应将其变为常量。\n\t1. 它减少了出现 bug 的机会。通过使变量成为常量，可以确保该值不会被意外更改。\n\t2. 它为编译器提供了更多优化程序的机会。当编译器可以假设值没有变化时，它能够利用更多技术来优化程序\n\n**首选常量变量而不是预处理器宏**：\n\t首选常量变量，而不是带有替换文本的类对象宏。\n\t1. 宏不遵循正常的 C++ 范围规则。#defined 宏后，当前文件中出现的所有后续出现的宏名称都将被替换。如果该名称在其他地方使用，您将在您不需要的地方获得宏替换。\n\t2. 使用宏调试代码通常更难。尽管源代码将具有宏的名称，但编译器和调试器永远不会看到宏，因为它在运行之前已被替换\n\t3. 常量变量没有这些问题：它们遵循正常的范围规则，可以被编译器和调试器看到，并且行为一致。\n\n> **类型限定符volatile**\n> **类型限定符**（有时简称为**限定符**）是应用于类型的关键字，用于修改该类型的行为方式。\n> 截至 C++23，C++ 只有两个类型限定符：`const` 和 `volatile`。\n> - `volatile` 限定符用于告知编译器对象的值可能随时更改。这个很少使用的限定符会**禁用某些类型的优化**。\n\n#### const成员函数\n类的成员函数后面加 const，表明这个函数不会对这个类对象的数据成员（准确地说是非静态数据成员）作任何改变。\n```c\nclass MyClass {\npublic:\n    int getData() const {\n\t    // data = 100  错误，不能修改普通成员变量\n\t    return data;\n    }; // 这是一个 const 成员函数\n\nprivate:\n    int data;    // 普通成员变量\n    mutable int logCount;   //可修改的成员变量\n};\n```\nconst 成员函数特点：\n1. 只能读取普通成员变量，**不能修改** 类的普通成员变量\n2. 不能调用该类的**非 const 成员函数**，但可以调用其他 const 成员函数\n```c\n\tvoid MyClass :: modifyData(int d) { data = d; }  // 非 const 成员函数\n\tint MyClass ::  getData() const {\n\t     // modifyData(100); // ❌ 错误，不能在 const 成员函数中调用非 const 成员函数\n\t     return data;\n\t}\n\tvoid MyClass :: printData() const {  // 另一个 const 成员函数\n\t     cout << \"Data: \" << getData() << endl;  // ✅ 允许调用 const 成员函数\n\t}\n```\n3. 可以修改 mutable 修饰的成员变量\n```c\n\tint MyClass :: logAdd() const {\n\t\tlogCount++ ;           //虽然logAdd是const函数，但是可以修改mutable变量\n\t}\n```\n\n4. **const 对象**只能调用 const 成员函数，以防止const对象意外修改成员变量。\n\t- **const成员函数的重载**：const 成员函数可以被视为非const 成员函数的重载版本。**普通对象** 将会优先调用**非 const 版本**的成员函数\n```c\n    const MyClass obj(10);  // obj 是 const 对象\n    std::cout << obj.getData() << std::endl;  // ✅ 可以调用 const 成员函数\n    // obj.modifyData(20); // ❌ 错误，const 对象不能调用非 const 成员函数\n```\n\n- **底层实现**：\n在 const 成员函数中，this 指针的类型是：\n```c\nconst ClassName* const this;\n```\n即this指针是const指针，且其指向的对象也是const的。因此this指针不能修改普通成员，也不能调用非cons成员函数\n\n值得注意的是，如果类中存在指针类型的数据成员，即便是const函数只能保证不修改该指针的值，并不能保证不修改指针指向的对象。\n\n```c\nclass Name {\npublic:\nvoid setName(const string &s) const;\nprivate:\n    char *m_sName;\n};\nvoid setName(const string &s) const {\n    m_sName = s.c_str();      // 错误！不能修改m_sName;\nfor (int i = 0; i < s.size(); ++i) \n    m_sName[i] = s[i];    //  不是错误的 const成员函数不能保证指针指向的对象的不变性\n}\n```\n\n>**最佳实践**：\n>\t对于不改变数据成员的成员函数都要在后面加 const，而对于改变数据成员的成员函数不能加 const\n#### constexpr\n**编译时常量**：在编译阶段其值就已经确定，并且在程序运行时不会改变的值。这类常量在编译时就可以被直接使用和优化\nC++11引入了constexpr关键字，用于**明确指定变量或函数是编译时常量**。\n\t- **constexpr** 变量始终是编译时常量。\n\t- 必须使用**常量表达式**初始化 constexpr 变量，否则将导致编译错误。\n\t- 函数参数不能声明为 `constexpr`，因为它们的初始化值直到运行时才确定。\n>**常量表达式**：在编译时期就可以求值的表达式。即其值在编译期间就可以确定\n```cpp\n// The return value of a non-constexpr function is not a constant expression\nint five()\n{\n    return 5;\n}\n\n    constexpr double gravity { 9.8 }; // ok: 9.8 is a constant expression\n    constexpr int sum { 4 + 5 };      // ok: 4 + 5 is a constant expression\n    constexpr int something { sum };  // ok: sum is a constant expression\n\n    std::cout << \"Enter your age: \";\n    int age{};\n    std::cin >> age;\n\n    constexpr int myAge { age };      // compile error: age is not a constant expression\n    constexpr int f { five() };       // compile error: return value of five() is not a constant expression\n\n由于函数通常在运行时执行，因此函数的返回值不是常量表达式（即使 return 语句返回的值是）。这就是为什么 `five（）` 不是 `constexpr int f`的合法初始化值。\n```\n\nconst 与 constexpr 对变量的含义：\n\t1. `const` 表示初始化后无法更改对象的值。初始化器的值**可能在编译时或运行时获取**。可以在运行时评估 const 对象。\n\t   `constexpr` 表示对象可以在常量表达式中使用。初始化器的值**必须在编译时获取**。可以在运行时或编译时评估 constexpr 对象。\n\t2. constexpr 变量是隐式的 const。const 变量不是隐式的 constexpr。\n\t  `constexpr` 不是对象类型的一部分。因此，定义为 `constexpr int` 的变量实际上具有 `const int` 类型\n\t\n应用场景：其**初始值设定项为常量表达式**的任何常量变量都应声明为 `constexpr`。\n\n**constexpr 函数**\n**constexpr 函数**是一个可以**在编译时执行**的函数，可以在常量表达式中调用。\nconstexpr 函数必须在编译时计算，而它所属的常量表达式必须在编译时计算\n```cpp\nconstexpr int cmax(int x, int y) // this is a constexpr function\n{\n    if (x > y)\n        return x;\n    else\n        return y;\n}\n\nint main()\n{\n    int m1 { max(5, 6) };            // ok\n    const int m2 { max(5, 6) };      // ok\n    constexpr int m3 { max(5, 6) };  // compile error: max(5, 6) not a constant expression\n\n    int m1 { cmax(5, 6) };           // ok: may evaluate at compile-time or runtime\n    const int m2 { cmax(5, 6) };     // ok: may evaluate at compile-time or runtime\n    constexpr int m3 { cmax(5, 6) }; // okay: must evaluate at compile-time\n\n    return 0;\n}\n```\n","tags":["c++"],"categories":["note","c++学习笔记"]},{"title":"c++学习笔记——变量与常用类型","url":"/2025/01/22/note/c++学习笔记/变量与常用类型/","content":"### 变量\n变量：是可用于存储信息的内存段的名称\n\t变量定义在操作系统中的细节：\n\t- 定义变量时，系统将为该变量留出一段内存。内存被组织成称为**内存地址**的顺序单元。与使用街道地址在街道上查找给定房屋的方式类似，唯一的内存地址允许我们在特定位置查找和访问内存内容。\n\t- 当您为变量对象指定值时，编译器和 CPU 会负责将值编码为该数据类型的适当位序列，然后将其存储在内存中（请记住：**内存只能存储位**）。例如，如果为整数对象分配值 `65`，则该值将转换为位序列 `0100 0001` 并存储在分配给该对象的内存中。相反，当对对象进行计算以生成值时，该位序列将重构回原始值。这意味着 `0100 0001` 将转换回值 `65`。\n\t- 只要对象存在就会一直占有内存\n\n>因为内存地址的数量有限，在现代计算机体系结构中，每个位都没有自己唯一的内存地址。而是选择将**每个内存地址保存 1 字节的数据**（**内存是字节可寻址的**），也就是说，**一个数据变量的大小至少是1字节**\n\t- **字节Byte**是作为内存单元进行操作的一组位。现代标准是**字节由 8 个顺序位bit**组成。\n\n下图显示了一些顺序内存地址，以及相应的数据字节：\n![|300](变量与常用类型/img-变量与常用类型-4.png)\n\n\n### 常用数据类型\nC++的**基本数据类型**如下表，务必将下面的表背熟并会推范围：\n\n| 整数类型         | 大小/字节 | 范围                                                  |\n| ------------ | ----- | --------------------------------------------------- |\n| bool         | 1     | 0或1                                                 |\n| char         | 1     | $-2^{7}～2^{7}-1$      (-128~127)                    |\n| short        | 2     | $-2^{15}～2^{15}-1$ （-32768~32767)                   |\n| int          | 4     | $-2^{31}～2^{31}-1$ （-2,147,483,648 ~ 2,147,483,647) |\n| unsigned int | 4     | $0～2^{32}-1$        (0 ~ 4,294,967,295)             |\n| long         | 4或8   |                                                     |\n| long long    | 8     | $-2^{63}～2^{63}-1$  （大概±922亿亿）                      |\n| 指针           | 4或8   |                                                     |\n\t*指针和long的范围取决于平台，32位是4字节，64位是8字节*\n\t\t\t对于指针，在32位系统时因为地址空间为 2 ^ 32，需要4字节存储地址。 同理，64位就需要地址空间为 2 ^ 64，需要8字节\n\t*有一些组合的类型，比如short int 、long int、long long int，用的少就不细说了*\n>**整数类型的范围计算公式**：\n>\t如果该类型占n位 （字节数✖️8）\n>\t\t- 无符号范围：$0～2^{n}-1$\n>\t\t- 有符号范围：$2^{n-1}～2^{n-1}-1$\n>\n>例如char占1字节，即有8位，那么：\n>\t- 无符号char的二进制范围是：0000 0000 ～ 1111 1111 换算成十进制是$0～2^{8}-1$ \n>\t- 有符号char的二进制范围是：1000 0000 ～ 0111 1111 换算成十进制是$-2^{7}-1～2^{7}-1$ \n\n| 浮点数类型       | 大小/字节   | 范围                    | 精度（有效数字位）       |\n| ----------- | ------- | --------------------- | --------------- |\n| float       | 4       | 1.2 E-38 到 3.4 E+38   | 6-7位，通常为 7 位    |\n| double      | 8       | 2.3 E-308 到 1.7 E+308 | 15-18位，通常为 16 位 |\n| long double | 8、12或16 | 取决于平台，不建议使用           | 18-21位          |\n\nsizeof：C++ 提供了一个名为 `sizeof` 的运算符来返回该类型对象的**字节大小**\n\t注意`sizeof` 不能对动态分配的内存的对象使用\n```cpp\n    std::cout << \"bool:\" << sizeof(bool) << \" bytes\\n\";\n    std::cout << \"char:\" << sizeof(char) << \" bytes\\n\";\n    std::cout << \"short:\" << sizeof(short) << \" bytes\\n\";\n    std::cout << \"int:\" << sizeof(int) << \" bytes\\n\";\n    std::cout << \"long:\" << sizeof(long) << \" bytes\\n\";\n    std::cout << \"long long:\" << sizeof(long long) << \" bytes\\n\";\n    std::cout << \"float:\" << sizeof(float) << \" bytes\\n\";\n    std::cout << \"double:\" << sizeof(double) << \" bytes\\n\";\n    std::cout << \"long double:\" << sizeof(long double) << \" bytes\\n\";\n```\n\n>**size_t**:\n>**std：：size_t** 是实现定义的 unsigned int 类型的别名,在标准库中用于表示对象的字节大小或长度。\n>\t内存对象的大小(sizeof的返回类型） 、容器大小和索引都是size_t类型\n>换句话说，编译器决定 `size_t` 是 unsigned int、unsigned long、unsigned long long 等。\n>\t因此size_t 和 unsigned int 区别在于**size_t的大小由平台地址空间决定**\n>\n>`size_t` 在许多不同的标头中定义。如果需要使用 `std：：size_t`， <cstddef\\>是最好的标头，因为它包含的其他已定义标识符的数量最少。\n\n\n>**整数除法**:\n\t 当一个整数不能整除另一个整数时，将会**舍弃掉小数部分**，这称为向下取整\n\t 例如：8 / 5 产生值 1.6。小数部分 （0.6） 被删除，1 的结果保持不变。\n```cpp\n    std::cout << 8 / 5 << '\\n';\n输出：1\n```\n### 溢出\n假如我们将超出范围的数分配给了一个基本类型对象，就会发生**溢出**。溢出会导致信息丢失\n\t例如下面的程序，x将会溢出\n```cpp\n    int x { 2'147'483'647 }; // the maximum value of a 4-byte signed integer\n    std::cout << x << '\\n';\n\n    x = x + 1; // integer overflow, undefined behavior\n    std::cout << x << '\\n';\n\n输出：\n\t2147483647\n\t-2147483648\n```\n>冷知识：在c++标准中，有符号整数溢出是未定义的行为，而无符号整数溢出是明确定义的行为（也就是说C++ 标准明确表示无符号整数溢出不是溢出）\n\n\n-**有符号整数的溢出** ：\n\t- 从最大值开始的溢出会将这个整数对象从其最小值开始增加 \n\t- 相反，如果从最小值向下溢出就从最大值开始减少\n\t- **wraps around**：可以理解为最大值和最小值围成一个圈，超过了这个值就是回到了圈的起点重新开始\n```c\n    int x = 2'147'483'647 ; //最大值\n    x = x + 1; // integer overflow, undefined behavior ，溢出成最小值\n    cout << x << '\\n';\n\n\tx = -2'147'483'648 ;    //最小值\n    x = x - 1; // integer overflow, undefined behavior，溢出成最大值\n    cout << x << '\\n';\n\n输出：\n\t-2147483648\n\t2147483647\n```\n\n-**无符号整数溢出**\n\t- 如果无符号值超出范围，则将其除以类型所能表示的最大数字+1，然后仅保留余数。\n\t\t- 例如将数字 `280`（需要 9 位表示）存储在 1 字节 （ 0 到 255范围） 无符号整数变量中。则将 280 除以 256，得到余数 24，然后存在这个变量中\n\t\t- 同样可以理解为一个圈，`256` 超出范围，因此它会回绕到值 `0`。`257` 回绕到值 `1`。`280` 回绕为值 `24`\n```cpp\n    unsigned short x{ 65535 }; // largest 16-bit unsigned value possible\n    std::cout << \"x was: \" << x << '\\n';\n\n    x = 65536; // 65536 is out of our range, so we get modulo wrap-around\n    std::cout << \"x is now: \" << x << '\\n';\n\n    x = 65537; // 65537 is out of our range, so we get modulo wrap-around\n    std::cout << \"x is now: \" << x << '\\n';\n\n输出：\n\tx was: 65535\n\tx is now: 0\n\tx is now: 1\n```\n\n- 如果无符号整数表示负数，会回绕到范围的顶部，开始减少\n```cpp\n    unsigned short x{ 0 }; // smallest 2-byte unsigned value possible\n    std::cout << \"x was: \" << x << '\\n';\n\n    x = -1; // -1 is out of our range, so we get modulo wrap-around\n    std::cout << \"x is now: \" << x << '\\n';\n\n    x = -2; // -2 is out of our range, so we get modulo wrap-around\n    std::cout << \"x is now: \" << x << '\\n';\n输出：\n\tx was: 0\n\tx is now: 65535\n\tx is now: 65534\n```\n\n>**无符号数的争议**：\n>\t许多开发人员（以及一些大型开发公司，如 Google）认为开发人员通常应该避免使用无符号整数。\n>\t无符号数字的范围底部是0，接近我们大多数值所在的位置，因此可以说无符号数更容易溢出。\n>\t特别是当您**混合使用有符号和无符号整数时**，可能会导致意外行为。\n>\t在 C++ 中，如果数学运算（例如算术或比较）有一个有符号整数和一个无符号整数，则**有符号整数通常会转换为无符号整数**。因此，结果将是 unsigned。\n>\t\n>\t例如：在这种情况下，如果 `u` 是signed的，将产生正确的结果。但是因为 `u` 是unsigned的（很容易错过），所以 s 被转换为 unsigned，结果 （`-1`） 被视为 unsigned 值。由于 `-1` 不能存储在无符号值中，因此我们会得到 overflow 和一个意外的答案。\n```cpp\n\tunsigned int u{ 2 };\n\tsigned int s{ 3 };\n\tstd::cout << u - s << '\\n'; // 2 - 3 = 4294967295\n```\n>在 C++ 中，仍有一些情况下可以使用无符号数字。\n>\t例如在处理位操作时，无符号数字是首选。\n>\t当需要明确定义的环绕行为时，它们也很有用（在某些算法中很有用，如加密和随机数生成）。\n>\t在某些情况下，使用无符号数字仍然是不可避免的，例如vector等容器类的下标索引类型size_t是无符号整型\n\n### 浮点数\n在现代体系结构中，浮点类型通常使用 IEEE 754 标准中定义的浮点格式之一实现。\n浮点数可用于存储非常大或非常小的数字，包括那些带有小数分量的数字。\n>浮点数的二进制实现参考：https://float.exposed/0x3dcccccd\n\n使用浮点数时，请始终至少包含一个小数位（即使小数为 0）。这有助于编译器了解该数字是浮点数，而不是整数。\n```cpp\ndouble b { 5.0 }; // 5.0 is a floating point literal (no suffix means double type by default)\n```\n\n默认情况下，小数的类型为 `double`。要使它们成为`float`文本，应使用 `f` （或 `F`） 后缀：\n```c\nfloat c { 5.0f }; // 5.0 is a floating point literal, f suffix means float type\n```\n###### 精度\n浮点类型的**精度**：定义它可以表示多少个有效数字而不会丢失信息。\n\t例如，float具有 6 到 9 位精度。这意味着 float 可以精确表示最多 6 个有效数字的任何数字。具有 7 到 9 位有效数字的数字可能会也可能不会准确表示，具体取决于特定值。但精度超过 9 位的数字肯定不会被准确表示。\n###### 输出浮点数\n当输出浮点数时，`std：：cout` 的默认精度为 6 —— 也就是说，它假设所有浮点变量都只对 6 位数字有效（浮点数的最小精度），因此它将截断此之后的任何内容。\n```cpp\n    std::cout << 9.87654321f << '\\n';\n    std::cout << 987.654321f << '\\n';\n    std::cout << 987654.321f << '\\n';\n    std::cout << 9876543.21f << '\\n';\n    std::cout << 0.0000987654321f << '\\n';\n\n输出：每个数字都只有 6 个有效数字。\n\t9.87654\n\t987.654\n\t987654\n\t9.87654e+006\n\t9.87654e-005\n```\n可以使用名为 `std：：setprecision（）` `的输出操纵器`函数来覆盖 std：：cout 显示的默认精度。**输出操纵器**会改变数据的输出方式，并在 _iomanip_ 标头中定义。\n```cpp\n#include <iomanip> // for output manipulator std::setprecision()\n#include <iostream>\n\nint main()\n{\n    std::cout << std::setprecision(17); // show 17 digits of precision\n    std::cout << 3.33333333333333333333333333333333333333f <<'\\n'; // f suffix means float\n    std::cout << 3.33333333333333333333333333333333333333 << '\\n'; // no suffix means double\n\n    return 0;\n}\n\n\n输出：\n\t3.3333332538604736\n\t3.3333333333333335\n\t\n使用 std：：setprecision（）将精度设置为 17 位，所以上述每个数字都打印有 17 位数字。但是，正如你所看到的，这些数字肯定不是精确到 17 位数字！由于 float 的精度低于 double，因此 float 的误差更大。\n```\n\n###### 舍入误差\n当由于无法精确存储数字而丢失精度时，这称为**舍入误差**。舍入错误可能会使数字略小或略大，具体取决于截断发生的位置。\n舍入错误可能会产生意想不到的后果：\n```cpp\n    std::cout << std::setprecision(17);\n\n    double d1{ 1.0 };\n    std::cout << d1 << '\\n';\n\n    double d2{ 0.1 + 0.1 + 0.1 + 0.1 + 0.1 + 0.1 + 0.1 + 0.1 + 0.1 + 0.1 }; // should equal 1.0\n    std::cout << d2 << '\\n';\n\n输出：\n\t1\n\t0.99999999999999989\n\n尽管我们可能期望 d1 和 d2 应该相等，但我们看到它们并不相等。即使 0.1 在第 17 位有效数字中有舍入误差，但当我们将 0.1 相加 10 次时，舍入误差已经悄悄进入第 16 位有效数字。继续操作将导致此错误变得越来越严重。\n如果我们在程序中比较 d1 和 d2，程序可能无法按预期执行。因为浮点数往往不精确，所以比较浮点数通常是有问题的\n```\n关于舍入误差的最后一点说明：数学运算（例如加法和乘法）往往会使舍入误差增加。\n\n因此，在使用需要比变量可以容纳的精度更高的浮点数时必须小心。**永远不要假设你的浮点数是准确的**。\n除非空间非常宝贵，否则首选 double 而不是 float，因为 float 中缺乏精度通常会导致不准确。\n\n>**C++中表示科学计数法**\n>- 在科学记数法 `1.2 x 10⁴` 中，`1.2` 是有效数字，`4` 是指数。由于 10⁴ 的计算结果10,000， 因此 1.2 x 10⁴ 的计算结果为 12,000。\n>- 由于在 C++ 中很难键入或显示指数，因此我们使用字母“e”（有时使用“E”）来表示方程的“10 次方”部分。例如，`1.2 x 10⁴` 将写入 `1.2e4`，`而 5.9722 x 10²⁴` 将写入 `5.9722e24`。 \n>- 对于小于 1 的数字，指数可以为负数。数字 `5e-2` 相当于 `5 * 10⁻²`，即 `5 / 10²`，即 `0.05`。\n\n\n### 类型转换\n在大多数情况下，C++ 将允许我们将一种基本类型的值转换为另一种基本类型的值。将值从一种类型转换为另一种类型的过程称为**类型转换**\n**隐式类型转换**：编译器不经过询问进行的类型转换\n\t例如，下面print（y) 中 int 变量 `y` 持有的值5将隐式转换为 double 值 `5.0`，然后复制到参数 `x` 中\n```cpp\nvoid print(double x) // print takes a double parameter\n{\n\tstd::cout << x << '\\n';\n}\n\nint main()\n{\n\tint y { 5 };\n\tprint(y); // y is of type int\n\n\treturn 0;\n}\n```\n\n将浮点值转换为整数值会导致删除任何小数分量。\n某些类型转换始终可以安全进行（例如 `int` 到 `double`），而其他类型可能会导致在转换过程中更改值（例如 `double` 到 `int`）。不安全的隐式转换通常会生成编译器警告，或者（在大括号初始化的情况下）生成错误。\n\n###### static_cast\n**显式类型转换**允许我们（程序员）显式地告诉编译器将值从一种类型转换为另一种类型\n要执行显式类型转换，在大多数情况下，我们将使用 `static_cast` 运算符\n```c\nstatic_cast<new_type>(expression)\n```\n\n现在明确请求将 double 值 `5.5` 转换为 `int` 值，因此编译器不会在编译时生成有关可能丢失数据的警告\n```cpp\nvoid print(int x)\n{\n\tstd::cout << x << '\\n';\n}\n\nint main()\n{\n\tprint( static_cast<int>(5.5) ); // explicitly convert double value 5.5 to an int\n\n\treturn 0;\n}\n```\n\n强制转换有符号和无符号类型\n\t如果转换的值不在目标类型的范围内，将会产生如下的结果\n```cpp\n    int s { -1 };\n    std::cout << static_cast<unsigned int>(s) << '\\n'; // prints 4294967295\n\n    unsigned int u { 4294967295 }; // largest 32-bit unsigned int\n    std::cout << static_cast<int>(u) << '\\n'; // implementation-defined prior to C++20, -1 as of C++20\n\n输出：\n\t4294967295\n\t-1\n\nSigned int 值 -1 不能表示为 unsigned int。结果取模为 unsigned int 值 4294967295。\nunsigned int 值 4294967295 不能表示为 signed int。在 C++20 之前，结果是 implementation defined （但可能是 -1）。从 C++20 开始，结果将模 wrap 为 -1。\n```\n\n","tags":["c++"],"categories":["note","c++学习笔记"]},{"title":"c++学习笔记——智能指针—auto_ptr","url":"/2025/01/19/note/c++学习笔记/智能指针—auto_ptr/","content":"智能指针是C++11的新特性\n**智能指针和指针的主要区别**：\n- 普通指针需要**手动管理内存**，容易出现内存泄漏（忘记释放内存）或悬空指针（释放后仍使用指针）。\n\t- 其他：不提供资源所有权管理的概念，多个指针可以指向同一块内存，容易引发内存管理问题\n- 智能指针能够在**自动管理内存**，在智能指针生命周期结束的时候释放指针内存，安全性更高\n\t- 其他：**提供资源所有权的管理**，unique_ptr独占所有权，shared_ptr共享所有权，weak_ptr不占用所有权\n注意事项:\n\t1. **始终在堆栈上分配智能指针，永远不应动态分配智能指针本身**\n\t2. 保证智能指针在包含它的函数或对象结束时正确地超出范围，从而确保智能指针拥有的对象被正确释放。（否则，存在智能指针可能无法正确释放的风险，这意味着它拥有的对象不会被释放，从而导致内存泄漏）\n### auto_ptr\n动态分配的内存经常出现忘了释放的问题，因为指针变量没有固有的机制来清理自身。\n例如下面的，早期执行 return 或 throw 语句，导致函数终止而不删除变量 ptr。\n```cpp\nvoid someFunction()\n{\n    Resource* ptr = new Resource();\n\n    int x;\n    std::cout << \"Enter an integer: \";\n    std::cin >> x;\n\n    if (x == 0)\n        return; // the function returns early, and ptr won’t be deleted!\n\n    // do stuff with ptr here\n\n    delete ptr;\n}\n```\n那么指针能不能像类的对象一样，超出使用范围时自动调用析构函数销毁\n答案是可以，用一个类包装的指针就能实现，下面是智能指针类的初始版本\n\t下面例子中，由于 ptr 变量是局部变量，因此当函数终止时 ptr 将被销毁（无论它如何终止）。由于 Auto_ptr1 析构函数将清理 Resource，因此我们可以确保 Resource 将得到正确清理。\n```c\n#include <iostream>\n\ntemplate <typename T>\nclass Auto_ptr1\n{\n\tT* m_ptr {};\npublic:\n\t// Pass in a pointer to \"own\" via the constructor\n\tAuto_ptr1(T* ptr=nullptr)\n\t\t:m_ptr(ptr)\n\t{\n\t}\n\n\t// The destructor will make sure it gets deallocated\n\t~Auto_ptr1()\n\t{\n\t\tdelete m_ptr;\n\t}\n\n\t// 重载指针符号，Overload dereference and operator-> so we can use Auto_ptr1 like m_ptr.\n\tT& operator*() const { return *m_ptr; }\n\tT* operator->() const { return m_ptr; }\n};\n\n// A sample class to prove the above works\nclass Resource\n{\npublic:\n    Resource() { std::cout << \"Resource acquired\\n\"; }\n    ~Resource() { std::cout << \"Resource destroyed\\n\"; }\n    void sayHi() { std::cout << \"Hi!\\n\"; }\n};\n\nvoid someFunction()\n{\n    Auto_ptr1<Resource> ptr(new Resource()); // ptr now owns the Resource\n\n    int x;\n    std::cout << \"Enter an integer: \";\n    std::cin >> x;\n\n    if (x == 0)\n        return; // the function returns early\n\n    // do stuff with ptr here\n    ptr->sayHi();\n}\n\nint main()\n{\n    someFunction();\n\n    return 0;\n}\n```\n**致命缺陷**： Auto_ptr1类缺乏构造函数，如果用**一个指针初始化另一个指针**（按值传递），编译器将使用默认的浅拷贝构造函数，使两个指针变量指向同一块内存。当指针都调用析构函数销毁时，就会有一个指针变成**悬空指针**，delete空指针将造成未定义的行为\n```cpp\n\tAuto_ptr1<Resource> res1(new Resource());\n\tAuto_ptr1<Resource> res2(res1); // Alternatively, don't initialize res2 and then assign res2 = res1;\n```\n为了能够按值传递，就要使用**移动语义**，转移对象的所有权，而不是拷贝对象\n更新Auto_ptr如下\n```cpp\ntemplate <typename T>\nclass Auto_ptr2\n{\n\tT* m_ptr {};\npublic:\n\tAuto_ptr2(T* ptr=nullptr)\n\t\t:m_ptr(ptr)\n\t{\n\t}\n\n\t~Auto_ptr2()\n\t{\n\t\tdelete m_ptr;\n\t}\n\n\t// 使用移动语义的复制构造函数，被移动的指针a变成了空指针，析构空指针a是安全的。A copy constructor that implements move semantics\n\tAuto_ptr2(Auto_ptr2& a) // note: not const\n\t{\n\t\t// We don't need to delete m_ptr here.  This constructor is only called when we're creating a new object, and m_ptr can't be set prior to this.\n\t\tm_ptr = a.m_ptr; // transfer our dumb pointer from the source to our local object\n\t\ta.m_ptr = nullptr; // make sure the source no longer owns the pointer\n\t}\n\n\t// An assignment operator that implements move semantics\n\t//必须先删除m_ptr再重新转移初始化\n\tAuto_ptr2& operator=(Auto_ptr2& a) // note: not const\n\t{\n\t\tif (&a == this)\n\t\t\treturn *this;\n\n\t\tdelete m_ptr; // make sure we deallocate any pointer the destination is already holding first\n\t\tm_ptr = a.m_ptr; // then transfer our dumb pointer from the source to the local object\n\t\ta.m_ptr = nullptr; // make sure the source no longer owns the pointer\n\t\treturn *this;\n\t}\n\n\tT& operator*() const { return *m_ptr; }\n\tT* operator->() const { return m_ptr; }\n\tbool isNull() const { return m_ptr == nullptr; }\n};\n```\n>悬空指针和nullptr的区别：\n>\t悬空指针是指向已经释放或不再有效的内存地址的指针。虽然它仍然持有一个地址值，但该地址指向的内存可能已经被释放或重分配，使用这样的指针会导致未定义行为。\n>\t```int* p = new int(10);\n\t\tdelete p;   // 释放内存\n\t\t\\*p = 20;    // 未定义行为（悬空指针）```\n>\tnullptr 是 C++11 引入的一种特殊值，用于表示空指针。它明确地表示指针当前不指向任何有效的内存地址。因此可以delete nullptr，这什么都不会发生。但是不能解引用空指针 * nullptr\n\n这就是std::auto_ptr的大致实现。std：：auto_ptr 于 C++98 年引入，并于 C++17 年删除，是 C++ 对标准化智能指针的首次尝试。std：：auto_ptr 选择像 Auto_ptr2 类一样实现移动语义。\n**auto_ptr仍存在的问题**：\n\t1. 由于 auto_ptr 通过**复制语义（复制构造函数和赋值运算符）实现移动语义**，资源的所有权会从源对象转移到目标对象，源对象会失去对资源的控制。\n\t因此**按值将 auto_ptr 传递给函数将导致资源移动到函数参数**（并在函数参数超出范围时在函数结束时销毁）.当你从调用方访问 auto_ptr 参数时（没有意识到它已被传输和删除），你突然取消引用了一个 null 指针。崩溃。\n```c\nvoid process(auto_ptr<int> ap) {  // 按值传递，所有权转移给函数参数\n    cout << \"函数内: \" << *ap << endl;\n}  // 函数结束，ap超出作用域，其指向的int对象被自动删除\n\nint main() {\n    auto_ptr<int> ptr(new int(42));\n    process(ptr);  // 调用函数，ptr的所有权转移给形参ap\n    cout << \"主函数: \" << *ptr << endl;  // 错误！ptr此时已为空指针\n    return 0;\n}\n\n```\n2. auto_ptr 总是使用非数组删除来删除它的内容。这意味着 **auto_ptr 无法正确处理动态分配的数组**，因为它使用了错误类型的释放。\n3. 不适用于stl的容器\n\n### 移动构造和赋值\n移动语义详情见引用和指针一节\n修改我们指针类，增加移动构造和赋值：\n\t移动函数使用**非 const 右值引用**参数（仅绑定到右值），而复制函数使用const 左值引用参数\n\t移动构造函数和移动赋值应标记为 `noexcept`。这告诉编译器这些函数不会引发异常。\n\t这样当传递临时参数时，将调用移动构造函数，避免多次构造临时对象\n```cpp\n\t// 移动构造\n\t// Transfer ownership of a.m_ptr to m_ptr\n\tAuto_ptr4(Auto_ptr4&& a) noexcept\n\t\t: m_ptr(a.m_ptr)\n\t{\n\t\ta.m_ptr = nullptr; // we'll talk more about this line below\n\t}\n\t// 移动赋值\n\t// Transfer ownership of a.m_ptr to m_ptr\n\tAuto_ptr4& operator=(Auto_ptr4&& a) noexcept\n\t{\n\t\t// Self-assignment detection\n\t\tif (&a == this)\n\t\t\treturn *this;\n\n\t\t// Release any resource we're holding\n\t\tdelete m_ptr;\n\n\t\t// Transfer ownership of a.m_ptr to m_ptr\n\t\tm_ptr = a.m_ptr;\n\t\ta.m_ptr = nullptr; // we'll talk more about this line below\n\n\t\treturn *this;\n\t}\n\t//深拷贝复制\n\t// Copy constructor\n\t// Do deep copy of a.m_ptr to m_ptr\n\tAuto_ptr4(const Auto_ptr4& a)\n\t{\n\t\tm_ptr = new T;\n\t\t*m_ptr = *a.m_ptr;\n\t}\n\n\t// Copy assignment\n\t// Do deep copy of a.m_ptr to m_ptr\n\tAuto_ptr4& operator=(const Auto_ptr4& a)\n\t{\n\t\t// Self-assignment detection\n\t\tif (&a == this)\n\t\t\treturn *this;\n\n\t\t// Release any resource we're holding\n\t\tdelete m_ptr;\n\n\t\t// Copy the resource\n\t\tm_ptr = new T;\n\t\t*m_ptr = *a.m_ptr;\n\n\t\treturn *this;\n\t}\n```\n实际上需要删除 copy 构造函数和 copy 赋值函数，以确保不会进行复制，因为深拷贝的代价很昂贵。\n```cpp\n\t// Copy constructor -- no copying allowed!\n\tAuto_ptr4(const Auto_ptr5& a) = delete;\n\t// Copy assignment -- no copying allowed!\n\tAuto_ptr4& operator=(const Auto_ptr5& a) = delete;\n\n```\n\n\n\n\n","tags":["c++"],"categories":["note","c++学习笔记"]},{"title":"c++学习笔记——继承","url":"/2025/01/09/note/c++学习笔记/继承/","content":"\n## 继承\n**继承**：是指一个类（子类）可以继承另一个类（父类）的属性和行为。继承表示一种 \"is-a\"（是一个）关系\n\t好处：继承实现了代码的重用和模块化，减少重复代码的编写。实现类之间的层次关系。如果我们更新或修改基类（例如添加新函数或修复错误），我们所有的派生类都将自动继承这些更改\n基类：定义层次关系中所有类的共用成员\n派生类：继承基类，定义自己的特有成员, 重写虚函数\n\n实例：BaseballPlayer继承Person类，使用冒号`:`、单词`public` 和我们希望继承的类的名称，称为`公共继承`\n```cpp\nclass Person\n{\n// In this example, we're making our members public for simplicity\npublic:\n    std::string m_name{};\n    int m_age{};\n\n    Person(std::string_view name = \"\", int age = 0)\n        : m_name{ name }, m_age{ age }\n    {\n    }\n\n    const std::string& getName() const { return m_name; }\n    int getAge() const { return m_age; }\n\n};\n\n// BaseballPlayer publicly inheriting Person\nclass BaseballPlayer : public Person\n{\npublic:\n    double m_battingAverage{};\n    int m_homeRuns{};\n\n    BaseballPlayer(double battingAverage = 0.0, int homeRuns = 0)\n       : m_battingAverage{battingAverage}, m_homeRuns{homeRuns}\n    {\n    }\n};\n```\n#### 派生类的实例化\n派生类对象实际包含基类部分和派生类部分。\n\t- 首先，构造最基类（位于继承树的顶部， 会调用默认构造函数）。然后按顺序构造每个子类，直到最后构造最子类（位于继承树的底部）\n\t- 销毁派生类时，将按构造的相反顺序调用每个析构函数。\n**派生类中初始化基类**：如果派生类构造时要初始化基类参数，可以使用委托构造函数的方法，显示指定要调用的Base构造函数\n\t注意：派生类的构造函数只能直接调用基类的构造函数，不能调用更祖宗的构造函数。例如C继承B，B继承A，C只能调用B的构造函数，不能调用A\n```c\nclass Derived: public Base\n{\npublic:\n    double m_cost {};\n\n    Derived(double cost=0.0, int id=0)\n        : Base{ id } // Call Base(int) constructor with value id!\n        , m_cost{ cost }\n    {\n    }\n\n    double getCost() const { return m_cost; }\n};\n```\n#### 访问控制\n- 派生类不能直接访问修改基类的私有成员，可以使用`protected`让派生类访问基类成员，而对外界屏蔽。\n\t但最好将成员设为私有，并且仅在规划派生类并且构建和维护这些私有成员的接口的成本太高时才使用 protected\n- **三种访问控制继承**\n\tC++ 默认为私有继承\n\t- public继承：最常用的继承，不会修改基类成员的任何属性\n\t- protected继承：基类的`public`成员在派生类中变为`protected`。几乎没人使用,\n\t- private继承：基类中的所有成员都作为 private 继承。也就是说无法通过派生类直接访问基类的任何成员（不过，派生类内部函数仍可以访问基类的public和protected成员）\n\t\t- 当派生类与基类没有明显的关系，但在内部使用基类进行实现时，私有继承可能很有用。\n```c\n// Inherit from Base publicly\nclass Pub: public Base\n{\n};\n\n// Inherit from Base protectedly\nclass Pro: protected Base\n{\n};\n\n// Inherit from Base privately\nclass Pri: private Base\n{\n};\n\nclass Def: Base // Defaults to private inheritance\n{\n};\n```\nprivate继承的实例：派生类内部可以访问修改m_public和m_protected，但派生类对象不能直接访问修改任何Base中有的成员\n```c\nclass Base\n{\npublic:\n    int m_public {};\nprotected:\n    int m_protected {};\nprivate:\n    int m_private {};\n};\n\nclass Pri: private Base // note: private inheritance\n{\n    // Private inheritance means:\n    // Public inherited members become private (so m_public is treated as private)\n    // Protected inherited members become private (so m_protected is treated as private)\n    // Private inherited members stay inaccessible (so m_private is inaccessible)\npublic:\n    Pri()\n    {\n        m_public = 1; // okay: m_public is now private in Pri\n        m_protected = 2; // okay: m_protected is now private in Pri\n        m_private = 3; // 不能访问，not okay: derived classes can't access private members in the base class\n    }\n};\n\nint main()\n{\n    // Outside access uses the access specifiers of the class being accessed.\n    // In this case, the access specifiers of base.\n    Base base;\n    base.m_public = 1; // okay: m_public is public in Base\n    base.m_protected = 2; // not okay: m_protected is protected in Base\n    base.m_private = 3; // not okay: m_private is private in Base\n\n    Pri pri;\n    pri.m_public = 1; // 不能访问，not okay: m_public is now private in Pri\n    pri.m_protected = 2; // 不能访问，not okay: m_protected is now private in Pri\n    pri.m_private = 3; // 不能访问，not okay: m_private is inaccessible in Pri\n\n    return 0;\n}\n```\n\n- 派生类可以修改基类的可访问成员(protected，public) 的访问说明符\n\t- 可以将 基类的public 成员在派生类中设为 private，隐藏基类中存在的功能，以便无法通过派生类访问它。\n\t- 下面的例子中，虽然 m_value 在 Derived 类中是 private，但它在 Base 类中仍然是 public。因此，Derived 中 m_value 的封装仍然可以通过强制转换为 Base& 并直接访问成员来颠覆。\n```cpp\nclass Base\n{\npublic:\n    int m_value {};\nprotected:\n    void printValue() const { std::cout << m_value; }\n};\n\nclass Derived: public Base\n{\nprivate:\n\tusing Base::m_value;\n\npublic:\n    Derived(int value)\n        : Base { value }\n    {\n    }\n\n    // Base::printValue was inherited as protected, so the public has no access\n    // But we're changing it to public via a using declaration\n    using Base::printValue; // note: no parenthesis here\n};\nint main()\n{\n    Derived derived { 7 };\n\tstd::cout << derived.m_value; // error: m_value is private in Derived\n\t\n    // printValue is public in Derived, so this is okay\n    derived.printValue(); // prints 7\n    return 0;\n}\n```\n#### 派生类调用函数\n调用成员函数步骤：编译器将从派生程度最高的类中选择最匹配的函数\n1. 首先检查派生类自己有没有该函数\n2. 如果有，则考虑具有该名称的所有重载函数，并使用函数重载解析过程来确定是否存在最佳匹配项\n3. 如果没有，编译器将遍历继承链，以相同的方式依次检查每个父类\n\n可以在派生类重新定义基类的同名函数，但这会隐藏所有基类的同名函数。\n- 如果在派生类中需要调用同名的基函数，要为函数加上基类的 scope 限定符\n```cpp\n\tclass Base\n\t{\n\tpublic:\n\t    Base() { }\n\t\n\t    void identify() const { std::cout << \"Base::identify()\\n\"; }\n\t};\n\t\n\tclass Derived: public Base\n\t{\n\tpublic:\n\t    Derived() { }\n\t\n\t    void identify() const\n\t    {\n\t        std::cout << \"Derived::identify()\\n\";\n\t        Base::identify(); // note call to Base::identify() here，如果没有范围解析限定符，将调用本类的identify（）\n\t    }\n\t};\n\t```\n- 也可以使用 using 声明，以使所有具有特定名称的 `Base` 函数在 `Derived` 中可见，这样可以在对象中调用`Base`的同名函数\n\t- 下面案例中，通过将 `using using :print; 的` using 声明放入 `Derived` 中，我们告诉编译器所有名为 `print` 的 `Base` 函数都应该在 `Derived` 中可见，这将使它们有资格进行重载解析。因此，在 `Derived：:p rint（double）` 上选择了 `Base：:p rint（int）。`\n```cpp\nclass Base\n{\npublic:\n    void print(int)    { std::cout << \"Base::print(int)\\n\"; }\n    void print(double) { std::cout << \"Base::print(double)\\n\"; }\n};\n\nclass Derived: public Base\n{\npublic:\n    using Base::print; // make all Base::print() functions eligible for overload resolution\n    void print(double) { std::cout << \"Derived::print(double)\"; }\n};\n\n\nint main()\n{\n    Derived d{};\n\n    d.print(5); // calls Base::print(int), which is the best matching function visible in Derived\n\n    return 0;\n}\n```\n- 在尝试调用基类中的友元函数（如 `operator<<）`时，可能会遇到一些棘手的问题。因为基类的友元函数实际上不是基类的一部分，所以使用 scope resolution 限定符将不起作用。我们需要使用 `static_cast`使我们的 `Derived` 类暂时看起来像 `Base` 类，以便可以调用函数的正确版本。\n```cpp\nclass Base\n{\npublic:\n    Base() { }\n\n\tfriend std::ostream& operator<< (std::ostream& out, const Base&)\n\t{\n\t\tout << \"In Base\\n\";\n\t\treturn out;\n\t}\n};\n\nclass Derived: public Base\n{\npublic:\n    Derived() { }\n\n \tfriend std::ostream& operator<< (std::ostream& out, const Derived& d)\n\t{\n\t\tout << \"In Derived\\n\";\n\t\t// static_cast Derived to a Base object, so we call the right version of operator<<\n\t\t//强制转换为 Base& 而不是 Base，以避免复制派生的 Base 部分\n\t\tout << static_cast<const Base&>(d);\n\t\treturn out;\n    }\n};\n```\n\n在派生类中重新定义函数时，派生函数不会继承基类中具有相同名称的函数的访问说明符。因此，在基类中定义为 private 的函数可以在派生类中重新定义为 public，反之亦然！\n\n#### 多重继承\nC++ 提供了执行多重继承的能力。**多重继承**使派生类能够从多个父类继承成员。\n假设我们想编写一个程序来跟踪一群教师。老师是一个人。但是，教师也是雇员（如果为自己工作，他们是自己的雇主）。\n```cpp\nclass Person\n{\nprivate:\n    std::string m_name{};\n    int m_age{};\n\npublic:\n    Person(std::string_view name, int age)\n        : m_name{ name }, m_age{ age }\n    {\n    }\n\n    const std::string& getName() const { return m_name; }\n    int getAge() const { return m_age; }\n};\n\nclass Employee\n{\nprivate:\n    std::string m_employer{};\n    double m_wage{};\n\npublic:\n    Employee(std::string_view employer, double wage)\n        : m_employer{ employer }, m_wage{ wage }\n    {\n    }\n\n    const std::string& getEmployer() const { return m_employer; }\n    double getWage() const { return m_wage; }\n};\n\n// Teacher publicly inherits Person and Employee\nclass Teacher : public Person, public Employee\n{\nprivate:\n    int m_teachesGrade{};\n\npublic:\n    Teacher(std::string_view name, int age, std::string_view employer, double wage, int teachesGrade)\n        : Person{ name, age }, Employee{ employer, wage }, m_teachesGrade{ teachesGrade }\n    {\n    }\n};\n\nint main()\n{\n    Teacher t{ \"Mary\", 45, \"Boo\", 14.3, 8 };\n\n    return 0;\n}\n```\nmixin多重继承\n```c\n// h/t to reader Waldo for this example\n#include <string>\n\nstruct Point2D\n{\n\tint x{};\n\tint y{};\n};\n\nclass Box // mixin Box class\n{\npublic:\n\tvoid setTopLeft(Point2D point) { m_topLeft = point; }\n\tvoid setBottomRight(Point2D point) { m_bottomRight = point; }\nprivate:\n\tPoint2D m_topLeft{};\n\tPoint2D m_bottomRight{};\n};\n\nclass Label // mixin Label class\n{\npublic:\n\tvoid setText(const std::string_view str) { m_text = str; }\n\tvoid setFontSize(int fontSize) { m_fontSize = fontSize; }\nprivate:\n\tstd::string m_text{};\n\tint m_fontSize{};\n};\n\nclass Tooltip // mixin Tooltip class\n{\npublic:\n\tvoid setText(const std::string_view str) { m_text = str; }\nprivate:\n\tstd::string m_text{};\n};\n\nclass Button : public Box, public Label, public Tooltip {}; // Button using three mixins\n\nint main()\n{\n\tButton button{};\n\t//使用显式的 `Box：：`、`Label：：`和 `Tooltip：：` 范围解析前缀\n\tbutton.Box::setTopLeft({ 1, 1 });\n\tbutton.Box::setBottomRight({ 10, 10 });\n\tbutton.Label::setText(\"Submit\");\n\tbutton.Label::setFontSize(6);\n\tbutton.Tooltip::setText(\"Submit the form to the server\");\n}\n```\n由于 mixin 旨在向派生类添加功能，而不是提供接口，因此 mixin 通常不使用虚函数\n\n**Curiously Recurring Template Pattern**:CRTP,派生类可以使用派生类作为模板类型参数从 mixin 基类继承\n```c\n// The Curiously Recurring Template Pattern (CRTP)\n\ntemplate <class T>\nclass Mixin\n{\n    // Mixin<T> can use template type parameter T to access members of Derived\n    // via (static_cast<T*>(this))\n};\n\nclass Derived : public Mixin<Derived>\n{\n};\n```\n**多重继承的问题**：\n- 命名冲突：当多个基类包含同名的函数时，可能会导致歧义\n\t- 可以显式指定要调用的父类版本\n- [钻石问题](https://en.wikipedia.org/wiki/Diamond_problem)：\n![[继承-1.png]]\t\n- 在这种情况下会出现许多问题，包括 Copier 是否应该有一个或两个 PoweredDevice 副本，以及如何解决某些类型的歧义引用。\n- 可以使用虚基类避免重复构造PoweredDevice的问题\n```c\nclass PoweredDevice\n{\n};\n\nclass Scanner: public PoweredDevice\n{\n};\n\nclass Printer: public PoweredDevice\n{\n};\n\nclass Copier: public Scanner, public Printer\n{\n};\n```\n\n#### 避免继承\n使用关键字`final`\n```c\nclass NonInheritable final {\npublic:\n    // 类的成员和方法定义\n};\n\n```\n#### 对象切片\n派生类对象复制到基类对象时，将去除掉派生类对象的部分，只保留基类对象\n实\n\t- 将 Derived 对象分配给 Base 对象时，仅复制 Derived 对象的 Base 部分。\n```cpp\nint main()\n{\n    Derived derived{ 5 };\n    Base base{ derived }; // what happens here?\n    std::cout << \"base is a \" << base.getName() << \" and has value \" << base.getValue() << '\\n';\n\n    return 0;\n}\n```\n避免对象切片的方式：\n1. 通过将函数参数设为引用而不是按值传递\n```c\nvoid printName(const Base& base) // note: base now passed by reference\n{\n    std::cout << \"I am a \" << base.getName() << '\\n';\n}\n```\n\n  2. 尝试使用 std：：vector 实现多态性时，使用类指针\n```c\n\tstd::vector<Base*> v{};\n\n\tBase b{ 5 }; // b and d can't be anonymous objects\n\tDerived d{ 6 };\n\n\tv.push_back(&b); // add a Base object to our vector\n\tv.push_back(&d); // add a Derived object to our vector\n```\n\n#### 向下转换\nC++会进行隐式地向上转换——将派生指针转换为基类指针。但当需要使用基类指针或引用访问特定于派生类的内容时，就需要将基类指针引用转换为派生类指针引用，即**向下转换**。\n\t使用**dynamic_cast** 的强制转换运算符将基类指针转换为派生类指针（只在有虚表的类起作用）\n\t如果dynamic_cast失败（如没有指向派生类对象），则转换结果将为 null 指针,因此要确保转换后指针不为空\n\t由于 dynamic_cast 在运行时会进行一些一致性检查（以确保可以进行转换， static_cast则不会检查），因此使用 dynamic_cast 确实会导致性能下降。\n\t例如下面代码\n```c\nBase* getObject(bool returnDerived)\n{\n\tif (returnDerived)\n\t\treturn new Derived{1, \"Apple\"};\n\telse\n\t\treturn new Base{2};\n}\nint main()\n{\n\tBase* b{ getObject(true) };\n\n\tDerived* d{ dynamic_cast<Derived*>(b) }; // use dynamic cast to convert Base pointer into Derived pointer\n\n\tif (d) // make sure d is non-null\n\t\tstd::cout << \"The name of the Derived is: \" << d->getName() << '\\n';\n\n\tdelete b;\n\n\treturn 0;\n}\n```\n在以下几种情况下，使用 dynamic_cast 进行降级不起作用：\n\t1.使用 protected 或 private 继承。\n\t2. 对于不声明或继承任何虚函数（因此没有虚表）的类。\n\t3. 在某些情况下，涉及虚拟基类\n\t4. 编译器关闭了 RTTI\n\n兄弟类指针引用之间的转换：使用`reinterpret_cast`\n例如下面的Derived1、Derived2均继承自Base\n```cpp\nint main()\n{\n\tDerived2 red_apple{ 1, \"Apple\",\"Red\" }; // create a red apple\n\tDerived1& d{ reinterpret_cast<Derived1&>(red_apple) }; // convert to Derived1 so we can call getName because Derived2 does not implement that for some important reason!\n\n\tstd::cout << \"The name of the Derived is: \" << d.getName() << '\\n';\n\n\treturn 0;\n}\n```\n#### **动态绑定**\n在虚函数**运行时**，通过引用（或指针）指向的对象来决定函数运行的版本。普通函数或者对象直接调用的虚函数则是在编译时进行静态绑定。\n当我们使用基类的引用（或指针）调用一个虚函数时将发生动态绑定。\n！注意：动态绑定只有当通过**指针或引用调用虚函数时**才会发生。\n```c\ndouble print_total(ostream&os,const Quote&item,size_t n){\n    double ret = item.net_price(n);  //调用基类还是派生类的虚函数？\n    return ret;\n}\nprint total(cout, basic, 20);  // 调用Quote  的net price函数 \nprint total(cout, bulk, 20);  //  调用Bulk quote的net price函数\n```\n\n#### 组合\n**组合**：表示一个类可以包含另一个类的对象作为其成员变量。表示一种“has-a”关系（拥有关系）或者“part-of”关系（部分关系）。\n\t好处：通过将不同的功能和特性分解成独立的类，可以将这些类组合成更复杂的类。在这种情况下，组合的类不需要知道其成员对象的内部实现细节，只需要知道如何与它们交互。\n\n\n","tags":["c++"],"categories":["note","c++学习笔记"]},{"title":"CUDA笔记——多GPU编程","url":"/2024/11/24/note/cuda/CUDA笔记——多GPU编程/","content":"\n### 设备间对等内存访问(Peer-to-Peer Memory Access)\n计算能力2.0及以上的设备支持设备间对等内存访问，**这意味着两个GPU之间的传输和访问可以不经过主机端中转**（通过PCIe或者nvlink），速度会有提升。查询`cudaDeviceCanAccessPeer()`可以得知设备是否支持这一特性。_(官方文档说还需要一个条件：64位程序，存疑)_\n\n需要使用`cudaDeviceEnablePeerAccess()`来开启这一特性。\n\n对等设备的的地址都使用统一虚拟地址空间的，可用同一个指针访问，如下例：\n\n```cpp\ncudaSetDevice(0);   // Set device 0 as current\nfloat* p0;\nsize_t size = 1024 * sizeof(float);\ncudaMalloc(&p0, size);      // Allocate memory on device 0\nMyKernel<<<1000, 128>>>(p0);    // Launch kernel on device 0\ncudaSetDevice(1);               // Set device 1 as current\ncudaDeviceEnablePeerAccess(0, 0);   // Enable peer-to-peer access with device 0\n\n// Launch kernel on device 1\n// This kernel launch can access memory on device 0 at address p0\nMyKernel<<<1000, 128>>>(p0);\n```\n### 设备间对等内存拷贝(Peer-to-Peer Memory Copy)\n\n对等设备的地址是支持统一编址和设备间对等内存访问的，可以直接使用`cudaMemcpy`直接在多gpu中直接点对点拷贝数据\n如何不直接支持统一编址，那么要使用`cudaMemcpyPeer()、cudaMemcpyPeerAsync()、cudaMemcpy3DPeer、cudaMemcpy3DPeerAsync()`来进行直接拷贝。无需先拷贝会主机端内存，再转到另一块卡上。\n注意对等内存拷贝不能并发执行，有点像同步\n\n支持p2p的设备，kernel函数可以同时访问多设备的内存\n如下例：\n\n```cpp\ncudaSetDevice(0);   // Set device 0 as current\nfloat* p0;\nsize_t size = 1024 * sizeof(float);\ncudaMalloc(&p0, size);  // Allocate memory on device 0\ncudaSetDevice(1);\nfloat* p1;\ncudaMalloc(&p1, size);  // Allocate memory on device 1\ncudaSetDevice(0);       // Set Device 0 as Current\nMyKernel<<<1000, 128>>>(p0);    // Launch Kernel on Device 0\ncudaSetDevice(1);               // Set Device 1 as Current\ncudaMemcpyPeer(p1, 1, p0, 0, size); // Copy p0 to p1\nMyKernel<<<1000, 128>>>(p1);        // Launch Kernel on Device 1\n```\n\n关于设备间的对等拷贝，如果使用的是NULL stream（流介绍见下面），则有如下性质：  \n_如果拷贝的双方中的任何一方，在设备拷贝前有任务未完成，则拷贝会被阻塞，直至任务完成。_ 只有拷贝结束后，两者的后续任务才能继续执行。\n\n### 多GPU上流和事件：\n对不属于当前设备的流和事件操作会失败：\n\t1. 流的内核启动\n\t2. 事件计时\n会成功：\n\t1. 异步内存拷贝\n\t2. 事件同步或查询\n\t3. 事件同步流（也就是说可以用事件来同步不同设备的流）","tags":["cuda"],"categories":["note","cuda"]},{"title":"CUDA笔记——流与异步并行（二）","url":"/2024/11/16/note/cuda/CUDA笔记——流与异步并行（二）/","content":"## CUDA并行行为\nCUDA允许以下操作异步并行：  \n- _主机端计算_ \n- 设备端计算(内核执行) \n- _主机端to设备端传数据_ \n- 设备端to主机端传数据 \n- _设备端内部传数据_ \n- 设备间传数据(可通过PCI-E直接传输，不需要先传到主机端再转发，_不过这一操作跟使用的操作系统有关_)\n\ndevice与host并行的行为：\n1. 内核启动与执行(可以通过将`CUDA_LAUNCH_BLOCKING`设为1，来禁止内核执行并行，debug使用)\n2. 设备端内部传输数据 _64KB及以下的 host-to-device数据传输_ \n\t- 在使用`cudaMemcpy()`时，如果数据小于等于64KB，其实传输相对于CPU是异步的。 如果数据多于64KB，则CPU会阻塞到数据传输完成。\n3. 使用流(带有`Async`前缀的内存传输函数)或内存映射传输数据（不再受64KB的限制）\n\t- 使用`Async`传输函数，不仅可以和CPU并行，而且可以和内核执行并行。\n\t- 如果没有使用锁页内存，即使使用了`Async`函数，内存传输也不是并行的\n4. 设备端memset函数(`cudaMemset()`)\n\n### 内核并行执行\n计算能力2.x及以上的设备，支持多个内核函数同时执行。(可以通过检查`concurrentKernels`来确定)\n\n- **执行多个内核函数，需要主机端不同的线程启动。如果一个线程依次启动多个内核，则这些内核会串行执行。同一线程的内核函数返回时会触发隐式的同步。**\n- 另外，多个内核函数必须位于同一个CUDA上下文(CUDA context)上。不同CUDA上下文上的内核不能并行。这意味着，启动多个内核的多个线程必须使用相同的CUDA上下文。(_如何传递CUDA上下文？_)\n\n### 数据并行传输(需要使用锁页内存)\n- 计算能力2.x及以上的设备，支持数据传入和传出并行。\n- 一些设备支持数据传输(主机端/设备端、设备端/设备端)和内核执行并行，可通过检查`asyncEngineCount`来确认。\n- 必须使用锁页内存。\n\n\n\n\n## 流\n\n在CUDA中，**流(streams)** 指的是在GPU上一连串执行的命令的操作队列，可以将其理解为数据的流动。CUDA通过流管理上面的并发操作。\n\n- 不同的线程，可以向同一个流填入任务。\n- **同一个流内的任务的执行是顺序和同步的**；\n- 同一设备上**不同的流可以并行**，其执行顺序不会有保证（当然是在GPU资源够用的情况下并行，不够用的话流就得排队了）\n\t- CUDA流可以看作是一条**命令流水线**，每个CUDA流都有自己的计算资源，包括寄存器、共享内存、全局内存等，这些资源是独立的，不同流之间不会相互干扰。\n![CUDA stream 与 CUDA event 详解_cudastreamwaitevent-CSDN博客](https://img-blog.csdnimg.cn/img_convert/87a785793d1839f95711d4484a38f9f0.png)\n- **多个流启动不同的内核函数**，就实现了单GPU的网格级的并行\n\n要实现流操作，有四个条件：\n1. GPU设备支持设备重叠功能(device overlap)\n2. 主机内存应被分配为锁页内存`pinned memory`，并使用使用锁页内存传输数据。\n3. 在主机和 GPU 之间传输数据而不阻塞主机进程(cudaMemcpyAsync() 函数)。\n4. 将每个操作放到不同的 CUDA 流中管理，以实现并发操作。\n\n\n### 流的创建和销毁\n下述代码是一个流的创建和销毁的例子。该程序创建了两个流，分配了两个锁页内存传输数据，依次启动了两个内核，最后销毁了这两个流。\n```c\ncudaStream_t stream[2];     //创建流\nfor (int i = 0; i < 2; ++i)\n    cudaStreamCreate(&stream[i]);    //初始化流\nfloat* hostPtr;\ncudaMallocHost(&hostPtr, 2 * size);  //锁页内存\n\nfor (int i = 0; i < 2; ++i) {  //如果设备支持数据传输和内核执行并行，那么下面数据传输和两个流启动的内核是可以并行的；不支持的话就是串行\n    cudaMemcpyAsync(inputDevPtr + i * size, hostPtr + i * size,\n                    size, cudaMemcpyHostToDevice, stream[i]);  //与普通的cudaMemcpy区别是:配合流使用异步数据传输，数据传输在后台copy引擎进行，不阻塞主机线程。要求是锁页内存\n                //cudaMemcpy是同步，调用时会阻塞主机线程，直到数据传输完成。\n    MyKernel <<<100, 512, 0, stream[i]>>>   \n        (outputDevPtr + i * size, inputDevPtr + i * size, size);  //使用流执行内核\n    cudaMemcpyAsync(hostPtr + i * size, outputDevPtr + i * size,\n                    size, cudaMemcpyDeviceToHost, stream[i]);\n}\n//for循环结束后,主机继续执行下面的代码，不会去等待上面的任何异步操作（当然同一个流中任务的执行是同步的，这样代码才执行正确）\n......\n//同步主机和流。同步后才能释放内存\nfor (int i = 0; i < 2; ++i)\n\tcudaStreamSynchronize(stream[i]);\n//释放内存\ncudaFreeHost(hostPtr);    \n//销毁流，但会在流执行完毕后回收\nfor (int i = 0; i < 2; ++i)\n    cudaStreamDestroy(stream[i]);\n```\n\n流的创建需要定义`cudaStream_t`结构，并调用`cudaStreamCreate()`来初始化。  \n流的销毁需要调用`cudaStreamDestroy()`来实现。\n\n当向流中添加内核函数任务时，不再是`<<<blocksPerGrid, threadsPerBlock>>>`，而是`<<<blocksPerGrid, threadsPerBlock, dynamic_shared_memory, stream>>>`。  \n\t其中dynamic_shared_memory指的是动态共享内存的大小(_回去翻书_)； stream就是`cudaStream_t`结构。\n\n当设备还在执行流中的任务，而用户调用`cudaStreamDestroy()`函数时，会等待当流中的任务完成后，与流相关的资源会自动释放。\n\n**另外需要注意的是，上例中主机端线程、数据拷贝和内核执行完全异步，因此在\"拷贝回主机端\"这一操作完成之前，主机端的内存数据是不正确的。必须在数据返回的一步做同步操作，方能保证数据是正确的。**\n\n### 默认流(Default Stream)\n\n在调用内核函数时，不指定流或者将流指定为0，则代表使用了默认流(default stream)。\n也就是说cuda任务的执行都是在流中进行。\n\n如果在编译时使用了`--default-stream per-thread`，或是在include任何cuda头文件前`#define CUDA_API_PER_THREAD_DEFAULT_STREAM`，则主机端的每一个线程都有自己专属的默认流。  \n而如果在编译时未指定相关flag，或指定`--default-stream legacy`，则默认流是一个特殊的流，称作NULL stream。主机端的所有线程会共享这个NULL stream。NULL stream是一个同步流，所有命令会产生隐式同步。\n\n### 流的优先级(Stream Priorities)\n\n可以通过`cudaStreamCreateWithPriority()`来在创建流时指定流的优先级。可以指定的优先级可由`cudaDeviceGetStreamPriorityRange()`来获得。\n\n运行时，高优先级stream中的线程块不能打断正在执行的低优先级stream的线程块(即不是抢占式的)。但是当低优先级stream的线程块退出SM时，高优先级stream中的线程块会被优先调度进SM。\n\n### 流同步\n\n显式同步：  \n`cudaDeviceSynchronize()`：直到**所有线程**向设备端的**所有流**的**所有已送入指令**完成，才会退出阻塞。\n`cudaStreamSynchronize()`：直到**指定流**的**之前所有已送入指令**完成，才会退出阻塞。此函数可以用作同步指定流，而其他流可以不受干扰地继续运行。  \n`cudaStreamWaitEvent()`：需要stream和event作为输入参数。在调用该函数之后的命令，需要等待该函数等待的事件(Event)发生后，才能执行。如果stream指定为0，则对于向所有stream加入的命令来说，只要加在了该函数之后，都会阻塞直到等待的时间发生方可执行。(不知道我理解的对不对：如果是Event->内核1->WaitEvent->内核2，则内核1不用等到Event发生就可以执行，而内核2必须等到Event发生才能执行。还是说内核1其实只有等待Event发生后才会执行？) (如果多个线程向同一个流压入了任务，然后线程0调用了cudaStreamWaitEvent()，则线程1会不会被阻塞？线程1压入的任务会不会被阻塞？) \n`cudaStreamQuery()`：查询流内所有压入的指令(preceding commands)是否全部完成。\n\n注意，同步函数慎用，因为有可能会产生速度的下降。\n\n隐时同步：不同流可以并行。但是当任何一个流执行如下的命令时，情况例外，不能并行： \n\t锁页内存的分配，设备端内存分配 ，设备端内存设置(memset)，设备内部拷贝 ，NULL stream内的命令， L1 cache｜共享内存空间的重新分配\n\n### 回调函数(Callbacks)\n`cudaStreamAddCallback()`函数，向流中添加callback。callback会在流中所有的任务完成后被调用。\n\t如果stream参数设为0，则代表之前的所有stream的任务执行完后就调用该callback。\n\t和`cudaStreamWaitEvent()`一样，对于在加在callback之后的指令，必须等待callback执行完成后，才会继续执行。\n\t\n下例是一个使用回调的例子。该例中，两个stream将数据拷回主机端后，会调用回调函数。\n```cpp\nvoid CUDART_CB MyCallback(cudaStream_t stream, cudaError_t status, void *data){\n    printf(\"Inside callback %d\\n\", (size_t)data);\n}\n...\nfor (size_t i = 0; i < 2; ++i) {\n    cudaMemcpyAsync(devPtrIn[i], hostPtr[i], size, cudaMemcpyHostToDevice, stream[i]);\n    MyKernel<<<100, 512, 0, stream[i]>>>(devPtrOut[i], devPtrIn[i], size);\n    cudaMemcpyAsync(hostPtr[i], devPtrOut[i], size, cudaMemcpyDeviceToHost, stream[i]);\n    //调用回调函数MyCallback\n    cudaStreamAddCallback(stream[i], MyCallback, (void*)i, 0);\n}\n```\n注意：回调函数中不能直接或间接的执行CUDA函数，否则会因为等待自己完成而造成死锁。\n\n### 事件\n事件(Event)可以被压入流中以监视流的运行情况，或者用于精确计时。有点像专用于流的printf\n\n如果向stream 0压入事件，则当压入事件前向所有流压入的任务完成后，事件才被触发。\n\n创建和销毁：\n```cpp\ncudaEvent_t start, stop;    //创建\ncudaEventCreate(&start);\ncudaEventCreate(&stop);\n...\ncudaEventDestroy(start);    //销毁\ncudaEventDestroy(stop);\n```\n\n使用Event计算时间的例子\n```cpp\ncudaEventRecord(start, 0);  //记录事件(将事件压入流)，流0则代表所有流完成任务后事件才会被触发\nfor (int i = 0; i < 2; ++i) {\n    cudaMemcpyAsync(inputDev + i * size, inputHost + i * size, size, cudaMemcpyHostToDevice, stream[i]);\n    MyKernel<<<100, 512, 0, stream[i]>>>(outputDev + i * size, inputDev + i * size, size);\n    cudaMemcpyAsync(outputHost + i * size, outputDev + i * size, size, cudaMemcpyDeviceToHost, stream[i]);\n}\ncudaEventRecord(stop, 0);\ncudaEventSynchronize(stop);\nfloat elapsedTime;\ncudaEventElapsedTime(&elapsedTime, start, stop);    //获取两个事件发生的时间差(ms)\n```\n\n\n\n### (多设备下)流和事件的执行情况\n下面将讨论，如果对一个不属于当前设备的流或事件进行操作，哪些操作会成功，哪些操作会失败：\n\n- **内核启动**(will fail)：如果将内核压入不属于当前设备的流中，则内核会启动失败。也就是说，如果要向一个流中压入内核，必须先切换到流所在的设备：\n\n```cpp\ncudaSetDevice(0);   // Set device 0 as current\ncudaStream_t s0;\ncudaStreamCreate(&s0);  // Create stream s0 on device 0\nMyKernel<<<100, 64, 0, s0>>>(); // Launch kernel on device 0 in s0\ncudaSetDevice(1);   // Set device 1 as current\ncudaStream_t s1;\ncudaStreamCreate(&s1);  // Create stream s1 on device 1\nMyKernel<<<100, 64, 0, s1>>>(); // Launch kernel on device 1 in s1\n\n// This kernel launch will fail:内核启动是向未与当前设备关联的流发出的，即流s0与设备1无关，启动失败\nMyKernel<<<100, 64, 0, s0>>>(); // Launch kernel on device 1 in s0\n```\n\n- **内存拷贝**(will success)：如果对一个不属于当前设备的流进行内存拷贝工作，内存拷贝会成功。\n- **cudaEventRecord()**(will fail)：必须现将设备上下文切换过去，再向流压入事件。\n- **cudaEventElapsedTime()**(will fail)：计算时间差前，必须先切换设备。\n- **cudaEventSynchronize() and cudaEventQuery()**(will success)：即使处于不同的设备，事件同步和事件查询依然有效。\n- **cudaStreamWaitEvent()**(will success)：比较特殊，即使函数输入的流和事件不在同一个设备上，也能成功执行。也就是说，可以让流等待另一个设备上(当然当前设备也可以)的事件。这个函数可以用作多个设备间的同步。\n\n另外需要注意，**每个设备都有自己的默认流**。因此在没有指定流的情况下，向不同设备分派的任务，实际上是压入了各个设备的默认流，他们之间是并行执行的。\n","tags":["cuda"],"categories":["note","cuda"]},{"title":"CUDA笔记——流与异步并行（一）","url":"/2024/11/16/note/cuda/CUDA笔记——流与异步并行（一）/","content":"## 锁页内存\n\n**锁页内存(Page-Locked Host Memory/Pinned Memory)** 指的是主机端上不会被换出到虚拟内存(位于硬盘)上的内存。\n- Malloc分配的普通内存是可分页的，其物理地址的页可能发生改变，会影响到CPU到GPU的数据传输，因此诞生了锁页内存\n\n**锁页内存特点**：\n1. **不可换出**\n\t• 页锁定的内存无法被操作系统移到磁盘上，因此始终保留在物理内存中（物理地址不变）。\n2. **更高的数据传输性能**\n\t• 使用页锁定内存，可以通过**直接内存访问**（DMA）来提高主机与设备之间数据传输的速度。\n3. **显存映射（Memory Mapping）支持**\n\t• 可以将页锁定内存直接映射到GPU设备的内存空间，从而实现**零拷贝访问**（Zero-Copy Access）。\n\t\n锁页内存相对于普通的内存\n- 优点：  \n\t- **异步数据传输**：使用锁页内存后，主机锁页内存与设备内存之间的数据传输，可以使用异步数据传输的函数或者流的方式，和内核函数执行并行。\n\t- 使用锁页内存后，可以将锁页内存映射到设备内存上,无需繁琐的搬运。 \n\t- 如果将锁页内存指定为合并写(write_combining)，则可以进一步提高带宽。\n- 缺陷：牺牲了分页内存的灵活性，消耗内存更快\n\n\n| 特性       | 锁页内存（Pinned Memory）                  | 普通内存（Pageable Memory）     |\n|----------|--------------------------------------|---------------------------|\n| 分配方式     | cudaHostAlloc() 或 cudaMallocHost()   | malloc() 或 new            |\n| 存储位置     | 主机（CPU）端，但固定在物理内存                    | 主机（CPU）端，可被操作系统换出         |\n| 是否可换页    | ❌ 不能换出到磁盘（始终驻留 RAM）                  | ✅ 可能被换出到磁盘（受操作系统管理）       |\n| CPU 访问速度 | ⚡ 快（因为不会换页）                          | ⏳ 可能慢（如果被换出到磁盘，需要换回）      |\n| GPU 访问速度 | ⚡ 快（可使用 DMA 直接访问，提高带宽）               | ⏳ 慢（需要 CPU 复制数据到锁页内存，再传输） |\n| 支持异步拷贝   | ✅ 支持 cudaMemcpyAsync()               | ❌ 不支持（必须同步拷贝）             |\n| 适用于      | 高性能数据传输（如 GPU 直接访问、异步数据传输）           | 一般用途（如小数据量或低速数据传输）        |\n| 缺点       | ❌ 需要更多物理内存（不能换出）❌ 可能影响系统性能（减少可用 RAM） | ❌ 数据传输较慢（特别是 CPU-GPU 之间）  |\n\n\nCUDA 提供了多种方法分配页锁定内存：\n```c\nvoid* hostPtr;\ncudaHostAlloc(&hostPtr, size, cudaHostAllocDefault);\n//• cudaHostAllocDefault：分配基本的页锁定内存。\n//• cudaHostAllocMapped：分配映射内存（GPU 可直接访问）。\n\ncudaFreeHost(hostPtr);\n```\n\n## 合并写内存\n\n如果在分配页锁定内存时，在 `cudaHostAlloc()` 时传入 `cudaHostAllocWriteCombined` flag，则该内存会被指定为 **合并写内存（Write-Combining Memory）**。\n\t- 锁页内存 默认 **启用 L1 & L2 缓存**，以提高 CPU 访问速度。而启用了合并写内存后，读写合并写内存就**不会使用 L1 & L2 缓存**\n```c\nvoid* ptr;\ncudaHostAlloc(&ptr, size, cudaHostAllocWriteCombined);\n```\n\n**合并写内存的优缺点**：\n- 优点：\n\t- **提高 PCI-E 传输性能**：通过 **减少写入操作的开销**，合并写内存 **可提升 40% 的数据传输速度**，适用于大规模 **CPU → GPU 的数据传输**。\n- 缺点：\n\t- **合并写内存可能不支持 CPU 原子操作（atomicXXX）**，不同 CPU 架构行为可能不一致。\n\t- **不适用于 GPU → CPU 传输**。由于不使用 L1 & L2 缓存，当 CPU 读取该内存时，速度 **会非常慢**。\n\n\n## 内存映射\n\nCUDA 中的 **内存映射(Mapped Memory)** 指的是 **将 CPU 端的锁页内存映射到 GPU 端，使 GPU 直接访问该内存**。\n\n### 使用方式\n要让 GPU 访问 CPU 端的锁页内存，需要在分配或注册时添加特定的 flag，将一块内存指定为向GPU映射的内存：\n• 使用 cudaHostAlloc() 分配内存，并传入 cudaHostAllocMapped：\n```c\ncudaHostAlloc(&ptr, size, cudaHostAllocMapped);\n```\n\n• 或者使用 cudaHostRegister() 注册已分配的 CPU 内存：\n```c\ncudaHostRegister(ptr, size, cudaHostAllocMapped);\n```\n\n映射的内存有两个不同的地址：\n1. **CPU 端地址**：\n• 通过 malloc() 或 cudaHostAlloc() 获取。\n\n2. **GPU 端地址**：\n• 需要使用 cudaHostGetDevicePointer() 获取：\n```c\nvoid* devPtr;\n\ncudaHostGetDevicePointer(&devPtr, ptr, 0);\n```\n\n### **内存映射的优点**\n\n1. **数据传输透明**：\n\t• CPU/GPU 之间的数据传输是 **自动** 进行的，不需要手动 cudaMemcpy() 复制数据。\n\t\n2. **隐藏 PCI-E 传输延迟**：\n\t• 内存映射可以隐藏 PCI-E 传输的高延迟。但是当 GPU 访问映射的 CPU 的内存数据不在 GPU 端，会触发 **PCI-E 传输请求**（速度比全局内存还慢）。\n\t\t• 提出该请求的线程会被 **换出**，直到数据到达后再继续执行。\n\t\t• **解决方案**：使用 **足够多的线程** 以隐藏 PCI-E 传输的高延迟。\n\n3. **支持数据传输和内核并行**：\n\t• 内存映射 **可以替代 CUDA 流**（Stream），实现 **数据传输与内核执行的并行**\n\n### **使用内存映射的注意事项**\n\n1.  **数据同步问题**：\n\t• 由于 CPU 和 GPU **共享同一块内存**，需要 **手动管理数据同步**，防止数据竞争。\n\n2.  **必须在 CUDA 运行前启用cudaSetDeviceFlags**：\n\t• 在执行其他 CUDA 函数前，需要启用cudaDeviceMapHost。如果未启用 ，cudaHostGetDevicePointer() **会返回错误**：\n```c\ncudaSetDeviceFlags(cudaDeviceMapHost);\n```\n\n3. **设备必须支持内存映射**：\n\t• 可以通过 cudaDeviceProp.canMapHostMemory 检查设备是否支持：\n```c\ncudaDeviceProp prop;\ncudaGetDeviceProperties(&prop, 0);\nprintf(\"Can map host memory: %d\\n\", prop.canMapHostMemory);\n```\n\n4.  **CPU 和 GPU 的原子操作不互通**：\n\t• **CPU 端和 GPU 端同时修改映射内存时，原子操作（atomicXXX）不保证原子性**，可能导致数据不一致。","tags":["cuda"],"categories":["note","cuda"]},{"title":"CUDA笔记——共享内存和bank conflict","url":"/2024/11/09/note/cuda/CUDA笔记——共享内存和bank conflict/","content":"\n共享内存比全局内存快得多，因此可以使用共享内存优化算法访存，从而提供性能\n- 然而并不是使用共享内存越多性能越快，过多的使用共享内存会导致SM上常驻block减少，降低占有率occupancy，降低性能\n\n>**最佳实践**：当线程需要多次读写全局内存时，或者同一block的线程需要数据同步和通信的情况，可以使用共享内存进行优化\n\n## 使用方式\n#### 静态分配\n- 静态分配的共享内存大小必须在**编译时**确定\n```c\n__shared__ 数据类型 变量名[大小];\n```\n#### 动态分配\n在 kernel 内部，使用 **extern** 关键字声明动态共享内存数组，其大小在运行时确定\n```c\nextern __shared__ float shared[];\n```\n- 调用 kernel 时，第三个参数用于指定动态共享内存的大小\n```c\nint block_size = 256;\nint shared_mem_size = block_size * sizeof(float); // 为每个 block 分配 block_size 个 float\nmyKernel<<<numBlocks, block_size, shared_mem_size>>>(...);\n```\n\n在模板kernel中使用动态共享内存时，不能直接使用 `extern __shared__ T sharedMem[];`\n- **必须** 先声明 `extern __shared__ unsigned char sharedMem[]`;\n- **然后** 在 kernel 内部用` reinterpret_cast<T*>(sharedMem)` 转换类型\n```c\ntemplate <typename T>\n__global__ void myKernel(T* d_out, T* d_in, int N) {\n    extern __shared__ unsigned char sharedMem[];  // 共享内存声明为字节数组\n\n    T* smem = reinterpret_cast<T*>(sharedMem);   // 强制转换为 T 类型指针\n\n    int tid = threadIdx.x;\n    if (tid < N) {\n        sharedMem[tid] = d_in[tid];\n        __syncthreads();\n        d_out[tid] = sharedMem[tid];\n    }\n}\n```\n## bank conflict\n\n### bank\n\n**共享内存的存储方式**: **shared memory** 是由32个 **memory bank** 组成的\n- bank的优点：可以同时处理跨 _b_ 个不同内存 bank 的任何内存负载或 _n_ 个地址的存储，从而产生比单个 bank 带宽高 _b_ 倍的有效带宽\n- **Bank结构**： \n\t- 每个 bank 的默认大小（访问粒度）是 **4 字节（即 32-bit，一个 int 或 float 的大小）**。\n\t- 每个bank都有多个内存地址，可以将每个bank看作是一列数据\n\t- **每一次每个bank只能访问一个内存地址**，多线程不能**同时访问同一个bank内的不同个内存地址**。\n\n- **Shared Memory到Bank的映射方式**: SM的是以wrap 32个线程为单位调度的，因此shared_memory 会**连续映射**到大小（默认是**4字节对齐**）相等的32个Bank上，\n\t- 对shared_memory 访问addr的逻辑地址，实际映射到BankIndex为\n>\t*BankIndex=(addr / BankSize) % 32*\n\n例如，声明共享内存\n```text\n二维 __shared__float sData[32][32]，那么 \n\tsData[0][0]、sData[1][0]...sData[31][0] 位于 Bank[0]，\n\t.....\n\tsData[31][0]、sData[31][1]...sData[31][31] 位于 Bank[31]\n\n一维 __shared__float sData[64]， 那么\n\tsData[0]、sData[32] 位于 Bank[0], \n\t....\n\tsData[31]、sData[63] 位于 Bank[31]\n```\n\n![简述CUDA线程及求CUDA中线程索引 - 知乎](https://pic1.zhimg.com/v2-7cb74504a5c7b81130bc6ad4d562220c_r.jpg)\n\n\n### **bank conflict**\n\n**bank conflict**：如果在**同一个wrap**中，**如果多个线程同时访问同一 bank 的不同地址（不同数据）**，即取同一列共享内存的不同数据，则访问将被序列化，**退化成顺序读写**\n\n> **broadcast**：如果多个线程请求的是**同一bank的相同地址**（即相同数据），就会触发广播操作，而不会产生bank conflict\n\n如下图中间warp中存在bank conflict，两个线程的冲突称为为2路冲突\n![如何实现一个高效的Softmax CUDA kernel？_OneFlow一流科技有限公司](https://oneflow-public.oss-cn-beijing.aliyuncs.com/images/OneTeam/2-way_bank_conflict.png)\n\nbank conflict示例代码：\n- 一维：\n```c\n\n__shared__ float sharedMem[64];\n\n//无冲突\nint tid = threadIdx.x; // 0 ~ 31\nfloat data = sharedMem[tid]; // 每个线程访问不同的 bank\n\n//无冲突\ndata = sharedMem[0]; // 所有线程访问 sharedMem[0]\n\n//2路冲突，所有线程访问间隔 2 的地址\ndata = sharedMem[tid * 2]; // 访问 0, 2, 4, ..., 62\n\n```\n\n- 二维\n```c\n// 1. st不冲突, ld冲突\n__global__ void half_conflict_transfer(float *in, float *out) {\n  __shared__ float tile[32][32];\n  unsigned int idx = threadIdx.y * blockDim.x + threadIdx.x;\n  tile[threadIdx.y][threadIdx.x] = in[idx];   //线程按行写入，不同的 threadIdx.x 访问不同的 Bank\n  __syncthreads();\n  out[idx] = tile[threadIdx.x][threadIdx.y];  //线程按列读取数据，例如第一个warp读取tile[0][0], tile[1][0], tile[2][0]...,发生冲突\n}\n// 2. ld/st 全冲突\n__global__ void conflict_column_transfer(float *in, float *out) {\n  __shared__ float tile[32][32];\n  unsigned int idx = threadIdx.y * blockDim.x + threadIdx.x;\n  tile[threadIdx.x][threadIdx.y] = in[idx];\n  __syncthreads();\n  out[idx] = tile[threadIdx.x][threadIdx.y];\n}\n//3. 无冲突访存\n__global__ void simple_transfer(float *in, float *out) {\n  __shared__ float tile[32][32+1];\n  unsigned int idx = threadIdx.y * blockDim.x + threadIdx.x;\n  tile[threadIdx.y][threadIdx.x] = in[idx];\n  __syncthreads();\n  out[idx] = tile[threadIdx.y][threadIdx.x];\n}\n\n```\n\n### 分析bank conflict的方法\n#### 手动模拟检查\n可以通过画图，模拟32个线程的访问情况，看看是否有访问同一个bank的时候\n- 线程访问 float类型的共享内存数据A\\[i\\]\\[j\\]的bank序号的公式如下：\n\t  - $\\text{Bank}(A[i][j]) = (i \\times 32 + j) \\mod 32$\n- 可以带入不同线程的 i、j序号来判断是否有冲突\n\n>**最佳实践** ：在分析bank conflict时，通常只考虑**threadIdx.x**的影响。 因为同一个 Warp 内，threadIdx.x 唯一不同，threadIdx.y 和 threadIdx.z 固定，所以在 Warp 级优化时，通常只考虑**threadIdx.x**\n\n#### NVIDIA Nsight Compute\n使用Nsight Compute分析程序，进入 **“Memory Workload Analysis” → “Shared Memory”**。\n• 找到 **“Shared Memory Bank Conflicts”** 指标：\n\t• **Shared Memory Bank Conflicts** (数量越大越差)。\n\t• **Shared Memory Efficiency** (接近 100% 最佳)。\n![](CUDA笔记——共享内存和bank%20conflict/img-共享内存-2.png)\n\n### 解决bank conflict的方法\n解决bank conflict的主要有padding和swizzling ：\n#### padding\n通过新增一列，相同列的不同行的元素的bank值不再一样\n![](CUDA笔记——共享内存和bank%20conflict/img-共享内存-3.png)\n\n```c\n//一维\n__shared__ float sharedMem[64 + 1]; \n\n//二维\n__shared__ int s_data[32][33];\n```\n\n**padding的缺点有**：\n- **增加共享内存占用**，降低occupancy，导致 **无法同时运行足够多的线程块**，\n- 破坏了原本的连续内存布局，访问数据时 **必须手动计算偏移量**\n- **地址访问对齐问题**。需要仔细考虑padding的大小来避免地址不对齐的问题\n\t- 比如访问shared memory时可能是向量化的访问，比如int4访问，也就是每次访问4个int，即16字节，那每次访问的地址必须是16字节对齐的，对于int s_data\\[32\\]\\[33\\]这种padding方式，**第二行元素的起始地址就是非16字节对齐**，会导致kernel执行出错。\n#### swizzling\nswizzling是在不额外分配内存的情况下，通过将shared memory的**数据进行重排**来避免bank conflict。将本来在相同 Bank 的内存映射到不同的物理地址，但对于用户来说逻辑地址依然为原来的地址。\n- 在 Swizzle 中采用**行列坐标进行异或**的方式进行物理内存重映射。之所以采用异或的原因在于异或操作满足**封闭性与双射性**\n- 重排后，每一**行内**的**数据集合**保持不变，但行内元素的相对位置进行重排，比如对于y=1行  ，原来的索引顺序是[0, 1, 2, 3, ......, 30, 31]，而新的索引顺序是[1, 0, 3, 2, 5, 4, ......, 31, 30]。\n![](CUDA笔记——共享内存和bank%20conflict/img-共享内存-5.png)\n\n```c\n//s_mem[threadIdx.y][threadIdx.x] = input[y1 * N + x1];\ns_mem[threadIdx.y][threadIdx.x ^ threadIdx.y] = input[y1 * N + x1];  //其映射的物理存储位置位置(row不变,col=x^y)\n\n\n//output[y2 * M + x2] = s_mem[threadIdx.x][threadIdx.y]; \noutput[y2 * M + x2] = s_mem[threadIdx.x][threadIdx.x ^ threadIdx.y];  // swizzling后，此处不存在bank conflict\n```\n\n## 实例：共享内存优化一维卷积\n\n卷积是一种数组操作，每个输出元素都是**周围输入元素的加权总和**。权重是由一个输入掩码数组也叫卷积核（convolution kernel）确定的。下面卷积计算都默认padding。\n一维卷积图例：N是输入数组，M是卷积核，P是输出数组\n![](CUDA笔记——共享内存和bank%20conflict/img-CUDA笔记——共享内存-8.png)\n超出范围的元素当0计算\n![](CUDA笔记——共享内存和bank%20conflict/img-CUDA笔记——共享内存-2.png)\n### 朴素实现\n- N 为输入数组。 \n- M 为卷积核。 \n- P 为输出数组。 \n- Mask_Width 为卷积核尺寸,默认是奇数。 \n- Width 为输入输出数组长度。\n```c\n__global__ void convolution_1D_basic_kernel(float *N, float *M, float *P, int Mask_Width, int Width);  \n{\n\tint radius=Mask_Width/2;\n\tint id=blockDim.x*blockIdx.x+threadIdx.x;\n\tint start_pos=id-radius;\n\tint sum=0;\n\tfor(int i=0;i<Mask_Width;i++){     //卷积核当前下标\n\t\tint cur_pos=start_pos+i;       //输入数组当前下标\n\t\tif(cur_pos>=0 && cur_pos<Width){\n\t\t\tsum+=N[cur_pos]*M[i];\n\t\t}\n\t}\n\tP[id]=sum;\n}\n```\n\n### 共享内存优化\n\n卷积核M数组尺寸小、内容不变、所有线程都以相同顺序访问，天然适合常量数组\n输入数组每个元素平均重复访问的次数为卷积核大小Mask_Width，适合使用共享数组\n\t- 使用共享数组就要以block为单位思考，发现不论block多大，都需要多用到Mask_Width-1的边缘数据\n\t- **难点**：**如何加载边缘数据**？可以使用线程交叉加载的方式，后radius的线程加载前radius个元素（假设radius<blockDim)，其实就是将block左平移一个块，对应的线程就加载对应的边缘数据， 另一半也是一样的方法\n\n![](CUDA笔记——共享内存和bank%20conflict/img-CUDA笔记——共享内存-2%201.png)\n```c\n__constant__  float M[MAX_MASK_WIDTH]\ncudaMemcpyToSymbol(M,h_M,Mask_Width*sizeof(float));\n\n__global__ void convolution_1D_basic_kernel(float *N, float *P, int Mask_Width, int Width);  \n{\n\tint radius=Mask_Width/2;\n\t__shared__ float Ns[blockDim.x+2*radius];\n\n\tint id=blockDim.x*blockIdx.x+threadIdx.x;\n\n\tint left=(blockDim.x-1)*blockIdx.x+threadIdx.x;   //平移到左边对应在N的id,如果该块是一个块则left小于0\t\n\tif(threadId.x>=blockDim.x-radius).     //思考为什么左边缘数据对应Ns的下标是threadId.x-（blockDim.x-radius）\n\t\tNs[threadIdx.x-blockDim.x+radius]=(left<0) 0 ? N[left];   //左边载入Ns\n\tNs[radius+threadIdx.x]=N[id];       //载入中间元素\n\n\tint right=(blockDim.x+1)*blockIdx.x+threadIdx.x;   //平移到左边对应在N的id,如果该块是最后块则right大于等于Width\t\n\tif(threadId.x<radius).     //思考为什么是小于radius\n\t\tNs[threadIdx.x+blockDim.x+radius]=(right>=Width) 0 ? N[right];   //载入右边Ns\t\n\t__syncthreads();\n\n\n\tint sum=0;\n\tfor(int i=0;i<Mask_Width;i++){     //卷积核当前下标\n\t\tsum+=Ns[threadIdx.x+i]*M[i];\n\t}\n\tP[id]=sum;\n}\n```\n\n**访存次数对比：**\n- 所以对于内部线程块，基本算法与分快算法的访存次数比值为：  \n    ( blockDim.x*(2n+1) )/(blockDim.x+2n) \n- 对于边缘线程块，比值为：  \n    ( (blockDim.x*(2n+1) - n(n+1)/2 )/(blockDim.x+n) \n如果blockDim.x 的值比n大的多，那么就近似为：2n+1=Mask_Width","tags":["cuda"],"categories":["note","cuda"]},{"title":"c++学习笔记——多态与虚函数","url":"/2024/09/10/note/c++学习笔记/多态与虚函数/","content":"## 多态与虚函数\n**多态**：实体具有多种形态的能力，在c++中具体表现就是函数具有多种形态。\n多态的实现方式主要有两种：**编译时多态**（静态多态）和**运行时多态**（动态多态）：\n\t**编译时多态性**：指由编译器解析的多态性形式。其中包括**函数重载解析以及模板解析**。\n\t**运行时多态性**：是指在运行时解析的多态性形式。这包括**虚拟函数解**析。\n\n**虚函数**：在基类中使用关键字virtual指明函数为虚函数，然后在派生类中重写虚函数。当通过**指针或引用**调用虚函数时，会基于指针（或引用）**指向的对象的类型**来动态选择（**即动态绑定**）。\n例如`A& rBase{ c };`，运行时编译器会调用 A 和 C 之间派生最多的匹配函数\n\t- 仅当通过**指针或引用**调用虚拟成员函数时，虚函数解析才有效。\n\t- 虚函数是为了解决编译时期指针或引用**不能确定它所指向的对象的具体类型**，需要在运行时期在对象构造后确定对象的**实际类型**后，根据其来选择对应的函数版本\n\n#### **虚函数与非虚函数的区别：**\n主要的区别在于**绑定方式**：\n- 非虚函数的解析是编译时就确定的，基于指针（或引用）的类型来静态选择（静态绑定）\n- 虚函数的解析是在运行时确定的，基于指针（或引用）指向的对象的类型来动态选择（动态绑定）\n#### 虚函数缺点:\n1. **时间开销**：解析虚拟函数调用比解析常规函数调用花费的时间更长，虚函数的调用需要两个额外的步骤\n2. **空间开销**：编译器还必须为具有虚函数的类的每个对象分配一个额外的虚指针，对象的大小就会增加一个指针的大小（指针类型32位系统中占用4字节，在64位系统中占用8字节），每个类还要生成一个虚函数表\n#### Note：\n- 不管虚函数是否用到，**派生类都要给每个虚函数定义**\n    -这是因为动态绑定，要在运行时才能指定调用哪个版本的虚函数\n\t-**基类中的虚函数在派生类中隐含地也是一个虚函数**，即使派生类的对应函数没有显式标记为 virtual。\n- **派生类中虚函数的形参和返回类型也必须与基类函数匹配**。否则派生类的虚函数将不会override基类的虚函数，因为编译器将这两个函数视为不同的函数\n\t- 除非基类B的虚函数返回类型是类本身的引用B&或指针B* ，则派生类D可以返回自己的类型即D&或D*\n    - 但也要要求D到B的类型转换是可访问的。\n    - 例如下面B的两个函数都不被视为重写\n```cpp\nclass A\n{\npublic:\n\tvirtual std::string_view getName1(int x) { return \"A\"; }\n\tvirtual std::string_view getName2(int x) { return \"A\"; }\n};\n\nclass B : public A\n{\npublic:\n\tvirtual std::string_view getName1(short x) { return \"B\"; } // note: parameter is a short\n\tvirtual std::string_view getName2(int x) const { return \"B\"; } // note: function is const\n};\n```\n- 派生类重写的虚函数尽量使用**override**，放置在虚函数签名之后（类似于函数const的用法）\n\t- override可以解决上一个隐患：如果函数没有重写基类函数（或应用于非虚函数），编译器会将该函数标记为错误\n\t- 由于 override 说明符隐含 virtual，因此被重写的虚函数前面无需再加上 virtual\n\t- 例如\n\t```cpp\nclass A\n{\npublic:\n\tvirtual std::string_view getName1(int x) { return \"A\"; }\n\tvirtual std::string_view getName2(int x) { return \"A\"; }\n\tvirtual std::string_view getName3(int x) { return \"A\"; }\n};\n\nclass B : public A\n{\npublic:\n\tstd::string_view getName1(short int x) override { return \"B\"; } // compile error, function is not an override\n\tstd::string_view getName2(int x) const override { return \"B\"; } // compile error, function is not an override\n\tstd::string_view getName3(int x) override { return \"B\"; } // okay, function is an override of A::getName3(int)\n\n};\n```\n- 不要**从构造函数或析构函数中调用虚函数** \n\t- 例如，在创建 Derived 类时，首先构造 Base 部分。如果要从 Base 构造函数调用虚拟函数，并且尚未创建类的 Derived 部分，则它将无法调用函数的 Derived 版本。在 C++ 中，它将改为调用 Base 基类版本。\n- 虚函数可以声明为`inline`，但实际内联的可能性有限。因为在编译时无法知道确切的虚函数实现，因此很难将虚函数内联。对于需要多态性的场景，通常不建议将虚函数声明为`inline`。\n- 静态函数不能定义为虚函数。因为静态函数不与任何类对象关联，所以它们不具备`this`指针和虚函数表指针。\n我们什么时候使用函数重载与函数重写（虚函数）？\n\t1. 当我们需要成员或非成员函数在传递不同类型的参数时表现不同时，就会使用函数重载。\n\t2. 当我们需要基类和派生类之间需要共享相同的方法名，但实现可能不同的情况，即成员函数在隐式对象是派生类时表现不同时，使用函数重写。\n\n## 纯虚函数\n- **纯虚函数**（pure virtual）：清晰地告诉用户当前的函数是没有实际意义的。**纯虚函数无需定义**，没有函数体，只用在函数体声明后`=0`就可以将一个虚函数说明为纯虚函数。\n```c\n     virtual fun(int x) const =0 ;    //也可以给继承的虚函数加上=0，重声明其是纯虚函数\n```\n- 含有纯虚函数的类是**抽象基类**（abstract base class）。抽象类不能实例化（不能创建抽象基类的对象）\n\t- 其派生类都必须为纯虚函数定义一个主体，否则该派生类也将被视为抽象基类。\n- 纯虚函数也可以提供定义，但必须在类外部单独定义\n- 在虚函数表中，纯虚函数指针的值取决于编译器，一般是0或者指向一个特殊的函数，使得调用纯虚函数时触发运行时错误。\n- **纯虚函数使用场景**：\n\t- 主要用于定义接口，强制派生类实现这些函数。在实际开发中，可以先定义一个抽象类，只完成部分功能，未完成的功能交给派生类来完成，这部分功能往往是基类是不需要的，虽然抽象基类没能完成，可是却要求派生类来完成。\n\t- 例如下面的**接口类**，任何从 IErrorLog 继承的类都必须为所有三个函数提供实现才能进行实例化。\n```c\nclass IErrorLog\n{\npublic:\n    virtual bool openLog(std::string_view filename) = 0;\n    virtual bool closeLog() = 0;\n\n    virtual bool writeError(std::string_view errorMessage) = 0;\n\n    virtual ~IErrorLog() {} // make a virtual destructor in case we delete an IErrorLog pointer, so the proper derived destructor is called\n};\n```\n\n* 只有类中的虚函数才能被定义为纯虚函数，普通成员函数和顶层函数均不能被声明为纯虚函数。\n\n## 虚函数与普通函数的思想区别：绑定\n#### 早期（静态）绑定\n程序编译时，机器语言的每一行都有自己唯一的顺序地址，因此每个函数最终都有一个唯一的地址。\n**绑定**（binding）是将名称与此类属性相关联的过程。\n\t**函数绑定**是确定与函数调用关联的函数定义的过程。\n\t实际调用绑定函数的过程称为 **dispatching**。\n\t\n**早期绑定**：在编译时期的函数绑定。\n\t- 在 C++ 中，当直接调用非成员函数或非虚拟成员函数时，**编译器可以确定哪个函数定义应与调用匹配**，**函数就可以在编译时执行**。\n\t- 然后，编译器可以生成机器语言指令，告诉 CPU 直接跳转到该函数的地址。\n\n#### 后期（动态）绑定\n**后期绑定**: 指针或引用调用的虚拟函数调用在运行之前无法解析，即编译器不能仅根据静态类型信息来确定被调用的函数，而必须使用动态类型信息进行解析。\n- 获得后期绑定的一种方法是使用**函数指针**。\n\t- 简单回顾一下函数指针，函数指针是一种指向函数而不是变量的指针。通过函数指针调用函数也称为间接函数调用。\n- 函数指针调用如下：\n\t- 在实际调用 `fcn（5）` 时，编译器在编译时不知道正在调用的是什么函数，因为编译器只知道指针fcn的地址，并不知道其调用函数的地址。\n\t- 相反，在运行时，**将对函数指针fcn持有的地址**中存在的任何函数进行间接函数调用。\n```c\n\nvoid printValue(int value)\n{\n    std::cout << value << '\\n';\n}\n\nint main()\n{\n    auto fcn { printValue }; // create a function pointer and make it point to function printValue\n    fcn(5);                  // invoke printValue indirectly through the function pointer\n\n    return 0;\n}\n```\n- 缺点：后期绑定的效率略低，因为它涉及额外的间接级别。\n\t- 通过早期绑定，CPU 可以直接跳转到函数的地址。\n\t- 对于后期绑定，程序必须读取指针中保存的地址，然后跳转到该地址。\n\n## 虚函数实现的底层原理\n**虚表**是函数的查找表，是一个函数指针数组，用于以动态/后期绑定方式解析函数调用。虚函数解析有时称为**动态调度**。\n\t- 每个使用虚函数的类（包括使用虚函数的派生类）都有自己相应的独立虚表。\n\t\t- 抽象类也有虚表，抽象类的构造函数或析构函数可以调用虚函数\n\t- 虚表包含类中所有可调用**虚函数地址入口**。\n\t- 虚表在编译时期构造，存储在**只读数据段.rdata**\n\t- 虚函数表的布局顺序与类定义中虚函数的声明顺序相同，除了新增的虚函数会排在继承自基类的虚函数之后\n\t\t- 编译器根据虚函数在类中的位置，从虚函数表中查找相应位置的函数地址。\n\t\t- 重写的虚函数在虚函数表的对应位置就是重写后的地址，不重写的虚函数其地址是基类地址\n**虚指针__vptr**：指向该类的虚拟表的隐藏指针成员\n\t\t\t- 实例：\n\t\t\t在创建 Base 类型的对象时，`*__vptr` 设置为指向 Base 的虚拟表。构造 D1 或 D2 类型的对象时，`*__vptr` 将分别设置为指向 D1 或 D2 的虚拟表。\n```c\nclass Base\n{\npublic:\n    VirtualTable* __vptr;\n    virtual void function1() {};\n    virtual void function2() {};\n};\n\nclass D1: public Base\n{\npublic:\n    void function1() override {};\n};\n\nclass D2: public Base\n{\npublic:\n    void function2() override {};\n};\nint main()\n{\n    D1 d1 {};\n    Base* dPtr = &d1;\n    dPtr->function1();      \n    //必须执行 3 次操作才能找到要调用的函数：首先，程序识别出 function1（） 是一个虚函数。其次，该程序使用 `dPtr->__vptr` 来访问 D1 的虚拟表。最后，它查找要在 D1 的虚拟表中调用哪个版本的 function1（）。这已经被设置为 D1：：function1（） 了。因此，`dPtr->function1（）` 解析为 D1：：function1（）！\n\n    return 0;\n}\n```\n各个类的虚表如下：\n![|500](多态与虚函数/img-多态与虚函数-0%201.png)\n## 附录\n#### final\n- 在我们想要限制用户覆盖函数的情况下，可以使用final说明符，表示重写行为到此类为止\n- 重写带有final的函数，编译器将给出编译错误\n```c\n#include <string_view>\n\nclass A\n{\npublic:\n\tvirtual std::string_view getName() const { return \"A\"; }\n};\n\nclass B : public A\n{\npublic:\n\t// note use of final specifier on following line -- that makes this function not able to be overridden in derived classes\n\tstd::string_view getName() const override final { return \"B\"; } // okay, overrides A::getName()\n};\n\nclass C : public B\n{\npublic:\n\tstd::string_view getName() const override { return \"C\"; } // compile error: overrides B::getName(), which is final\n};\n```\n- 在我们想要阻止从类继承的情况下，final 说明符应用在类名之后,例如 class B **final** : public A\n```c\n#include <string_view>\n\nclass A\n{\npublic:\n\tvirtual std::string_view getName() const { return \"A\"; }\n};\n\nclass B final : public A // note use of final specifier here\n{\npublic:\n\tstd::string_view getName() const override { return \"B\"; }\n};\n\nclass C : public B // compile error: cannot inherit from final class\n{\npublic:\n\tstd::string_view getName() const override { return \"C\"; }\n};\n```\n#### 虚拟析构函数\n- 基类和派生类类最好都**将析构函数设置为虚函数和public**\n\t- 原因：析构函数声明为虚函数可以确保在通过**基类指针删除派生类对象**时，可以正确地调用派生类的析构函数。这样可以避免内存泄漏和资源泄漏。\n\t\t- 如果不是虚函数，使用基类引用或指针指向派生类对象，当删除指针或引用时，就会**只调用基类的析构函数**，而不会调用派生类的析构函数，应该被删除的派生类的成员就不会被删除,程序将面临内存泄漏的风险。\n\t\t- 当派生类对象被销毁时，基类的析构函数会自动被调用\n\t- 构造函数不能是虚函数\n\t\t- 原因：虚函数依赖于完整的对象和已建立的虚函数表，因此在构造一个对象时，由于对象还未创建成功，也没有建立好虚表，是没法调用虚函数的\n\t- 例如：下面derived的成员m_array就不会被删除\n```c\nclass Base\n{\npublic:\n\t//正确做法： virtual ~Base() \n    ~Base() // note: not virtual\n    {\n    }\n};\n\nclass Derived: public Base\n{\nprivate:\n    int* m_array {};\n    //正确做法： virtual ~Derived()  \n    ~Derived() // note: not virtual (your compiler may warn you about this)\n    {\n        delete[] m_array;\n    }\n};\n\nint main()\n{\n    Derived* derived { new Derived(5) };\n    Base* base { derived };\n\n    delete base;\n\n    return 0;\n}\n```\n#### 忽略虚函数\n- 极少数情况下，您可能希望忽略函数的虚拟化，那么使用scope resolution 运算符::指定应该调用的函数\n```c\nint main()\n{\n    Derived derived {};\n    const Base& base { derived };\n\n    // Calls Base::getName() instead of the virtualized Derived::getName()\n    std::cout << base.Base::getName() << '\\n';\n\n    return 0;\n}\n```\n#### 虚基类\n当一个类继承多个具有相同祖宗类的类时，需要用到虚基类避免多次构造祖宗类\n实例：\n- 对于最派生类的构造函数，**虚基类始终在非虚拟基类之前创建**\n- 如果一个类继承了一个或多个具有虚拟父类的类，**则最底层的派生类负责构造虚拟基类**。在本例中，Copier 继承了 Printer 和 Scanner，两者都有一个 PoweredDevice 虚拟基类。 Copier 是最底层的派生类，负责创建 PoweredDevice。\n- 继承虚基类的所有类都将有一个虚拟表，并且该类的所有派生类也会拥有一个虚拟表，用于访问子对象的成员\n\t```c\n\tclass PoweredDevice\n\t{\n\t};\n\t\n\tclass Scanner: virtual public PoweredDevice.    //PoweredDevice成了虚基类\n\t{\n\t};\n\t\n\tclass Printer: virtual public PoweredDevice。   //PoweredDevice成了虚基类\n\t{\n\t};\n\t\n\tclass Copier: public Scanner, public Printer.   //copier继承两个虚基类，但只构造一次PoweredDevice\n\t{\n\t};\n\t```\n#### 名称隐藏\n如果子类定义了一个与父类虚函数同名的新函数（即使参数不同），在子类作用域中会导致同名函数的隐藏。此时，父类中所有同名的重载函数都被隐藏，不再可见。\n\t例如父类有n个重载的print函数，子类有一个自己的print函数，那么子类只能调用自己的那个print函数, 就算是调用父类的虚print函数也没用\n\n可以通过使用**using 解决名称隐藏问题**：\n```c\nclass Derived : public Base {\npublic:\n    using Base::func;  // 引入 Base 的所有 func 重载版本\n    \n    void print(int x) override {\n        std::cout << \"Derived::func(int) called with \" << x << std::endl;\n    }\n    \n    void print(char x) {  // 新增的函数\n        std::cout << \"Derived::func(char) called with \" << x << std::endl;\n    }\n};\n```\n#### 友元函数的重写\n- 友元函数不是类的成员函数，不能被继承，因此是无法被重写override的，但可以重载overload\n\t- 那么如何让继承类使用基类的友元函数？答案是在友元函数中调用一个虚普通成员函数\n\t- 实例：\n```c\nclass Base\n{\npublic:\n\t// Here's our overloaded operator<<\n\tfriend std::ostream& operator<<(std::ostream& out, const Base& b)\n\t{\n\t\t// Call virtual function identify() to get the string to be printed\n\t\tout << b.identify();\n\t\treturn out;\n\t}\n\n\t// We'll rely on member function identify() to return the string to be printed\n\t// Because identify() is a normal member function, it can be virtualized\n\tvirtual std::string identify() const\n\t{\n\t\treturn \"Base\";\n\t}\n};\n\nclass Derived : public Base\n{\npublic:\n\t// Here's our override identify() function to handle the Derived case\n\tstd::string identify() const override\n\t{\n\t\treturn \"Derived\";\n\t}\n};\n\nint main()\n{\n\tBase b{};\n\tstd::cout << b << '\\n';\n\n\tDerived d{};\n\tstd::cout << d << '\\n'; // 继承类成员也能正确调用，因为在调用Base的<<时Derived发生了隐式的向上转换，Derived&转换为了Base&，然后调用identify（）时发生了虚函数解析，解析为了Derived的版本\n\tBase& bref{ d };\n\tstd::cout << bref << '\\n';\n\n\treturn 0;\n}\n```\n#### 实例\n1. 下面的基类指针rBase是指向派生类Derived的引用，那么rBase.getName()将调用哪个类的函数？\n```c\nclass Base\n{\npublic:\n    std::string_view getName() const { return \"Base\"; }\n};\n\nclass Derived: public Base\n{\npublic:\n    std::string_view getName() const { return \"Derived\"; }\n};\n\nint main()\n{\n    Derived derived {};\n    Base& rBase{ derived };\n    std::cout << \"rBase is a \" << rBase.getName() << '\\n';\n\n    return 0;\n}\n```\n\n2.  那么下面重写虚函数后，rBase.getName()将调用哪个类的函数？\n```c\nclass Base\n{\npublic:\n    virtual std::string_view getName() const { return \"Base\"; } // note addition of virtual keyword\n    virtual ~Base() = default;          //基类的析构函数最好也要变为虚函数\n};\n\nclass Derived: public Base\n{\npublic:\n    virtual std::string_view getName() const { return \"Derived\"; }\n};\n\nint main()\n{\n    Derived derived {};\n    Base& rBase{ derived };\n    std::cout << \"rBase is a \" << rBase.getName() << '\\n';\n\n    return 0;\n}\n\n```\n当 _rBase.getName（）_ 被计算时，它通常会解析为 Base：：getName（）。但是，Base：：getName（） 是虚函数的，它告诉程序去查看是否有可用于 Derived 对象的函数的更多派生版本。在这种情况下，它将解析为 Derived：：getName（）！\n\n3. 下面将打印什么？\n```c\n#include <iostream>\n#include <string_view>\n\nclass A\n{\npublic:\n    virtual std::string_view getName() const { return \"A\"; }\n};\n\nclass B: public A\n{\npublic:\n    // note: no virtual keyword in B, C, and D\n    std::string_view getName() const { return \"B\"; }\n};\n\nclass C: public B\n{\npublic:\n    std::string_view getName() const { return \"C\"; }\n};\n\nclass D: public C\n{\npublic:\n    std::string_view getName() const { return \"D\"; }\n};\n\nint main()\n{\n    C c {};\n    B& rBase{ c }; // note: rBase is a B this time\n    std::cout << rBase.getName() << '\\n';\n\n    return 0;\n}\n```\nC. 即使 B 和 C 未标记为虚函数，A::getName（） 是虚函数，那么B：：getName（） 和 C：：getName（） 是隐式的虚函数。","tags":["c++"],"categories":["note","c++学习笔记"]},{"title":"c++学习笔记——类","url":"/2024/09/07/note/c++学习笔记/类/","content":"面向对象程序设计（object-oriented programming）的核心思想是数据抽象、继承和多态。\n- 抽象： 将类与接口的实现进行分离\n- 继承： 允许从现有类派生出新类的方法，新类可以继承现有类的属性和方法，还可以添加新的属性和方法或者覆盖现有的方法。\n- 多态： 实体具体多种形态，分为**编译时多态**（静态多态）和**运行时多态**（动态多态），详情见虚函数\n其他概念：\n- 接口：\n- 封装：将数据和操作数据的函数组合在一起，这样可以隐藏对象的内部细节。\n- 数据隐藏\n- 泛型编程：是通过模板（template）机制允许用户编写与类型无关的通用代码\n- RAII（Resource Acquisition Is Initialization）是C++中的一种编程技巧，它的核心思想是：资源的管理（如内存、文件句柄、锁等）应该与对象的生命周期绑定，即**对象在创建时获得资源，在销毁时释放资源**。\n面向对象与面向过程的区别：\n\n\n## 类\n物体有两个主要组成部分：1） 一些可观察的属性（例如重量、颜色、大小、固体、形状等），以及 2） 它们可以执行或已经执行的一些基于这些属性的行为（例如被打开、损坏其他东西等）。\n\n在编程中，我们用变量表示属性，用函数表示行为。对应于类中就是使用成员变量和成员函数\n在类中可以按任何顺序定义成员变量和成员函数！\n在成员函数情况下，我们不需要将 类作为参数传递。调用成员函数的对象将隐式传递给成员函数。因此，调用成员函数的对象通常称为**隐式对象**。\n\n如果类类型没有任何数据成员，考虑改用命名空间\n```c\nnamespace Foo\n{\n    void printHi() { std::cout << \"Hi!\\n\"; }\n};\n\nint main()\n{\n    Foo::printHi(); // no object needed\n\n    return 0;\n}\n```\n\n**权限访问表**：\n注意同一个类的对象之间可以互相访问其私有成员，因为私有成员的访问权限是基于类的\n![[类-1.png|900]]\n- **public（公有）**： `public`访问修饰符允许类成员在类的外部被访问。这意味着，如果一个成员被声明为`public`，那么它可以在类的任何地方被访问，包括类的实例、派生类以及非成员函数。通常，类的公有成员用于定义类的公共接口，允许外部代码与类进行交互。\n    \n- **private（私有）**： `private`私有成员仅在类的内部被访问，或同友元的成员函数访问。这意味着，如果一个成员被声明为`private`，那么它不能在类的外部或派生类中被访问。通常，类的私有成员用于存储类的内部状态和实现细节。这些成员不应该被外部代码直接访问，以保持封装性和数据隐藏。\n    \n- **protected（受保护）**： `protected`访问修饰符介于`public`和`private`之间。如果一个成员被声明为`protected`，那么它可以在类的内部以及派生类中被访问，但不能在其他非成员函数中访问。`protected`成员通常用于存储在派生类中需要访问或修改的数据或实现细节。\n\n想要访问或者修改私有成员就要设置getter和setter，例如：\n>**左值**：持久存在，能获取地址，如变量、数组元素、解引用指针\n>**右值**：临时存在，不能获取地址，如字面量、运算结果、临时值\n\n```cpp\nclass Date\n{\nprivate:\n    int m_year { 2020 };\n    int m_month { 10 };\n    int m_day { 14 };\n\npublic:\n\t//注意getter 应提供对数据的 “只读” 访问权限。\n\t//应按值（如果复制成员的成本较低）或 const 左值引用（如果创建成员的开销较高）返回\n    int getYear() const { return m_year; }        // getter for year\n\tconst int& getYear() const { return m_year; } //使用左值引用返回\n    void setYear(int year) { m_year = year; }     // setter for year\n\n    int getMonth() const  { return m_month; }     // getter for month\n    void setMonth(int month) { m_month = month; } // setter for month\n\n    int getDay() const { return m_day; }          // getter for day\n    void setDay(int day) { m_day = day; }         // setter for day\n};\n```\n**类与结构的差异**：\n1. 类将其成员默认为 private，而结构将其成员默认为 public。\n2. 类默认继承方式是private，结构默认是public\n简单没有特别需求的数据集合建议用struct\n\n## 构造函数\n\n聚合初始化（aggregate initialization）：\n- 如果类的类型是聚合aggregate的（**成员都是公共的，非私有**），可以使用{}来初始化\n- 成员将按照声明顺序初始化\n```cpp\nstruct Foo // Foo is an aggregate\n{\n    int x {};\n    int y {};\n};\n\nint main()\n{\n    Foo foo { 6, 7 }; // uses aggregate initialization\n\n    return 0;\n}\n```\n\n**构造函数**是在创建非聚合类类型对象后自动调用的特殊成员函数。\n\t- 编译器会查看是否有与调用方提供的初始化值（如果有）匹配的可访问构造函数。\n\t- 如果找到可访问的匹配构造函数，则**先分配对象的内存**，然后在未初始化的对象上调用构造函数。反之，没有对应的构造函数就会报错\n\t- 聚合不允许有构造函数 —— 因此，如果向聚合添加构造函数，它将不再是聚合。\n\n常见的几种构造函数：\n- **默认构造函数（Default constructor）**：不带任何参数（或所有参数具有默认值）的构造函数。如果程序员没有为类定义任何构造函数，编译器将自动生成一个默认构造函数。\n- **带参数构造函数（Parameterized constructor）**：带有一个或多个参数的构造函数。这种构造函数允许在创建对象时初始化对象的成员。\n- **拷贝构造函数（Copy constructor）**：接受相同类类型对象的引用作为参数的构造函数。它用于初始化一个对象为另一个对象的副本。如果程序员没有定义拷贝构造函数，编译器将自动生成一个。\n- **移动构造函数（Move constructor）**：接受相同类类型对象的**右值引用**作为参数的构造函数。它用于在不创建对象副本的情况下，将资源从一个对象移动到另一个对象。这在C++11及更高版本中引入，以优化性能。如果程序员没有定义移动构造函数，编译器可能会自动生成一个。\n\n**NOTE**：\n- 构造函数的隐式转换：构造函数也不例外，`Foo（int， int）` 构造函数将匹配其参数可隐式转换为 `int` 的任何调用\n>隐式类型转换：编译器将在函数调用中执行参数的隐式转换（如果需要），以便匹配参数为不同类型的函数定义\n\n- 构造函数不能是 const\n\t- 通常，不能在 const 对象上调用非 const 成员函数。但是，由于构造函数是隐式调用的，因此可以在 const 对象上调用非 const 构造函数。\n- 构造函数不能是虚函数。\n\t- 因为虚函数需要完整的对象和虚表，构造函数调用时未构造出完整的对象，也没有虚表，是不能够调用虚函数的\n- **单个列表初始化和单参数构造函数**的冲突：\n\t- C++ 初始化的缺点之一：`{ 10 }` 将匹配**列表构造函数**（如果存在）或**单参数构造函数**（如果列表构造函数不存在）。\n\t- C++的解决方案是列表不为空时，优先使用列表构造函数。如果为空则默认构造函数优先\n```c\nstd::vector<int> data{ 10 }; // what does this do? 会调用列表构造函数\nstd::vector<int> v2(10);     //调用单参数构造函数\n```\n#### 构造函数命名规则\n- 构造函数必须与类同名（大小写相同）。对于模板类，此名称不包括模板参数。\n- 构造函数没有返回类型（甚至没有 `void`）。\n```cpp\nclass Foo\n{\nprivate:\n    int m_x {};\n    int m_y {};\n\npublic:\n    Foo(int x, int y) // here's our constructor function that takes two initializers\n\t    : m_x{ x } , m_y{ y }   //使用列表初始化，可以使用括号()初始化。冒号开始，逗号分隔，没有结尾。要按照声明顺序初始化\n    {\n        std::cout << \"Foo(\" << x << \", \" << y << \") constructed\\n\";\n    }\n\n    void print() const\n    {\n        std::cout << \"Foo(\" << m_x << \", \" << m_y << \")\\n\";\n    }\n};\n\nint main()\n{\n    Foo foo{ 6, 7 }; // calls Foo(int, int) constructor\n    foo.print();\n\n    return 0;\n}\n```\n\n#### 默认构造函数\n不含任何参数的构造函数\n```c\n    Foo() // default constructor\n    {\n        std::cout << \"Foo default constructed\\n\";\n    }\n\nFoo foo{}; // value initialization, calls Foo() default constructor\nFoo foo2;  // default initialization, calls Foo() default constructor\n\n```\n- 一个类应该只有一个默认构造函数，不能提供多个构造函数\n- 如果没有显示定义构造函数，则编译器会提供一个无参的隐式构造函数\n\n**带默认参数的构造函数**：\n```c\n    Foo(int x=0, int y=0) // has default arguments\n        : m_x { x }\n        , m_y { y }\n    {\n        std::cout << \"Foo(\" << m_x << \", \" << m_y << \") constructed\\n\";\n    }\n```\n\n\n默认值有时还可用于将多个构造函数减少为更少的构造函数。例如，下面的Emplyee类 通过在 `id` 参数上放置默认值，我们可以创建一个需要 name 参数但可以选择接受 id 参数的 `\n```cpp\nclass Employee\n{\nprivate:\n    std::string m_name{};\n    int m_id{ 0 }; // default member initializer\n\npublic:\n\n    Employee(std::string_view name, int id = 0) // default argument for id\n        : m_name{ name }, m_id{ id }\n    {\n        std::cout << \"Employee \" << m_name << \" created\\n\";\n    }\n};\n\nint main()\n{\n    Employee e1{ \"James\" };\n    Employee e2{ \"Dave\", 42 };\n}\n```\n**NOTE**：\n\t1. 默认值必须附加到函数调用中最右侧的参数\n\t2. 如果构造函数中的所有参数都有默认参数，则该构造函数是默认构造函数\n\n**显式默认的默认构造函数**\n如果有一个用户声明的构造函数，那么编译器不会生成默认构造函数，我们可以告诉编译器主动生成 default 构造函数\n```c\n\n    Foo() = default; // generates an explicitly defaulted default constructor\n```\n显式默认的默认构造函数与空的用户定义构造函数的区别：\n\t编译器提供的默认构造函数会在对象将在默认初始化之前进行零初始化，性能差一些但安全性高一些\n\n#### 拷贝构造函数\n- 如果您没有为类提供复制构造函数，C++ 将为您创建一个公共**隐式拷贝构造函数**。默认拷贝构造函数执行的是逐个拷贝类的成员变量（浅拷贝）\n\n```cpp\n    Fraction f { 5, 3 };  // Calls Fraction(int, int) constructor\n    Fraction fCopy { f }; // 默认的拷贝构造函数， fCopy 是f的副本\n    Fraction f2 = f;      // 同样调用默认的拷贝构造函数\n```\n\n- 可以使用 `= default` 语法显式请求编译器为我们创建一个默认的复制构造函数\n```cpp\n    // Explicitly request default copy constructor\n    Fraction(const Fraction& fraction) = default;\n```\n\n- 偶尔我们会遇到不希望某个类的对象是可复制的。我们可以通过使用 `= delete` 语法将复制构造函数标记为已删除来防止这种情况\n```cpp\n    // Delete the copy constructor so no copies can be made\n    Fraction(const Fraction& fraction) = delete;\n```\n\n- 自己定义拷贝构造函数：如果类包含指向动态分配内存或资源的指针时，需要自定义拷贝构造函数以实现深拷贝。\n```cpp\nclass Fraction\n{\nprivate:\n    int m_numerator{ 0 };\n    int m_denominator{ 1 };\n\npublic:\n    // Default constructor\n    Fraction(int numerator=0, int denominator=1)\n        : m_numerator{numerator}, m_denominator{denominator}\n    {\n    }\n\n    // Copy constructor\n    Fraction(const Fraction& fraction)\n        // Initialize our members using the corresponding member of the parameter\n        : m_numerator{ fraction.m_numerator }\n        , m_denominator{ fraction.m_denominator }\n    {\n        std::cout << \"Copy constructor called\\n\"; // just to prove it works\n    }\n```\n这里涉及到访问控制的问题，Fraction拷贝构造函数可以读取其他Fraction对象的private成员吗，即同一类的对象可以访问其他对象的private成员吗？ \n\t答案是可以，因为访问控制是基于类的，而不是基于对象，同类对象可以访问彼此的私有成员\n\n- 隐式复制构造函数调用\n一般需要创建**临时对象副本**来存储传入的参数时，都会隐式调用复制构造函数，例如下面几种情况。\n1. 将一个类对象初始化新对象\n```c\nFraction fCopy { f };\n```\n2. 将对象作为参数传递给函数，且为按值传递时，编译器将隐式调用复制构造函数，复制一个临时副本来传递参数\n```cpp\nvoid printFraction(Fraction f) // f is pass by value，这里将隐式调用复制构造函数，复制一个临时的f\n{\n    f.print();\n}\n\nint main()\n{\n    Fraction f{ 5, 3 };\n\n    printFraction(f); // f is copied into the function parameter using copy constructor\n    printFraction(Fraction(3, 4));  // 创建一个临时的 Fraction 对象，调用复制构造函数\n    return 0;\n}\n```\n\n3. 函数返回对象，且为按值返回时，从一个函数返回一个临时对象，也会隐式调用复制构造函数。\n```c\nFraction createFraction() {\n    return Fraction(3, 4);  // 临时对象会调用复制构造函数\n}\n```\n思考🤔 从执行逻辑上，下面会调用几次复制构造函数：\n如果运行的话可能次数会减少，因为编译器会进行copy elision优化\n```cpp\nint main()\n{\n    Fraction f2 { createFraction() }; // Fraction is returned using copy constructor\n\n    printFraction(f2); // f2 is copied into the function parameter using copy constructor\n\n    return 0;\n}\n```\n\n**NOTE**：\n\t- 复制构造函数除了复制之外，不应有任何其他工作\n\t- 首选隐式复制构造函数，除非你有特定原因要创建自己的构造函数。\n\t- 复制构造函数的参数应为 const 左值引用\n\t\t- 因为当对象参数按值传递时，会隐式调用复制构造函数复制一个临时对象，如果复制构造函数自身也按值传递，那么它将会再次调用自己，这将导致无限递归调用，程序会因栈溢出而崩溃。\n#### 委托构造函数\n这是C++11的特性\n\n在构造函数中不能直接调用同类的另一个构造函数：\n下面会导致编译错误或者构造出一个临时对象\n```cpp\nclass Employee\n{\nprivate:\n    std::string m_name { \"???\" };\n    int m_id { 0 };\n    bool m_isManager { false };\n\npublic:\n    Employee(std::string_view name, int id)\n        : m_name{ name }, m_id { id } // this constructor initializes name and id\n    {\n        std::cout << \"Employee \" << m_name << \" created\\n\"; // our print statement is back here\n    }\n\n    Employee(std::string_view name, int id, bool isManager)\n        : m_isManager { isManager } // this constructor initializes m_isManager\n    {\n        // Call Employee(std::string_view, int) to initialize m_name and m_id\n        Employee(name, id); // this doesn't work as expected!因为这里构造的是一个临时对象，最后会被删除\n    }\n\n    const std::string& getName() const { return m_name; }\n};\n\nint main()\n{\n    Employee e2{ \"Dave\", 42, true };\n    std::cout << \"e2 has name: \" << e2.getName() << \"\\n\"; // print e2.m_name\n}\n\n输出：\nEmployee Dave created\ne2 has name: ???\n```\n\n**委托构造函数**：允许构造函数将初始化委托（转移责任）给同一类类型的另一个构造函数\n\t实例：在列表初始化中调用另一个构造函数，将变量name传递给另一个构造函数\n```cpp\npublic:\n    Employee(std::string_view name)\n        : Employee{ name, 0 } // delegate initialization to Employee(std::string_view, int) constructor\n    {\n    }\n\n    Employee(std::string_view name, int id)\n        : m_name{ name }, m_id { id } // actually initializes the members\n    {\n        std::cout << \"Employee \" << m_name << \" created\\n\";\n    }\n\n};\n```\n**NOTE**：\n1. 构造函数可以委托或初始化，但不允许同时初始化和委托\n2. 如果您有多个构造函数，请考虑是否可以使用委托构造函数来减少重复代码。通常将具有较少参数的构造函数委托给具有更多参数的构造函数。\n## const类\n初始化 const 类类型对象后，不允许任何修改const对象数据成员\nConst 对象不能调用非 const 成员函数 （非 const 成员没有限制）\n\t由于 const 成员函数可以在 const 和非 const 对象上调用，因此如果成员函数不修改对象的状态，则应将其设为 const。\n\t构造函数不能设为 const，因为它们需要初始化对象的成员\n\n>const 成员函数的限制：\n\t• 不能修改对象的状态（除非通过 mutable 或 const_cast）。\n\t• 不能调用非 const 成员函数\n\t• 无法返回对数据成员的非 const 引用\n```c\nstruct Date\n{\n    int year {};\n    int month {};\n    int day {};\n\n    void print() const // now a const member function,要声明为const函数\n    {\n        std::cout << year << '/' << month << '/' << day;\n    }\n};\n\nint main()\n{\n    const Date today { 2020, 10, 14 }; // const\n\n    today.print();  // ok: const object can call const member function\n\n    return 0;\n}\n```\n\n下面的代码错误在哪？\n```c\nstruct Date\n{\n    int year {};\n    int month {};\n    int day {};\n\n    void print() // non-const\n    {\n        std::cout << year << '/' << month << '/' << day;\n    }\n};\n\nvoid doSomething(const Date& date)\n{\n    date.print();\n}\n\nint main()\n{\n    Date today { 2020, 10, 14 }; // non-const\n    today.print();\n\n    doSomething(today);\n\n    return 0;\n}\n```\n错误：doSomething中，`date` 被视为 const 对象（因为它是通过 const 引用传递的）。然而const对象`date`调用非const函数print，导致了错误\n解决方法：让print变成const\n\n#### 空类\n","tags":["c++"],"categories":["note","c++学习笔记"]},{"title":"c++学习笔记——函数重载","url":"/2024/06/07/note/c++学习笔记/函数重载/","content":"函数重载是C++**静态多态特性**的实现之一。\n**函数重载**：允许我们创建多个同名的函数，只要每个同名函数具有不同的参数类型（或者函数可以以其他方式区分），C++会使用上下文来确定要使用的重载函数版本\n\n| 区分重载函数的属性 | 能否重载    | Note                                               |\n| --------- | ------- | -------------------------------------------------- |\n| 参数类型      | 可以      |                                                    |\n| 参数数量      | 可以      | 不包括 typedef、type aliases 和 const 参数的限定符。<br>包括省略号。 |\n| **返回类型**  | **不可以** |                                                    |\n对于**成员函数**，还会考虑其他函数级限定符：const 、volatile、Ref 都可以重载\n\n一些需要注意的点：\n1. 函数返回类型不同不会影响重载。\n2. &不会影响重载，C++类型引用&和类型本身视为同一个特征标。\n3. const会影响重载，如下面的例子dribble( )函数将根据实参是否为const来决定使用哪个原型。\n    - 注意：如果没有`dribble(const char * a)`，`dribble(char * a)`也可以与const参数匹配，因为可以将非const值赋给const变量，但反之是非法的\n```c\nvoid dribble(char * a);\nvoid dribble(const char * a);\n```\n\n**类型签名**：函数标头中用于区分函数的部分，上面的函数名称、参数数量、参数类型和函数级限定符都是签名的一部分\n\n```cpp\nint add(int x, int y) // integer version\n{\n    return x + y;\n}\n\ndouble add(double x, double y) // floating point version\n{\n    return x + y;\n}\n\nint add(int x, int y, int z)\n{\n    return x + y + z;\n}\n\n//只要每个重载函数的参数类型列表不同，也可以区分函数。\ndouble add(int x, double y); // mixed version\ndouble add(double x, int y); // mixed version\ndouble add(double x, ...); // mixed version\n\n```\n\n对于按值传递的参数，也不考虑 const 限定符。\n\t下面不被视为重载\n```cpp\nvoid print(int);\nvoid print(const int); // not differentiated from print(int)\n```\n\n为什么返回类型不同不被视为重载：\n\t为了避免问题变得过于复杂。如果返回值用于区分，那么我们将没有一种简单的语法方法来判断正在调用函数的哪个重载 —— 我们还必须了解返回值是如何被使用的，这需要更多的分析。\n重载的实现原理：\n\t**名称修饰**，函数的编译名称会根据各种条件（如参数的数量和类型）被更改（“损坏”），以便其在链接器中具有唯一的名称。\n\t例如，原型为 `int fcn（）` 的函数可能会编译为损坏的名称`__fcn_v`，而 `int fcn（int）` 可能会编译为损坏的名称`__fcn_i`。因此，虽然在源代码中，两个重载函数共享名称 `fcn（），`但在编译代码中，**不同函数的名称是唯一**的（`__fcn_v` 与 `__fcn_i`）。\n\n#### 重载函数的调用\n重载函数进行函数调用时，编译器会逐步执行一系列规则，以确定哪些（如果有）重载函数是最匹配的\n**基本优先级如下**：  \n\t**精确匹配 → 类型提升 → 标准转换 → 用户定义转换 → 可变参数**\n\n**具体步骤**：\n**步骤 1）** **精确匹配**：编译器尝试查找完全匹配项。这分两个阶段进行。首先，编译器将查看是否存在一个重载函数，其中函数调用中的参数类型与重载函数中的参数类型完全匹配。\n编译器将对函数调用中的参数应用一些**简单的转换**。**普通转换**是一组特定的转换规则，这些规则将修改类型（不修改值）以查找匹配项\n\t包括：\n\t    - 左值到右值的转换\n\t    - 限定转换（例如，non-const 到 const）\n\t    - 非引用到引用转换\n\t例如：调用了 `foo（x），`其中 `x` 是一个 `int`。编译器会简单地将 `x` 从 `int` 转换为 `const int`，然后匹配 `foo（const int）。`我们也调用了 `foo（d），`其中 `d` 是`双精度`值。编译器会简单地将 `d` 从 `double` 转换为 `const double&`，然后匹配 `foo（const double&）。`\n```cpp\nvoid foo(const int)\n{\n}\n\nvoid foo(const double&) // double& is a reference to a double\n{\n}\n\nint main()\n{\n    int x { 1 };\n    foo(x); // x trivially converted from int to const int\n\n    double d { 2.3 };\n    foo(d); // d trivially converted from double to const double& (non-ref to ref conversion)\n\n    return 0;\n}\n```\n\n 通过普通转换进行的匹配被视为完全匹配。这意味着以下程序会导致不明确的匹配：\n ```cpp\nvoid foo(int)\n{\n}\n\nvoid foo(const int&) // int& is a reference to a int\n{\n}\n\nint main()\n{\n    int x { 1 };\n    foo(x); // ambiguous match with foo(int) and foo(const int&)\n\n    return 0;\n}\n```\n\n**第 2 步**）**类型提升**：如果未找到完全匹配项，编译器将尝试通过对参数应用**隐式类型转换数字提升**来查找匹配项。\n\t例如：对于 `foo（'a'），`由于在上一步中找不到 `foo（char）` 的精确匹配项，因此编译器会将 char `'a'` 提升为 `int`，并查找匹配项。这与 `foo（int）` 匹配，因此函数调用解析为 `foo（int）。`\n```cpp\nvoid foo(int)\n{\n}\n\nvoid foo(double)\n{\n}\n\nint main()\n{\n    foo('a');  // promoted to match foo(int)\n    foo(true); // promoted to match foo(int)\n    foo(4.5f); // promoted to match foo(double)\n\n    return 0;\n}\n```\n**步骤 3**）**标准转换**： 如果通过数字提升未找到匹配项，则编译器将尝试通过对参数应用**标准转换**来查找匹配项。\n\t例如：在这种情况下，由于没有 `foo（char）` （完全匹配） ，也没有 `foo（int）` （促销匹配），因此 `'a'` 在数值上转换为 double 并与 `foo（double）` 匹配。\n```cpp\nvoid foo(double)\n{\n}\n\nvoid foo(std::string)\n{\n}\n\nint main()\n{\n    foo('a'); // 'a' converted to match foo(double)\n\n    return 0;\n}\n```\n\n**第 4 步**）**用户定义转换**：如果通过数字转换未找到匹配项，则编译器将尝试通过任何**用户定义的转换**找到匹配项。\n值得注意到是，**类的构造函数**还充当从其他类型到该类类型的用户定义转换，并且可以在此步骤中用于查找匹配的函数。\n\t例如：编译器将首先检查是否存在与 `foo（X）` 完全匹配。我们还没有定义一个。接下来，编译器将检查 `x` 是否可以在数值上提升，而它不能。然后编译器将检查 `x` 是否可以进行数值转换，而它也不能。最后，编译器将查找任何用户定义的转换。由于我们定义了从 `X` 到 `int` 的用户定义转换，因此编译器会将 `X` 转换为 `int` 以匹配 `foo（int）。`\n```cpp\nclass X // this defines a new type called X\n{\npublic:\n    operator int() { return 0; } // Here's a user-defined conversion from X to int\n};\n\nvoid foo(int)\n{\n}\n\nvoid foo(double)\n{\n}\n\nint main()\n{\n    X x; // Here, we're creating an object of type X (named x)\n    foo(x); // x is converted to type int using the user-defined conversion from X to int\n\n    return 0;\n}\n```\n\n**第 5 步**）**可变参数**：如果通过用户定义的转换未找到匹配项，编译器将查找使用省略号的匹配函数。\n**第 6 步**）如果此时未找到匹配项，编译器将放弃并发出有关找不到匹配函数的编译错误。\n\n**不明确匹配**：例如**多个最佳匹配导致歧义**，将会编译错误错误\n\t例如：`5L` 的类型为 `long`，编译器将首先查看是否能找到 `foo（long）` 的精确匹配项，但找不到。接下来，编译器将尝试数字提升，但无法提升 `long` 类型的值，因此这里也没有匹配项。\n\t之后，编译器将尝试通过对 `long` 参数应用数值转换来查找匹配项。在检查所有数字转换规则的过程中，编译器将找到两个可能的匹配项。如果 `long` 参数在数值上转换为 `int`，则函数调用将匹配 `foo（int）。`如果 `long` 参数被转换为 `double`，那么它将匹配 `foo（double）。`由于已通过数字转换找到两个可能的匹配项，因此函数调用被视为不明确。\n```cpp\nvoid foo(int)\n{\n}\n\nvoid foo(double)\n{\n}\n\nint main()\n{\n    foo(5L); // 5L is type long\n\n    return 0;\n}\n```\n另一个产生不明确匹配项的示例：\n\t尽管您可能希望 `0` 解析为 `foo（unsigned int），`而 `3.14159` 解析为 `foo（float），`但这两种调用都会导致不明确的匹配。`int` 值 `0` 可以在数值上转换为 `unsigned int` 或 `float`，因此任一重载的匹配效果相同，结果是不明确的函数调用。\n\t这同样适用于将 `double` 转换为 `float` 或 `unsigned int`。两者都是数字转换，因此任一重载的匹配效果相同，结果同样不明确。\n\n```cpp\nvoid foo(unsigned int)\n{\n}\n\nvoid foo(float)\n{\n}\n\nint main()\n{\n    foo(0);       // int can be numerically converted to unsigned int or to float\n    foo(3.14159); // double can be numerically converted to unsigned int or to float\n\n    return 0;\n}\n```\n有几种方法可以解决不明确的匹配项：\n\t1. 最好的方法是简单地定义一个新的重载函数，该函数采用您尝试调用函数的类型的参数。\n\t2. 显式转换不明确的参数以匹配要调用的函数的类型。例如，要让 `foo（0）` 匹配上面的例子中的 `foo（unsigned int），`你可以这样做\n\t也可以使用 Literal 后缀来确保将 Literal 解释为正确的类型\n```cpp\nint x{ 0 };\nfoo(static_cast<unsigned int>(x)); // will call foo(unsigned int)\nfoo(0u); // will call foo(unsigned int) since 'u' suffix is unsigned int, so this is now an exact match\n```\n\n**删除函数**：如果我们有一个明确不希望可调用的函数，我们可以使用 **= delete** 说明符将该函数定义为已删除。如果编译器将函数调用与已删除的函数匹配，则编译将停止并出现编译错误。\n\t注意已删除的函数仍被视为函数重载解析的候选项。\n```cpp\nvoid printInt(int x)\n{\n    std::cout << x << '\\n';\n}\n\nvoid printInt(char) = delete; // calls to this function will halt compilation\nvoid printInt(bool) = delete; // calls to this function will halt compilation\n```cpp\nint main()\n{\n    printInt(97);   // okay\n\n    printInt('a');  // compile error: function deleted\n    printInt(true); // compile error: function deleted\n\n    printInt(5.0);  // compile error: ambiguous match\n\n    return 0;\n}\n```\n删除一堆单独的函数重载工作正常，但可能会很冗长。我们可以使用函数模板来实现此目的，\n\t如下所示：\n```cpp\nvoid printInt(int x)\n{\n    std::cout << x << '\\n';\n}\n\n// This function template will take precedence for arguments of other types\n// Since this function template is deleted, calls to it will halt compilation\ntemplate <typename T>\nvoid printInt(T x) = delete;\n```\n\n**非模板函数 vs 模板实例化**：\n\t如果非模板函数得到精确匹配的话，**优先选择非模板函数**。\n```c   \ntemplate <typename T> void f(T); // 模板\nvoid f(int);                     // 非模板\nint main() {\n\tf(42); // 优先调用 void f(int)\n}\n```\n.\n\t没有精确匹配的非模板函数，会将可以匹配的模板函数视为精确匹配。即**模板的精确匹配，优先级低于非模板函数的精确匹配，但高于类型提升**\n```c\ntemplate <typename T> void f(T);      // 模板函数\nvoid f(int);    // 非模板函数（需要类型提升）\n\nint main() {\n    f('a');     // char 类型不是int的精确匹配, 将优先匹配模板函数\n}\n\n```\n#### 默认参数\n如果调用方未提供参数，则使用 default 参数的值。\n必须使用等号来指定 default 参数。使用括号或大括号初始化不起作用\n默认参数由编译器在函数调用的站点插入。当编译器看到 `print（3）` 时，它会将此函数调用重写为 `print（3， 4），`以便参数的数量与参数的数量相匹配。\n```cpp\nvoid print(int x, int y=4) // 4 is the default argument\n{\n    std::cout << \"x: \" << x << '\\n';\n    std::cout << \"y: \" << y << '\\n';\n}\n\nint main()\n{\n    print(1, 2); // y will use user-supplied argument 2\n    print(3); // y will use default argument 4, as if we had called print(3, 4)\n\n    return 0;\n}\n```\n\nC++ 不支持 （从 C++23 开始） 函数调用语法，例如 `print（，，3）` （作为在使用 `x` 和 `y` 的默认参数时，为 `z` 提供显式值的一种方式。这有三个主要后果：\n1. 在函数调用中，任何显式提供的参数都必须是最左侧的参数（不能跳过具有默认值的参数）。\n```cpp\nvoid print(std::string_view sv=\"Hello\", double d=10.0);\n\nint main()\n{\n    print();           // okay: both arguments defaulted\n    print(\"Macaroni\"); // okay: d defaults to 10.0\n    print(20.0);       // error: does not match above function (cannot skip argument for sv)\n\n    return 0;\n}\n```\n-\n2. 如果为参数指定了 default 参数，则所有后续参数（右侧）也必须为 default 参数指定。\n```cpp\nvoid print(int x=10, int y); // 错误，not allowed\n```\n-\n3. 如果多个参数具有 default 参数，则最左边的参数应该是用户最有可能显式设置的参数。\n\n一旦声明，default 参数就不能在同一翻译单元中重新声明。这意味着对于具有 forward 声明和函数定义的函数，default 参数可以在 forward 声明或函数定义中声明，但不能同时在两者中声明。\n```cpp\nvoid print(int x, int y=4); // forward declaration\n\nvoid print(int x, int y=4) // compile error: redefinition of default argument\n{\n    std::cout << \"x: \" << x << '\\n';\n    std::cout << \"y: \" << y << '\\n';\n}\n```\n最佳做法是在 forward 声明中声明 default 参数，而不是在函数定义中声明 default，因为 forward 声明更有可能被其他文件看到并在使用之前包含在内（特别是如果它位于头文件中）。\n\t在 foo.h 中：\n```cpp\n#ifndef FOO_H\n#define FOO_H\nvoid print(int x, int y=4);\n#endif\n```\n-\n\t在 main.cpp：我们能够使用函数 `print（）` 的默认参数，因main.cpp包含foo.h，它具有定义 default 参数的 forward 声明\n```cpp\n#include \"foo.h\"\n#include <iostream>\n\nvoid print(int x, int y)\n{\n    std::cout << \"x: \" << x << '\\n';\n    std::cout << \"y: \" << y << '\\n';\n}\n\nint main()\n{\n    print(5);\n\n    return 0;\n}\n```\n\n**默认参数的函数重载**：\n具有 default 参数的函数可能会重载。\n```cpp\nvoid print(std::string_view s)\n{\n    std::cout << s << '\\n';\n}\n\nvoid print(char c = ' ')\n{\n    std::cout << c << '\\n';\n}\n\nint main()\n{\n    print(\"Hello, world\"); // resolves to print(std::string_view)\n    print('a');            // resolves to print(char)\n    print();               // resolves to print(char)\n\n    return 0;\n}\n```\n下面的案例中，由于默认值不是函数签名的一部分，因此这些函数声明是差分重载。\n```cpp\nvoid print(int x);                  // signature print(int)\nvoid print(int x, int y = 10);      // signature print(int, int)\nvoid print(int x, double y = 20.5); // signature print(int, double)\n```\n\n默认参数很容易导致模棱两可的函数调用：\n```cpp\nvoid foo(int x = 0)\n{\n}\n\nvoid foo(double d = 0.0)\n{\n}\n\nint main()\n{\n    foo(); // ambiguous function call\n\n    return 0;\n}\n```\n更复杂的案例：\n\t对于调用 `print（1），`编译器无法判断这是解析为 `print（int）、``print（int， int）` 还是 `print（int， double）。`\n```cpp\nvoid print(int x);                  // signature print(int)\nvoid print(int x, int y = 10);      // signature print(int, int)\nvoid print(int x, double y = 20.5); // signature print(int, double)\n\nint main()\n{\n    print(1, 2);   // will resolve to print(int, int)\n    print(1, 2.5); // will resolve to print(int, double)\n    print(1);      // ambiguous function call\n\n    return 0;\n}\n```\n\n**默认参数不适用于通过函数指针调用的函数**\n\n","tags":["c++"],"categories":["note","c++学习笔记"]},{"title":"CUDA笔记——CUDA语言","url":"/2024/05/08/note/cuda/CUDA笔记——CUDA语言/","content":"## CUDA 代码架构\n```c++\n#include <cuda_runtime.h>  // CUDA 运行时 API\nheader inclusion\nconst or macro definition\ndeclarations of C++ functions and CUDA kernels\n\n__global__ void vectorAddKernel(const float* A, const float* B, float* C, int size) {\n    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n    if (idx < size) {\n        C[idx] = A[idx] + B[idx];\n\n    }\n}\n\nint main()\n{\n    allocate host and device memory\n    initialize data in host memory\n    transfer data from host to device\n    launch (call) kernel to do calculations in the device\n    transfer data from device to host\n    free host and device memory\n}\n\ndefinitions of C++ functions and CUDA kernels\n````\n- `__global__` 是 **CUDA 核函数** 的修饰符，用于 **定义在 GPU 上运行、由 CPU 端调用的函数**。\n- 其他kernel修饰符如下\n\n| kernel修饰符    | 意义                                              |\n| ------------ | ----------------------------------------------- |\n| `__global__` | 表示为kernel函数，在host中调用，device中执行                  |\n| `__device__` | 表示为device函数，在kernel中调用，device中执行                |\n| `__host__`   | 表示未host函数，在host中调用，host中执行  （可以与`__device__`合用） |\n**维度指定**：\n```c++\ndim3 grid_dim(gridDim.x,gridDim.y,gridDim.z)\ndim3 block_dim(blockDim.x,blockDim.y,blockDim.z)\nkernelFunct<<<grid_dim,block_dim>>>\n\n//通常block_dim都是指定的常数，grid_dim根据要分配的线程总数量指定\n//例1:对某个大小为N的一维数组每个元素进行计算\ndim3 block_dim(THREADS_PER_BLOCK);\ndim3 grid_dim((N+THREADS_PER_BLOCK-1)/THREADS_PER_BLOCK); //相当于计算N个线程总共需要的blcokNum，要向上取整\n\n\n//例2:对宽width，长height的二维数组中每个元素进行计算\ndim3 blockDim(THREADS_PER_BLOCKX, THREADS_PER_BLOCKY);\ndim3 gridDim((width + blockDim.x - 1) / blockDim.x, (height + blockDim.y - 1) / blockDim.y);\n```\n**kernel的注意事项**：\n1. 在`kernelFunct<<<grid_dim,block_dim>>>`中，grid_dim,block_dim是必须要指定的\n    - grid_dim可以理解为要分配的block数，block_dim则是每个block分配的thread数，总线程数gridDim.x * gridDim.y* gridDim.z * blockDim.x * blockDim.y* blockDim.z\n\t- grid_dim指定了grid的维度，block_dim指定了block的维度\n\t- 一般来说grid_dim越大越好，但block_dim不能太小（因为wrap以32个thread来捆绑）\n3. kernel的没有返回值\n4. 传入kernel的指针必须指向device的内存，除非使用unified memory\n5. kernel不能被其他kernel调用，除非使用dynamic parallelism \n6. kernel不能为class的成员\n\n\nid的计算：\n```c\n//二维块在二维数组对应id\n    int i = blockIdx.x * blockDim.x + threadIdx.x;\n    int j = blockIdx.y * blockDim.y + threadIdx.y;\n//大小为 （Dx， Dy）的二维块，索引为（x， y）的线程的线程 顺序ID 为 （x + y * Dx）,类比二维数组就是x是列号j，y是行号i，Dx是行长度n\n\tint threadId= threadId.x + threadId.y*blockDim.x\n```\n线程同步：\n```c\n__syncthreads();   //只有同一block中的线程可以同步\n```\n## CUDA runtime API\n常用API由内存分配和同步API\n- **cudaMalloc(void\\*\\* devPtr, size_t size)**: \n\t- 分配`size`字节的device内存空间，该空间开头由`*devPtr`指向(注意**devPtr是个二级指针**，因为要改变指针的值（指向地址）)。 返回值是cudaError_t\n    - 例：\n```c++\n            double* d_x\n            cudaMalloc((void**)&d_x,sizeof(double)*n);     //这里传入的参数是指针的地址，说明参数需要二级指针，(void**)可以省略\n```\n- **cudaMemcpy(void* dst,  const void* src,  size_t size ,  kind)** : \n\t- 从由`src`指向的源地址内存空间中复制`size`字节到 由`dst`指向的地址内存空间。移动方式为`kind`，`kind`如下表\n    - 例：\n```c++\n    cudaMemcpy(d_x , h_x, sizeof(double)*n , cudaMemcpyHostToDevice);  //把host中h_x指向的内容复制到device中d_x指向的内存空间\n    cudaMemcpy(h_z, d_z, sizeof(double)*n, cudaMemcpyDeviceToHost);    //把device的计算结果传回host\n```\n![](CUDA笔记——CUDA语言/img-CUDA语言-5.png)\n\n- **cudaFree(void* devPtr)**: 释放GPU内存空间\n\n- **cudaDeviceSynchronize**():  \n\t- 同步GPU和CPU：因为kernel与CPU的执行是异步的，该API能够阻塞CPU等待device执行kernel完后再往下运行。\n    - cudaMemcpy不需要，因为其自带阻塞功能\n    - 如果有多个kernel要执行的话：命令行`export CUDA_LAUNCH_BLOCKING=1`，可以直接设置每次执行kernel阻塞\n## nvcc编译\n.cu文件的编译分为两个部分，一部分是编译主机代码，另一部分是编译设备代码，设备代码的编程过程中会生成.ptx文件\n1. 首先nvcc会把`cu`文件分为host code 和 device code，其中host code由c++编译器编译\n2. device code由nvcc编译为**PTX**（Parallel Thread eXecution）code，\n\t- 可以在命令行指定**virtual architecture**的计算能力： `-arch=compute_XY`\n3. PTX code再编译为cubin binary文件\n\t- 可以在命令行指定 real architecture的计算能力：`-code=sm_ZW`\n\t\t- 例如：nvcc **-arch=compute_70**  **-code=sm_70** xxx.cu\n\t- 可以使用`-gencode` 指定多个GPU的计算能力\n\n![](CUDA笔记——CUDA语言/img-CUDA语言-1.png)\n## 错误管理\ncuda API或kernel出现错误时，不会停止运行主机代码\n\ncuda api调用返回cudaError_t\n\t- 成功：返回cuda Success\n\t- 错误：返回错误码，需要使用cudaGetErrorString查看错误信息\n\n使用宏检查基本API的错误\n```c\n#define CHECK_CUDA_ERROR(call)                                           \\\n    do {                                                                 \\\n        cudaError_t err = call;                                          \\\n        if (err != cudaSuccess) {                                        \\\n            fprintf(stderr, \"CUDA Error at %s:%d - %s\\n\",                \\\n                    __FILE__, __LINE__, cudaGetErrorString(err));        \\\n            exit(EXIT_FAILURE);                                          \\\n        }                                                                \\\n    } while (0)\n\n//使用实例\nCHECK_CUDA_ERROR(cudaMalloc((void**)&d_ptr, size));\nCHECK_CUDA_ERROR(cudaMemcpy(d_ptr, h_ptr, size, cudaMemcpyHostToDevice));\nCHECK_CUDA_ERROR(cudaFree(d_ptr));\n```\n\nkernel函数的错误需要使用cudaGetLastErro()\n- 由于CUDA 内核调用是 **异步** 执行的，因此即使内核出错，cudaGetLastError() 也可能不会立即报告错误。\n- 在宏中需要使用 cudaDeviceSynchronize() 来强制同步并检查错误\n```c\n\n#define CHECK_CUDA_KERNEL(call)                                          \\\n    do {                                                                 \\\n        call;                                                            \\\n        cudaError_t err = cudaGetLastError();                            \\\n        if (err != cudaSuccess) {                                        \\\n            fprintf(stderr, \"CUDA Kernel Error at %s:%d - %s\\n\",         \\\n                    __FILE__, __LINE__, cudaGetErrorString(err));        \\\n            exit(EXIT_FAILURE);                                          \\\n        }                                                                \\\n        err = cudaDeviceSynchronize();                                   \\\n        if (err != cudaSuccess) {                                        \\\n            fprintf(stderr, \"CUDA Sync Error at %s:%d - %s\\n\",           \\\n                    __FILE__, __LINE__, cudaGetErrorString(err));        \\\n            exit(EXIT_FAILURE);                                          \\\n        }                                                                \\\n    } while (0)\n\nCHECK_CUDA_KERNEL(myKernel<<<gridSize, blockSize>>>(d_ptr));\n```","tags":["cuda"],"categories":["note","cuda"]},{"title":"CUDA笔记——GPU结构","url":"/2024/05/06/note/cuda/CUDA笔记——GPU结构/","content":"## GPU结构\nGPU全名为Graphics Processing Unit，又称视觉处理器、图形显示卡，是一种专门用来执行图形处理和并行计算任务的**芯片**。\nGPU负责渲染出2D、3D、VR效果，主要专注于计算机图形图像领域。后来人们发现，GPU非常适合并行计算，可以加速现代科学计算，GPU也因此不再局限于游戏和视频领域。\n\n### GPU工作流\n\nCPU 主要负责从主存（Main Memory）中读取和写入数据，并通过总线（Bus）与 GPU 进行通信。相比之下，GPU 不仅拥有大量专门用于并行计算的核心，还配备了一块独立的存储区域，称为显存（VRAM）。\n\n在 GPU 执行计算任务时，它的计算核心无法直接访问主存中的数据，而是必须通过显存进行数据读写。因此，在编写 GPU 相关的代码时，程序员需要显式地管理数据传输，指定哪些数据需要在主存与显存之间进行拷贝，以确保计算任务能够顺利执行。\n![CPU与GPU](https://www.lulaoshi.info/assets/cpu-and-gpu-392408bf.png)\n\n### GPU组成结构\n#### SM\n在英伟达的设计里，多个核心组成一个Streaming Multiprocessor（**SM**）\n- 每一个SM有左右两个SM Processing Block（SMP），**每个SM有多个SP组成**\n\t- 每个SM可以执行多个block，block一旦分配给SM就会常驻在SM中直到执行结束\n\t- 每个SM都有一个local L1 cache，但共用GPU的L2 cache\nSM结构图如下\n![](CUDA笔记——GPU结构/img-GPU和CUDA简介-2.png)\n以NVIDIA Tesla P100为例，包含60个SM \n![Nvidia unveils first Pascal graphics card, the monstrous Tesla P100 ...](https://cdn.arstechnica.net/wp-content/uploads/sites/3/2016/04/gp100_block_diagram-1.png)\n\n#### SM内部结构\nSM包括SP、各种内存、线程束调度器（wrap scheduler）、指令分发器（dispatch unit）等，有些架构的SM还有tensor core\n1. SP（Streaming Processor）\n\t- **GPU最基本处理单元，又称CUDA core，相当於一个简易的CPU**，一个sp执行一个thread，可以类比办公桌 \n\t- 内部包括控制单元Dispatch Port，Operand Collector，以及浮点计算单元FP Unit、整数计算单元Int Unit，另外逼包括计算结果队列当然还有Compare.Logic Branch等\n2. 共享内存share memory：位于片内，靠近每个sm处理器内核的轻量级低延迟内存（类似于L1 cache），每个SM都有一个共享内存，被执行的block划分\n3. 寄存器：位于片内，SM内的寄存器文件很大，大到分配到SM每个线程块内的每个线程，都拥有自己的寄存器。\n\t- **零开销线程束切换**：线程束warp的上下文切换，实际上只需要换一下寄存器空间的指针即可，十分迅速。生命周期是kernel函数内，编译命令-maxrregcount可以控制寄存器分配数\n4. 线程本地内存：片外，每个线程都有自己的本地私有内存，通常用来存储寄存器溢出的数据。GPU通常会使用L1 L2来对本地内存进行优化\n### GPU和CPU在结构上的区别\n与CPU的结构对比图：\n[![The GPU Devotes More Transistors to Data Processing|600](https://docs.nvidia.com/cuda/cuda-c-programming-guide/_images/gpu-devotes-more-transistors-to-data-processing.png)](https://docs.nvidia.com/cuda/cuda-c-programming-guide/_images/gpu-devotes-more-transistors-to-data-processing.png)\n1. **核心数量**：\n- CPU拥有少量（2-16个）高性能核心，GPU有成千上万个较小的核心；\n2. **控制单元和指令处理**：\n\t- CPU具有复杂的控制单元和高级指令集，适合执行需要多种逻辑操作和频繁数据交换的任务。\n\t- GPU控制单元较简单，指令集精简，适合大规模并行的浮点运算。\n3. **缓存和内存架构**：\n\t- CPU通常拥有较大的缓存（如L1、L2和L3缓存），较少数量的寄存器，减少内存访问延迟\n\t- GPU一般有较小的缓存，更依赖显存（VRAM）进行数据存储和访问。此外GPU的寄存器数量比CPU大得多\n\n|      | CPU                            | GPU                        |\n| ---- | ------------------------------ | -------------------------- |\n| 核心数量 | 少量高性能核心（通常2-16个），侧重单线程性能       | 大量简化核心（通常数百到数千个），侧重并行计算吞吐量 |\n| 指令集  | 丰富且复杂，支持多种任务、分支预测、乱序执行         | 简化指令集，采用SIMT架构，分支预测和调度相对简单 |\n| 控制单元 | 复杂的控制逻辑，适应复杂的控制流和上下文切换         | 控制逻辑较简单，主要依靠大量核心进行并行运算     |\n| 内存架构 | 多级高速缓存（L1、L2、L3）优化低延迟访问，内存带宽较低 | 依赖显存（VRAM），但延迟相对较高         |\n\n\n\n### SIMD与SIMT\nSIMD（**Single Instruction, Multiple Data**）和 SIMT（**Single Instruction, Multiple Threads**）是 CPU 和 GPU 在并行计算设计上的一个重要区别。\n\n- SIMD：单指令多数据，由一个指令并行执行多个数据。例如CPU核心中的多个处理器单元执行相同的指令，但是每个单元处理不同的数据。是数据级的并行。典型的 SIMD 指令集有 Intel SSE、AVX、AVX-512\n- SIMT：单指令多线程，多个线程执行相同的指令，每个线程处理不同的数据。例如GPU中每个SM有多个线程来执行相同的指令，这些线程可以独立控制自己的数据流和状态，是线程级的并行\n\n|           | SIMD (单指令多数据流)              | SIMT (单指令多线程)                   |\n| --------- | --------------------------- | ------------------------------- |\n| **基本概念**  | 同一时刻多数据应用相同的指令              | 同一时刻多线程执行相同的指令                  |\n| **执行单位**  | 单个指令在多个数据元素上并行执行            | 每个线程执行相同的指令                     |\n| **处理器架构** | 在一个处理器中有多个数据路径，每个路径处理不同的数据  | 每个线程对应一个执行单元，可以并行执行多个线程         |\n| **指令流**   | 所有数据元素使用相同的指令，但数据元素的操作是独立的  | 所有线程使用相同的指令，每个线程执行独立的操作         |\n| **控制流**   | 控制流通常较为简单，直接操作数据流           | **每个线程有自己的控制流**，可能有分支和同步操作      |\n| **并行度**   | 在单指令下处理多个数据元素，但并行度受到数据分布的限制 | 高度并行，每个线程都有自己的控制和数据，但线程数受限于硬件资源 |\n\n\n","tags":["cuda"],"categories":["note","cuda"]}]